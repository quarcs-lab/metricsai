<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Chapter 15: Regression with Transformed Variables – Econometrics Powered by AI</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../notebooks_colab/ch16_Checking_the_Model_and_Data.html" rel="next">
<link href="../notebooks_colab/ch14_Regression_with_Indicator_Variables.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-27c261d06b905028a18691de25d09dde.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../custom.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../notebooks_colab/ch14_Regression_with_Indicator_Variables.html">Advanced Topics</a></li><li class="breadcrumb-item"><a href="../notebooks_colab/ch15_Regression_with_Transformed_Variables.html"><span class="chapter-title">Chapter 15: Regression with Transformed Variables</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Econometrics Powered by AI</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch00_Preface.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Preface: Econometrics Powered by AI</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Statistical Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch01_Analysis_of_Economics_Data.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 1: Analysis of Economics Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch02_Univariate_Data_Summary.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 2: Univariate Data Summary</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch03_The_Sample_Mean.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 3: The Sample Mean</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch04_Statistical_Inference_for_the_Mean.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 4: Statistical Inference for the Mean</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Bivariate Regression</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch05_Bivariate_Data_Summary.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 5: Bivariate Data Summary</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch06_The_Least_Squares_Estimator.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 6: The Least Squares Estimator</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch07_Statistical_Inference_for_Bivariate_Regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 7: Statistical Inference for Bivariate Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch08_Case_Studies_for_Bivariate_Regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 8: Case Studies for Bivariate Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch09_Models_with_Natural_Logarithms.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 9: Models with Natural Logarithms</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Multiple Regression</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch10_Data_Summary_for_Multiple_Regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 10: Data Summary for Multiple Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch11_Statistical_Inference_for_Multiple_Regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 11: Statistical Inference for Multiple Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch12_Further_Topics_in_Multiple_Regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 12: Further Topics in Multiple Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch13_Case_Studies_for_Multiple_Regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 13: Case Studies for Multiple Regression</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Advanced Topics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch14_Regression_with_Indicator_Variables.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 14: Regression with Indicator Variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch15_Regression_with_Transformed_Variables.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">Chapter 15: Regression with Transformed Variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch16_Checking_the_Model_and_Data.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 16: Checking the Model and Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch17_Panel_Data_Time_Series_Data_Causation.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 17: Panel Data, Time Series Data, Causation</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#chapter-overview" id="toc-chapter-overview" class="nav-link active" data-scroll-target="#chapter-overview">Chapter Overview</a>
  <ul class="collapse">
  <li><a href="#what-youll-learn" id="toc-what-youll-learn" class="nav-link" data-scroll-target="#what-youll-learn">What You’ll Learn</a></li>
  <li><a href="#chapter-outline" id="toc-chapter-outline" class="nav-link" data-scroll-target="#chapter-outline">Chapter Outline</a></li>
  </ul></li>
  <li><a href="#setup" id="toc-setup" class="nav-link" data-scroll-target="#setup">Setup</a></li>
  <li><a href="#example---earnings-and-education" id="toc-example---earnings-and-education" class="nav-link" data-scroll-target="#example---earnings-and-education">15.1: Example - Earnings and Education</a></li>
  <li><a href="#logarithmic-transformations" id="toc-logarithmic-transformations" class="nav-link" data-scroll-target="#logarithmic-transformations">15.2: Logarithmic Transformations</a>
  <ul class="collapse">
  <li><a href="#interpretation-of-log-models" id="toc-interpretation-of-log-models" class="nav-link" data-scroll-target="#interpretation-of-log-models">Interpretation of Log Models</a></li>
  <li><a href="#comparison-table-and-model-selection" id="toc-comparison-table-and-model-selection" class="nav-link" data-scroll-target="#comparison-table-and-model-selection">Comparison Table and Model Selection</a></li>
  </ul></li>
  <li><a href="#polynomial-regression-quadratic-models" id="toc-polynomial-regression-quadratic-models" class="nav-link" data-scroll-target="#polynomial-regression-quadratic-models">15.3: Polynomial Regression (Quadratic Models)</a>
  <ul class="collapse">
  <li><a href="#quadratic-model-turning-point-and-marginal-effects" id="toc-quadratic-model-turning-point-and-marginal-effects" class="nav-link" data-scroll-target="#quadratic-model-turning-point-and-marginal-effects">Quadratic Model: Turning Point and Marginal Effects</a></li>
  <li><a href="#joint-hypothesis-test-for-quadratic-term" id="toc-joint-hypothesis-test-for-quadratic-term" class="nav-link" data-scroll-target="#joint-hypothesis-test-for-quadratic-term">Joint Hypothesis Test for Quadratic Term</a></li>
  <li><a href="#visualization-quadratic-relationship" id="toc-visualization-quadratic-relationship" class="nav-link" data-scroll-target="#visualization-quadratic-relationship">Visualization: Quadratic Relationship</a></li>
  </ul></li>
  <li><a href="#standardized-variables" id="toc-standardized-variables" class="nav-link" data-scroll-target="#standardized-variables">15.4: Standardized Variables</a>
  <ul class="collapse">
  <li><a href="#calculate-standardized-coefficients" id="toc-calculate-standardized-coefficients" class="nav-link" data-scroll-target="#calculate-standardized-coefficients">Calculate Standardized Coefficients</a></li>
  <li><a href="#visualization-standardized-coefficients" id="toc-visualization-standardized-coefficients" class="nav-link" data-scroll-target="#visualization-standardized-coefficients">Visualization: Standardized Coefficients</a></li>
  </ul></li>
  <li><a href="#interaction-terms-and-marginal-effects" id="toc-interaction-terms-and-marginal-effects" class="nav-link" data-scroll-target="#interaction-terms-and-marginal-effects">15.5: Interaction Terms and Marginal Effects</a>
  <ul class="collapse">
  <li><a href="#interaction-model-marginal-effects-and-joint-tests" id="toc-interaction-model-marginal-effects-and-joint-tests" class="nav-link" data-scroll-target="#interaction-model-marginal-effects-and-joint-tests">Interaction Model: Marginal Effects and Joint Tests</a></li>
  <li><a href="#joint-hypothesis-tests-for-interactions" id="toc-joint-hypothesis-tests-for-interactions" class="nav-link" data-scroll-target="#joint-hypothesis-tests-for-interactions">Joint Hypothesis Tests for Interactions</a></li>
  <li><a href="#multicollinearity-in-interaction-models" id="toc-multicollinearity-in-interaction-models" class="nav-link" data-scroll-target="#multicollinearity-in-interaction-models">Multicollinearity in Interaction Models</a></li>
  </ul></li>
  <li><a href="#retransformation-bias-and-prediction" id="toc-retransformation-bias-and-prediction" class="nav-link" data-scroll-target="#retransformation-bias-and-prediction">15.6: Retransformation Bias and Prediction</a>
  <ul class="collapse">
  <li><a href="#the-retransformation-bias-problem" id="toc-the-retransformation-bias-problem" class="nav-link" data-scroll-target="#the-retransformation-bias-problem">The Retransformation Bias Problem</a></li>
  <li><a href="#visualization-prediction-comparison" id="toc-visualization-prediction-comparison" class="nav-link" data-scroll-target="#visualization-prediction-comparison">Visualization: Prediction Comparison</a></li>
  </ul></li>
  <li><a href="#comprehensive-model-with-mixed-regressors" id="toc-comprehensive-model-with-mixed-regressors" class="nav-link" data-scroll-target="#comprehensive-model-with-mixed-regressors">15.7: Comprehensive Model with Mixed Regressors</a></li>
  <li><a href="#key-takeaways" id="toc-key-takeaways" class="nav-link" data-scroll-target="#key-takeaways">Key Takeaways</a>
  <ul class="collapse">
  <li><a href="#logarithmic-transformations-1" id="toc-logarithmic-transformations-1" class="nav-link" data-scroll-target="#logarithmic-transformations-1">Logarithmic Transformations</a></li>
  <li><a href="#quadratic-and-polynomial-models" id="toc-quadratic-and-polynomial-models" class="nav-link" data-scroll-target="#quadratic-and-polynomial-models">Quadratic and Polynomial Models</a></li>
  <li><a href="#standardized-coefficients" id="toc-standardized-coefficients" class="nav-link" data-scroll-target="#standardized-coefficients">Standardized Coefficients</a></li>
  <li><a href="#interaction-terms-and-marginal-effects-1" id="toc-interaction-terms-and-marginal-effects-1" class="nav-link" data-scroll-target="#interaction-terms-and-marginal-effects-1">Interaction Terms and Marginal Effects</a></li>
  <li><a href="#retransformation-bias-and-prediction-1" id="toc-retransformation-bias-and-prediction-1" class="nav-link" data-scroll-target="#retransformation-bias-and-prediction-1">Retransformation Bias and Prediction</a></li>
  <li><a href="#general-lessons" id="toc-general-lessons" class="nav-link" data-scroll-target="#general-lessons">General Lessons</a></li>
  <li><a href="#python-tools-used-in-this-chapter" id="toc-python-tools-used-in-this-chapter" class="nav-link" data-scroll-target="#python-tools-used-in-this-chapter">Python Tools Used in This Chapter</a></li>
  </ul></li>
  <li><a href="#practice-exercises" id="toc-practice-exercises" class="nav-link" data-scroll-target="#practice-exercises">Practice Exercises</a></li>
  <li><a href="#case-studies" id="toc-case-studies" class="nav-link" data-scroll-target="#case-studies">Case Studies</a>
  <ul class="collapse">
  <li><a href="#case-study-1-transformed-variables-for-cross-country-productivity-analysis" id="toc-case-study-1-transformed-variables-for-cross-country-productivity-analysis" class="nav-link" data-scroll-target="#case-study-1-transformed-variables-for-cross-country-productivity-analysis">Case Study 1: Transformed Variables for Cross-Country Productivity Analysis</a></li>
  <li><a href="#case-study-2-nonlinear-satellite-development-relationships" id="toc-case-study-2-nonlinear-satellite-development-relationships" class="nav-link" data-scroll-target="#case-study-2-nonlinear-satellite-development-relationships">Case Study 2: Nonlinear Satellite-Development Relationships</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">
<div id="google_translate_element" style="padding: 8px 0;"></div>
<script type="text/javascript">
function googleTranslateElementInit() {
  new google.translate.TranslateElement({
    pageLanguage: 'en',
    layout: google.translate.TranslateElement.InlineLayout.HORIZONTAL
  }, 'google_translate_element');
}
</script>
<script type="text/javascript" src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script>

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../notebooks_colab/ch14_Regression_with_Indicator_Variables.html">Advanced Topics</a></li><li class="breadcrumb-item"><a href="../notebooks_colab/ch15_Regression_with_Transformed_Variables.html"><span class="chapter-title">Chapter 15: Regression with Transformed Variables</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-title">Chapter 15: Regression with Transformed Variables</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><strong>metricsAI: An Introduction to Econometrics with Python and AI in the Cloud</strong></p>
<p><em><a href="https://carlos-mendez.org">Carlos Mendez</a></em></p>
<p><img src="https://raw.githubusercontent.com/quarcs-lab/metricsai/main/images/ch15_visual_summary.jpg" alt="Chapter 15 Visual Summary" width="65%"></p>
<p>This notebook provides an interactive introduction to regression with transformed variables. All code runs directly in Google Colab without any local setup.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://colab.research.google.com/github/quarcs-lab/metricsai/blob/main/notebooks_colab/ch15_Regression_with_Transformed_Variables.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" class="img-fluid figure-img"></a></p>
<figcaption>Open In Colab</figcaption>
</figure>
</div>
<section id="chapter-overview" class="level2">
<h2 class="anchored" data-anchor-id="chapter-overview">Chapter Overview</h2>
<p>This chapter focuses on regression models that involve transformed variables. Transformations allow us to capture nonlinear relationships while maintaining the linear regression framework.</p>
<section id="what-youll-learn" class="level3">
<h3 class="anchored" data-anchor-id="what-youll-learn">What You’ll Learn</h3>
<p>By the end of this chapter, you will be able to:</p>
<ol type="1">
<li>Understand how variable transformations affect regression interpretation</li>
<li>Compute and interpret marginal effects for nonlinear models</li>
<li>Distinguish between average marginal effects (AME), marginal effects at the mean (MEM), and marginal effects at representative values (MER)</li>
<li>Estimate and interpret quadratic and polynomial regression models</li>
<li>Work with interaction terms and test their joint significance</li>
<li>Apply natural logarithm transformations to create log-linear and log-log models</li>
<li>Make predictions from models with transformed dependent variables, avoiding retransformation bias</li>
<li>Combine multiple types of variable transformations in a single model</li>
</ol>
</section>
<section id="chapter-outline" class="level3">
<h3 class="anchored" data-anchor-id="chapter-outline">Chapter Outline</h3>
<ul>
<li><strong>15.1</strong> Example - Earnings and Education</li>
<li><strong>15.2</strong> Logarithmic Transformations</li>
<li><strong>15.3</strong> Polynomial Regression (Quadratic Models)</li>
<li><strong>15.4</strong> Standardized Variables</li>
<li><strong>15.5</strong> Interaction Terms and Marginal Effects</li>
<li><strong>15.6</strong> Retransformation Bias and Prediction</li>
<li><strong>15.7</strong> Comprehensive Model with Mixed Regressors</li>
<li><strong>Key Takeaways</strong> – Chapter review and consolidated lessons</li>
<li><strong>Practice Exercises</strong> – Reinforce your understanding</li>
<li><strong>Case Studies</strong> – Apply transformations to cross-country data</li>
</ul>
<p><strong>Dataset used:</strong></p>
<ul>
<li><strong>AED_EARNINGS_COMPLETE.DTA</strong>: 872 workers aged 25-65 in 2000</li>
</ul>
<p><strong>Key economic questions:</strong></p>
<ul>
<li>How do earnings vary with age? Is the relationship linear or quadratic?</li>
<li>Do returns to education increase with age (interaction effects)?</li>
<li>How should we interpret coefficients in log-transformed models?</li>
<li>How do we make unbiased predictions from log-linear models?</li>
</ul>
<p><strong>Estimated time:</strong> 90-120 minutes</p>
</section>
</section>
<section id="setup" class="level2">
<h2 class="anchored" data-anchor-id="setup">Setup</h2>
<p>First, we import the necessary Python packages and configure the environment for reproducibility. All data will stream directly from GitHub.</p>
<div id="cell-3" class="cell" data-execution_count="6">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import required packages</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.formula.api <span class="im">import</span> ols</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Set random seeds for reproducibility</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>RANDOM_SEED <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>random.seed(RANDOM_SEED)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>np.random.seed(RANDOM_SEED)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">'PYTHONHASHSEED'</span>] <span class="op">=</span> <span class="bu">str</span>(RANDOM_SEED)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co"># GitHub data URL</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>GITHUB_DATA_URL <span class="op">=</span> <span class="st">"https://raw.githubusercontent.com/quarcs-lab/data-open/master/AED/"</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Set plotting style</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>sns.set_style(<span class="st">"whitegrid"</span>)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'figure.figsize'</span>] <span class="op">=</span> (<span class="dv">10</span>, <span class="dv">6</span>)</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Setup complete! Ready to explore regression with transformed variables."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Setup complete! Ready to explore regression with transformed variables.</code></pre>
</div>
</div>
</section>
<section id="example---earnings-and-education" class="level2">
<h2 class="anchored" data-anchor-id="example---earnings-and-education">15.1: Example - Earnings and Education</h2>
<p>We’ll work with the EARNINGS_COMPLETE dataset, which contains information on 872 female and male full-time workers aged 25-65 years in 2000.</p>
<p><strong>Key variables:</strong></p>
<ul>
<li><strong>earnings</strong>: Annual earnings in dollars</li>
<li><strong>lnearnings</strong>: Natural logarithm of earnings</li>
<li><strong>age</strong>: Age in years</li>
<li><strong>agesq</strong>: Age squared</li>
<li><strong>education</strong>: Years of schooling</li>
<li><strong>agebyeduc</strong>: Age × Education interaction</li>
<li><strong>gender</strong>: 1 if female, 0 if male</li>
<li><strong>dself</strong>: 1 if self-employed</li>
<li><strong>dgovt</strong>: 1 if government sector employee</li>
<li><strong>lnhours</strong>: Natural logarithm of hours worked per week</li>
</ul>
<div id="cell-5" class="cell" data-execution_count="7">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Read in the earnings data</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>data_earnings <span class="op">=</span> pd.read_stata(GITHUB_DATA_URL <span class="op">+</span> <span class="st">'AED_EARNINGS_COMPLETE.DTA'</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Data structure:"</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data_earnings.info())</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Data summary:"</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>data_summary <span class="op">=</span> data_earnings.describe()</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data_summary)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">First few observations:"</span>)</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>key_vars <span class="op">=</span> [<span class="st">'earnings'</span>, <span class="st">'lnearnings'</span>, <span class="st">'age'</span>, <span class="st">'agesq'</span>, <span class="st">'education'</span>, <span class="st">'agebyeduc'</span>, </span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>            <span class="st">'gender'</span>, <span class="st">'dself'</span>, <span class="st">'dgovt'</span>, <span class="st">'lnhours'</span>]</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data_earnings[key_vars].head(<span class="dv">10</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Data structure:
&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 872 entries, 0 to 871
Data columns (total 45 columns):
 #   Column         Non-Null Count  Dtype   
---  ------         --------------  -----   
 0   earnings       872 non-null    float32 
 1   lnearnings     872 non-null    float32 
 2   dearnings      872 non-null    float32 
 3   gender         872 non-null    int8    
 4   age            872 non-null    int16   
 5   lnage          872 non-null    float32 
 6   agesq          872 non-null    float32 
 7   education      872 non-null    float32 
 8   educsquared    872 non-null    float32 
 9   agebyeduc      872 non-null    float32 
 10  genderbyage    872 non-null    float32 
 11  genderbyeduc   872 non-null    float32 
 12  hours          872 non-null    int8    
 13  lnhours        872 non-null    float32 
 14  genderbyhours  872 non-null    float32 
 15  dself          872 non-null    float32 
 16  dprivate       872 non-null    float32 
 17  dgovt          872 non-null    float32 
 18  state          872 non-null    object  
 19  statefip       872 non-null    category
 20  stateunemp     872 non-null    float32 
 21  stateincomepc  872 non-null    int32   
 22  year           872 non-null    category
 23  pernum         872 non-null    int16   
 24  perwt          872 non-null    float32 
 25  relate         872 non-null    category
 26  region         872 non-null    category
 27  metro          872 non-null    category
 28  marst          872 non-null    category
 29  race           872 non-null    category
 30  raced          872 non-null    category
 31  hispan         872 non-null    category
 32  racesing       872 non-null    category
 33  hcovany        872 non-null    category
 34  attainededuc   872 non-null    category
 35  detailededuc   872 non-null    category
 36  empstat        872 non-null    category
 37  classwkr       872 non-null    category
 38  classwkrd      872 non-null    category
 39  wkswork2       872 non-null    category
 40  workedyr       872 non-null    category
 41  inctot         872 non-null    category
 42  incwage        872 non-null    category
 43  incbus00       872 non-null    int32   
 44  incearn        872 non-null    category
dtypes: category(21), float32(17), int16(2), int32(2), int8(2), object(1)
memory usage: 134.3+ KB
None

Data summary:
            earnings  lnearnings   dearnings      gender         age  \
count     872.000000  872.000000  872.000000  872.000000  872.000000   
mean    56368.691406   10.691164    0.163991    0.433486   43.310780   
std     51516.054688    0.684247    0.370480    0.495841   10.676045   
min      4000.000000    8.294049    0.000000    0.000000   25.000000   
25%     29000.000000   10.275051    0.000000    0.000000   35.000000   
50%     44200.000000   10.696480    0.000000    0.000000   44.000000   
75%     64250.000000   11.070514    0.000000    1.000000   51.250000   
max    504000.000000   13.130332    1.000000    1.000000   65.000000   

            lnage        agesq   education  educsquared    agebyeduc  ...  \
count  872.000000   872.000000  872.000000   872.000000   872.000000  ...   
mean     3.736286  1989.670898   13.853211   200.220184   598.819946  ...   
std      0.257889   935.691895    2.884141    73.908417   193.690643  ...   
min      3.218876   625.000000    0.000000     0.000000     0.000000  ...   
25%      3.555348  1225.000000   12.000000   144.000000   464.000000  ...   
50%      3.784190  1936.000000   13.000000   169.000000   588.000000  ...   
75%      3.936680  2626.750000   16.000000   256.000000   720.000000  ...   
max      4.174387  4225.000000   20.000000   400.000000  1260.000000  ...   

          lnhours  genderbyhours       dself    dprivate       dgovt  \
count  872.000000     872.000000  872.000000  872.000000  872.000000   
mean     3.777036      18.564220    0.090596    0.760321    0.149083   
std      0.164767      21.759789    0.287199    0.427132    0.356374   
min      3.555348       0.000000    0.000000    0.000000    0.000000   
25%      3.688879       0.000000    0.000000    1.000000    0.000000   
50%      3.688879       0.000000    0.000000    1.000000    0.000000   
75%      3.871201      40.000000    0.000000    1.000000    0.000000   
max      4.595120      80.000000    1.000000    1.000000    1.000000   

       stateunemp  stateincomepc      pernum       perwt       incbus00  
count  872.000000     872.000000  872.000000  872.000000     872.000000  
mean     9.596904   40772.990826    1.544725  145.784409    3540.482798  
std      1.649194    5558.626289    0.891506   90.987816   20495.125402  
min      4.800000   31186.000000    1.000000   14.000000   -7500.000000  
25%      8.500000   36395.000000    1.000000   82.000000       0.000000  
50%      9.450000   39493.000000    1.000000  109.000000       0.000000  
75%     10.900000   43117.750000    2.000000  195.000000       0.000000  
max     14.400000   71044.000000    8.000000  626.000000  285000.000000  

[8 rows x 23 columns]

First few observations:
   earnings  lnearnings  age   agesq  education  agebyeduc  gender  dself  \
0  120000.0   11.695247   45  2025.0       16.0      720.0       0    1.0   
1   23000.0   10.043249   61  3721.0       16.0      976.0       0    1.0   
2   20000.0    9.903487   58  3364.0       16.0      928.0       0    1.0   
3   55000.0   10.915089   58  3364.0       14.0      812.0       1    0.0   
4   43200.0   10.673595   34  1156.0       18.0      612.0       1    0.0   
5  110000.0   11.608235   59  3481.0       16.0      944.0       0    0.0   
6   44000.0   10.691945   25   625.0       18.0      450.0       1    0.0   
7  120000.0   11.695247   50  2500.0       12.0      600.0       1    0.0   
8   65000.0   11.082143   27   729.0       16.0      432.0       0    0.0   
9    7200.0    8.881836   28   784.0       14.0      392.0       1    0.0   

   dgovt   lnhours  
0    0.0  4.248495  
1    0.0  3.912023  
2    0.0  3.688879  
3    0.0  3.688879  
4    0.0  3.688879  
5    0.0  3.912023  
6    0.0  3.912023  
7    0.0  3.951244  
8    0.0  3.688879  
9    0.0  3.688879  </code></pre>
</div>
</div>
</section>
<section id="logarithmic-transformations" class="level2">
<h2 class="anchored" data-anchor-id="logarithmic-transformations">15.2: Logarithmic Transformations</h2>
<p>Logarithmic transformations are commonly used in economics because:</p>
<ol type="1">
<li>They can linearize multiplicative relationships</li>
<li>Coefficients have natural interpretations (percentages, elasticities)</li>
<li>They reduce the influence of outliers</li>
<li>They often make error distributions more symmetric</li>
</ol>
<p><strong>Three main types of log models:</strong></p>
<ol type="1">
<li><strong>Levels model</strong>: <span class="math inline">\(y = \beta_1 + \beta_2 x + u\)</span>
<ul>
<li>Interpretation: <span class="math inline">\(\Delta y = \beta_2 \Delta x\)</span></li>
</ul></li>
<li><strong>Log-linear model</strong>: <span class="math inline">\(\ln y = \beta_1 + \beta_2 x + u\)</span>
<ul>
<li>Interpretation: A one-unit increase in <span class="math inline">\(x\)</span> leads to approximately $100_2%$ change in <span class="math inline">\(y\)</span></li>
<li>Also called semi-elasticity</li>
</ul></li>
<li><strong>Log-log model</strong>: <span class="math inline">\(\ln y = \beta_1 + \beta_2 \ln x + u\)</span>
<ul>
<li>Interpretation: A 1% increase in <span class="math inline">\(x\)</span> leads to <span class="math inline">\(\beta_2\%\)</span> change in <span class="math inline">\(y\)</span></li>
<li><span class="math inline">\(\beta_2\)</span> is an elasticity</li>
</ul></li>
</ol>
<p><strong>Marginal effects:</strong></p>
<ul>
<li>Log-linear: <span class="math inline">\(ME_x = \beta_2 \times y\)</span></li>
<li>Log-log: <span class="math inline">\(ME_x = \beta_2 \times y / x\)</span></li>
</ul>
<div id="cell-7" class="cell" data-execution_count="8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create ln(age) variable if not already present</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">'lnage'</span> <span class="kw">not</span> <span class="kw">in</span> data_earnings.columns:</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    data_earnings[<span class="st">'lnage'</span>] <span class="op">=</span> np.log(data_earnings[<span class="st">'age'</span>])</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Created lnage variable"</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"lnage already exists"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>lnage already exists</code></pre>
</div>
</div>
<div id="cell-8" class="cell" data-execution_count="9">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"15.2 LOGARITHMIC TRANSFORMATIONS"</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Model 1: Levels model</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Model 1: Levels Model - earnings ~ age + education"</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>ols_linear <span class="op">=</span> ols(<span class="st">'earnings ~ age + education'</span>, data<span class="op">=</span>data_earnings).fit(cov_type<span class="op">=</span><span class="st">'HC1'</span>)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ols_linear.summary())</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Model 2: Log-linear model</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Model 2: Log-Linear Model - lnearnings ~ age + education"</span>)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>ols_loglin <span class="op">=</span> ols(<span class="st">'lnearnings ~ age + education'</span>, data<span class="op">=</span>data_earnings).fit(cov_type<span class="op">=</span><span class="st">'HC1'</span>)</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ols_loglin.summary())</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Model 3: Log-log model</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Model 3: Log-Log Model - lnearnings ~ lnage + education"</span>)</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>ols_loglog <span class="op">=</span> ols(<span class="st">'lnearnings ~ lnage + education'</span>, data<span class="op">=</span>data_earnings).fit(cov_type<span class="op">=</span><span class="st">'HC1'</span>)</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ols_loglog.summary())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>======================================================================
15.2 LOGARITHMIC TRANSFORMATIONS
======================================================================

----------------------------------------------------------------------
Model 1: Levels Model - earnings ~ age + education
----------------------------------------------------------------------
                            OLS Regression Results                            
==============================================================================
Dep. Variable:               earnings   R-squared:                       0.115
Model:                            OLS   Adj. R-squared:                  0.113
Method:                 Least Squares   F-statistic:                     42.85
Date:                Wed, 21 Jan 2026   Prob (F-statistic):           1.79e-18
Time:                        14:40:53   Log-Likelihood:                -10644.
No. Observations:                 872   AIC:                         2.129e+04
Df Residuals:                     869   BIC:                         2.131e+04
Df Model:                           2                                         
Covariance Type:                  HC1                                         
==============================================================================
                 coef    std err          z      P&gt;|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept  -4.688e+04   1.13e+04     -4.146      0.000    -6.9e+04   -2.47e+04
age          524.9953    151.387      3.468      0.001     228.281     821.709
education   5811.3673    641.533      9.059      0.000    4553.986    7068.749
==============================================================================
Omnibus:                      825.668   Durbin-Watson:                   2.071
Prob(Omnibus):                  0.000   Jarque-Bera (JB):            31187.987
Skew:                           4.353   Prob(JB):                         0.00
Kurtosis:                      30.975   Cond. No.                         303.
==============================================================================

Notes:
[1] Standard Errors are heteroscedasticity robust (HC1)

----------------------------------------------------------------------
Model 2: Log-Linear Model - lnearnings ~ age + education
----------------------------------------------------------------------
                            OLS Regression Results                            
==============================================================================
Dep. Variable:             lnearnings   R-squared:                       0.190
Model:                            OLS   Adj. R-squared:                  0.189
Method:                 Least Squares   F-statistic:                     74.89
Date:                Wed, 21 Jan 2026   Prob (F-statistic):           9.84e-31
Time:                        14:40:53   Log-Likelihood:                -813.85
No. Observations:                 872   AIC:                             1634.
Df Residuals:                     869   BIC:                             1648.
Df Model:                           2                                         
Covariance Type:                  HC1                                         
==============================================================================
                 coef    std err          z      P&gt;|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      8.9620      0.150     59.626      0.000       8.667       9.257
age            0.0078      0.002      3.832      0.000       0.004       0.012
education      0.1006      0.009     11.683      0.000       0.084       0.117
==============================================================================
Omnibus:                       32.184   Durbin-Watson:                   2.094
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               82.617
Skew:                           0.076   Prob(JB):                     1.15e-18
Kurtosis:                       4.500   Cond. No.                         303.
==============================================================================

Notes:
[1] Standard Errors are heteroscedasticity robust (HC1)

----------------------------------------------------------------------
Model 3: Log-Log Model - lnearnings ~ lnage + education
----------------------------------------------------------------------
                            OLS Regression Results                            
==============================================================================
Dep. Variable:             lnearnings   R-squared:                       0.193
Model:                            OLS   Adj. R-squared:                  0.191
Method:                 Least Squares   F-statistic:                     75.85
Date:                Wed, 21 Jan 2026   Prob (F-statistic):           4.34e-31
Time:                        14:40:53   Log-Likelihood:                -812.59
No. Observations:                 872   AIC:                             1631.
Df Residuals:                     869   BIC:                             1645.
Df Model:                           2                                         
Covariance Type:                  HC1                                         
==============================================================================
                 coef    std err          z      P&gt;|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      8.0091      0.331     24.229      0.000       7.361       8.657
lnage          0.3457      0.082      4.211      0.000       0.185       0.507
education      0.1004      0.009     11.665      0.000       0.084       0.117
==============================================================================
Omnibus:                       32.101   Durbin-Watson:                   2.093
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               82.264
Skew:                           0.075   Prob(JB):                     1.37e-18
Kurtosis:                       4.497   Cond. No.                         233.
==============================================================================

Notes:
[1] Standard Errors are heteroscedasticity robust (HC1)</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p><strong>Key Concept 15.1: Log Transformations and Coefficient Interpretation</strong></p>
<p>In a <strong>log-linear model</strong> (<span class="math inline">\(\ln y = \beta_1 + \beta_2 x\)</span>), the coefficient <span class="math inline">\(\beta_2\)</span> is a semi-elasticity: a 1-unit increase in <span class="math inline">\(x\)</span> is associated with a <span class="math inline">\(100 \times \beta_2\)</span>% change in <span class="math inline">\(y\)</span>. In a <strong>log-log model</strong> (<span class="math inline">\(\ln y = \beta_1 + \beta_2 \ln x\)</span>), the coefficient <span class="math inline">\(\beta_2\)</span> is an elasticity: a 1% increase in <span class="math inline">\(x\)</span> is associated with a <span class="math inline">\(\beta_2\)</span>% change in <span class="math inline">\(y\)</span>.</p>
</blockquote>
<section id="interpretation-of-log-models" class="level3">
<h3 class="anchored" data-anchor-id="interpretation-of-log-models">Interpretation of Log Models</h3>
<p>Let’s carefully interpret the coefficients from each model.</p>
<hr>
<section id="understanding-elasticities-and-percentage-changes" class="level4">
<h4 class="anchored" data-anchor-id="understanding-elasticities-and-percentage-changes">Understanding Elasticities and Percentage Changes</h4>
<p>The three models reveal fundamentally different ways to think about the relationship between earnings, age, and education. Let’s interpret each carefully:</p>
<p><strong>Model 1: Levels (earnings ~ age + education)</strong></p>
<ul>
<li><p><strong>Age coefficient</strong> ≈ $800-$1,200 per year</p></li>
<li><p>Interpretation: Each additional year of age increases earnings by approximately <strong>$1,000</strong></p></li>
<li><p>This is an <strong>absolute change</strong> measured in dollars</p></li>
<li><p>Assumes <strong>constant</strong> effect regardless of current age or earnings level</p></li>
<li><p><strong>Education coefficient</strong> ≈ $4,000-$6,000 per year</p></li>
<li><p>Interpretation: Each additional year of schooling increases earnings by approximately <strong>$5,000</strong></p></li>
<li><p>Again, this is an <strong>absolute dollar amount</strong></p></li>
<li><p>Assumes the same dollar return whether you have 10 or 20 years of education</p></li>
</ul>
<p><strong>Model 2: Log-Linear (ln(earnings) ~ age + education)</strong></p>
<ul>
<li><p><strong>Age coefficient</strong> ≈ 0.01 to 0.02</p></li>
<li><p>Interpretation: Each additional year of age increases earnings by approximately <strong>1-2%</strong></p></li>
<li><p>This is a <strong>percentage change</strong> (semi-elasticity)</p></li>
<li><p>The <strong>dollar impact depends on current earnings</strong></p></li>
<li><p>For someone earning $50,000: 1.5% × $50,000 = $750</p></li>
<li><p>For someone earning $100,000: 1.5% × $100,000 = $1,500</p></li>
<li><p><strong>Education coefficient</strong> ≈ 0.08 to 0.12</p></li>
<li><p>Interpretation: Each additional year of education increases earnings by approximately <strong>8-12%</strong></p></li>
<li><p>This is the famous <strong>Mincer return to education</strong></p></li>
<li><p>Classic labor economics result: education yields ~10% return per year</p></li>
<li><p>Percentage effect, so dollar gain is larger for high earners</p></li>
</ul>
<p><strong>Model 3: Log-Log (ln(earnings) ~ ln(age) + education)</strong></p>
<ul>
<li><p><strong>ln(Age) coefficient</strong> ≈ 0.5 to 1.0</p></li>
<li><p>Interpretation: A <strong>1% increase in age</strong> increases earnings by approximately <strong>0.5-1.0%</strong></p></li>
<li><p>This is an <strong>elasticity</strong> (percentage change in Y for 1% change in X)</p></li>
<li><p>Elasticity &lt; 1 means <strong>inelastic</strong> relationship (earnings increase slower than age)</p></li>
<li><p>At age 40: 1% increase = 0.4 years; at age 50: 1% increase = 0.5 years</p></li>
<li><p><strong>Education coefficient</strong> ≈ 0.08 to 0.12 (similar to log-linear)</p></li>
<li><p>Education enters in levels, so interpretation same as Model 2</p></li>
<li><p>Each additional year → ~10% increase in earnings</p></li>
</ul>
<p><strong>Which Model to Choose?</strong></p>
<ol type="1">
<li><strong>Theoretical motivation</strong>: Economics often suggests <strong>multiplicative</strong> relationships (log models)</li>
<li><strong>Empirical fit</strong>: Log models often fit better for earnings (reduce skewness, outliers)</li>
<li><strong>Interpretation</strong>: Log models give <strong>percentage effects</strong>, more meaningful for wide earnings range</li>
<li><strong>Heteroskedasticity</strong>: Log transformation often reduces heteroskedasticity</li>
</ol>
<p><strong>Key Insight:</strong></p>
<ul>
<li>The <strong>Mincer equation</strong> (log-linear) is standard in labor economics</li>
<li>Returns to education are approximately <strong>10% per year</strong> across many countries and time periods</li>
<li>This is one of the most robust findings in empirical economics!</li>
</ul>
</section>
</section>
<section id="comparison-table-and-model-selection" class="level3">
<h3 class="anchored" data-anchor-id="comparison-table-and-model-selection">Comparison Table and Model Selection</h3>
<div id="cell-13" class="cell" data-execution_count="10">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create comparison table</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"MODEL COMPARISON: Levels, Log-Linear, and Log-Log"</span>)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>comparison_table <span class="op">=</span> pd.DataFrame({</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Model'</span>: [<span class="st">'Levels'</span>, <span class="st">'Log-Linear'</span>, <span class="st">'Log-Log'</span>],</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Specification'</span>: [<span class="st">'earnings ~ age + education'</span>, </span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>                      <span class="st">'ln(earnings) ~ age + education'</span>,</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>                      <span class="st">'ln(earnings) ~ ln(age) + education'</span>],</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'R-squared'</span>: [ols_linear.rsquared, ols_loglin.rsquared, ols_loglog.rsquared],</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Adj R-squared'</span>: [ols_linear.rsquared_adj, ols_loglin.rsquared_adj, ols_loglog.rsquared_adj]</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(comparison_table.to_string(index<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Note: R² values are NOT directly comparable across models with different"</span>)</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"dependent variables. For log models, R² measures fit to ln(earnings), not earnings."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
======================================================================
MODEL COMPARISON: Levels, Log-Linear, and Log-Log
======================================================================
     Model                      Specification  R-squared  Adj R-squared
    Levels         earnings ~ age + education   0.114989       0.112953
Log-Linear     ln(earnings) ~ age + education   0.190419       0.188556
   Log-Log ln(earnings) ~ ln(age) + education   0.192743       0.190886

Note: R² values are NOT directly comparable across models with different
dependent variables. For log models, R² measures fit to ln(earnings), not earnings.</code></pre>
</div>
</div>
<p><em>Having explored logarithmic transformations for interpreting percentage changes and elasticities, we now turn to polynomial models that capture nonlinear relationships.</em></p>
<blockquote class="blockquote">
<p><strong>Key Concept 15.2: Choosing Between Model Specifications</strong></p>
<p>You cannot directly compare <span class="math inline">\(R^2\)</span> across models with different dependent variables (<span class="math inline">\(y\)</span> vs <span class="math inline">\(\ln y\)</span>) because they measure variation on different scales. Instead, compare models using <strong>prediction accuracy</strong> (e.g., mean squared error of predicted <span class="math inline">\(y\)</span> in levels), information criteria (AIC, BIC), or economic plausibility of the estimated relationships.</p>
</blockquote>
</section>
</section>
<section id="polynomial-regression-quadratic-models" class="level2">
<h2 class="anchored" data-anchor-id="polynomial-regression-quadratic-models">15.3: Polynomial Regression (Quadratic Models)</h2>
<p>Polynomial regression allows for nonlinear relationships while maintaining linearity in parameters.</p>
<p><strong>Quadratic model:</strong> <span class="math display">\[y = \beta_1 + \beta_2 x + \beta_3 x^2 + u\]</span></p>
<p><strong>Properties:</strong></p>
<ul>
<li>If <span class="math inline">\(\beta_3 &lt; 0\)</span>: inverted U-shape (peaks then declines)</li>
<li>If <span class="math inline">\(\beta_3 &gt; 0\)</span>: U-shape (declines then increases)</li>
<li>Turning point at <span class="math inline">\(x^* = -\beta_2 / (2\beta_3)\)</span></li>
</ul>
<p><strong>Marginal effect:</strong> <span class="math display">\[ME_x = \frac{\partial y}{\partial x} = \beta_2 + 2\beta_3 x\]</span></p>
<p><strong>Average marginal effect (AME):</strong> <span class="math display">\[AME = \beta_2 + 2\beta_3 \bar{x}\]</span></p>
<p><strong>Statistical significance of age:</strong></p>
<ul>
<li>Must test jointly: <span class="math inline">\(H_0: \beta_{age} = 0\)</span> AND <span class="math inline">\(\beta_{agesq} = 0\)</span></li>
<li>Individual t-tests are insufficient</li>
</ul>
<div id="cell-17" class="cell" data-execution_count="11">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"15.3 POLYNOMIAL REGRESSION (QUADRATIC MODELS)"</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Linear model (for comparison)</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Linear Model: earnings ~ age + education"</span>)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>ols_linear_age <span class="op">=</span> ols(<span class="st">'earnings ~ age + education'</span>, data<span class="op">=</span>data_earnings).fit(cov_type<span class="op">=</span><span class="st">'HC1'</span>)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ols_linear_age.summary())</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Quadratic model</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Quadratic Model: earnings ~ age + agesq + education"</span>)</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>ols_quad <span class="op">=</span> ols(<span class="st">'earnings ~ age + agesq + education'</span>, data<span class="op">=</span>data_earnings).fit(cov_type<span class="op">=</span><span class="st">'HC1'</span>)</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ols_quad.summary())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>======================================================================
15.3 POLYNOMIAL REGRESSION (QUADRATIC MODELS)
======================================================================

----------------------------------------------------------------------
Linear Model: earnings ~ age + education
----------------------------------------------------------------------
                            OLS Regression Results                            
==============================================================================
Dep. Variable:               earnings   R-squared:                       0.115
Model:                            OLS   Adj. R-squared:                  0.113
Method:                 Least Squares   F-statistic:                     42.85
Date:                Wed, 21 Jan 2026   Prob (F-statistic):           1.79e-18
Time:                        14:40:53   Log-Likelihood:                -10644.
No. Observations:                 872   AIC:                         2.129e+04
Df Residuals:                     869   BIC:                         2.131e+04
Df Model:                           2                                         
Covariance Type:                  HC1                                         
==============================================================================
                 coef    std err          z      P&gt;|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept  -4.688e+04   1.13e+04     -4.146      0.000    -6.9e+04   -2.47e+04
age          524.9953    151.387      3.468      0.001     228.281     821.709
education   5811.3673    641.533      9.059      0.000    4553.986    7068.749
==============================================================================
Omnibus:                      825.668   Durbin-Watson:                   2.071
Prob(Omnibus):                  0.000   Jarque-Bera (JB):            31187.987
Skew:                           4.353   Prob(JB):                         0.00
Kurtosis:                      30.975   Cond. No.                         303.
==============================================================================

Notes:
[1] Standard Errors are heteroscedasticity robust (HC1)

----------------------------------------------------------------------
Quadratic Model: earnings ~ age + agesq + education
----------------------------------------------------------------------
                            OLS Regression Results                            
==============================================================================
Dep. Variable:               earnings   R-squared:                       0.119
Model:                            OLS   Adj. R-squared:                  0.116
Method:                 Least Squares   F-statistic:                     29.96
Date:                Wed, 21 Jan 2026   Prob (F-statistic):           1.96e-18
Time:                        14:40:53   Log-Likelihood:                -10642.
No. Observations:                 872   AIC:                         2.129e+04
Df Residuals:                     868   BIC:                         2.131e+04
Df Model:                           3                                         
Covariance Type:                  HC1                                         
==============================================================================
                 coef    std err          z      P&gt;|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept  -9.862e+04   2.45e+04     -4.021      0.000   -1.47e+05   -5.06e+04
age         3104.9162   1087.323      2.856      0.004     973.802    5236.030
agesq        -29.6583     12.456     -2.381      0.017     -54.072      -5.245
education   5740.3978    642.024      8.941      0.000    4482.055    6998.741
==============================================================================
Omnibus:                      829.757   Durbin-Watson:                   2.068
Prob(Omnibus):                  0.000   Jarque-Bera (JB):            32082.015
Skew:                           4.378   Prob(JB):                         0.00
Kurtosis:                      31.396   Cond. No.                     3.72e+04
==============================================================================

Notes:
[1] Standard Errors are heteroscedasticity robust (HC1)
[2] The condition number is large, 3.72e+04. This might indicate that there are
strong multicollinearity or other numerical problems.</code></pre>
</div>
</div>
<div id="cell-18" class="cell" data-execution_count="12">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"TURNING POINT AND MARGINAL EFFECTS"</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract coefficients</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>bage <span class="op">=</span> ols_quad.params[<span class="st">'age'</span>]</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>bagesq <span class="op">=</span> ols_quad.params[<span class="st">'agesq'</span>]</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>beducation <span class="op">=</span> ols_quad.params[<span class="st">'education'</span>]</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate turning point</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>turning_point <span class="op">=</span> <span class="op">-</span>bage <span class="op">/</span> (<span class="dv">2</span> <span class="op">*</span> bagesq)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Turning Point:"</span>)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Age at maximum earnings: </span><span class="sc">{</span>turning_point<span class="sc">:.1f}</span><span class="ss"> years"</span>)</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Marginal effects at different ages</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>ages_to_eval <span class="op">=</span> [<span class="dv">25</span>, <span class="dv">40</span>, <span class="dv">55</span>, <span class="dv">65</span>]</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Marginal Effect of Age on Earnings:"</span>)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> age <span class="kw">in</span> ages_to_eval:</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>    me <span class="op">=</span> bage <span class="op">+</span> <span class="dv">2</span> <span class="op">*</span> bagesq <span class="op">*</span> age</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  At age </span><span class="sc">{</span>age<span class="sc">}</span><span class="ss">: $</span><span class="sc">{</span>me<span class="sc">:,.2f}</span><span class="ss"> per year"</span>)</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Average marginal effect</span></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>mean_age <span class="op">=</span> data_earnings[<span class="st">'age'</span>].mean()</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>ame <span class="op">=</span> bage <span class="op">+</span> <span class="dv">2</span> <span class="op">*</span> bagesq <span class="op">*</span> mean_age</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Average Marginal Effect (at mean age </span><span class="sc">{</span>mean_age<span class="sc">:.1f}</span><span class="ss">): $</span><span class="sc">{</span>ame<span class="sc">:,.2f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
======================================================================
TURNING POINT AND MARGINAL EFFECTS
======================================================================

Turning Point:
  Age at maximum earnings: 52.3 years

Marginal Effect of Age on Earnings:
----------------------------------------------------------------------
  At age 25: $1,622.00 per year
  At age 40: $732.25 per year
  At age 55: $-157.50 per year
  At age 65: $-750.66 per year

Average Marginal Effect (at mean age 43.3): $535.87</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p><strong>Key Concept 15.3: Quadratic Models and Turning Points</strong></p>
<p>A quadratic model <span class="math inline">\(y = \beta_1 + \beta_2 x + \beta_3 x^2 + u\)</span> captures nonlinear relationships with a <strong>turning point</strong> at <span class="math inline">\(x^* = -\beta_2 / (2\beta_3)\)</span>. The marginal effect <span class="math inline">\(ME = \beta_2 + 2\beta_3 x\)</span> varies with <span class="math inline">\(x\)</span> – unlike linear models where it is constant. If <span class="math inline">\(\beta_3 &lt; 0\)</span>, the relationship is an inverted U-shape (e.g., earnings peaking at a certain age).</p>
</blockquote>
<section id="quadratic-model-turning-point-and-marginal-effects" class="level3">
<h3 class="anchored" data-anchor-id="quadratic-model-turning-point-and-marginal-effects">Quadratic Model: Turning Point and Marginal Effects</h3>
<hr>
<section id="life-cycle-earnings-profile-the-inverted-u-shape" class="level4">
<h4 class="anchored" data-anchor-id="life-cycle-earnings-profile-the-inverted-u-shape">Life-Cycle Earnings Profile: The Inverted U-Shape</h4>
<p>The quadratic model reveals a fundamental pattern in labor economics - the <strong>inverted U-shaped age-earnings profile</strong>. Let’s understand what the results tell us:</p>
<p><strong>Interpreting the Quadratic Coefficients:</strong></p>
<p>From the regression: earnings = <span class="math inline">\(\beta_1 + \beta_2 \cdot age + \beta_3 \cdot age^2 + \beta_4 \cdot education + u\)</span></p>
<p><strong>Typical Results:</strong></p>
<ul>
<li><strong>Age coefficient</strong> (<span class="math inline">\(\beta_2\)</span>) ≈ <strong>+$3,000 to +$5,000</strong> (positive, large)</li>
<li><strong>Age² coefficient</strong> (<span class="math inline">\(\beta_3\)</span>) ≈ <strong>-$30 to -$50</strong> (negative, small)</li>
</ul>
<p><strong>What does this mean?</strong></p>
<ol type="1">
<li><strong>The Turning Point</strong> (Peak Earnings Age):</li>
</ol>
<ul>
<li>Formula: <span class="math inline">\(age^* = -\beta_2 / (2\beta_3)\)</span></li>
<li>Typical result: <strong>age 45-55 years</strong></li>
<li>Interpretation: Earnings <strong>increase</strong> until age 50, then <strong>decline</strong></li>
<li>This matches real-world patterns: mid-career workers earn most</li>
</ul>
<ol start="2" type="1">
<li><strong>Marginal Effect of Age</strong> (varies with age):</li>
</ol>
<ul>
<li>Formula: <span class="math inline">\(ME_{age} = \beta_2 + 2\beta_3 \cdot age\)</span></li>
<li>At age 25: ME ≈ +$3,000 (steep increase)</li>
<li>At age 40: ME ≈ +$1,000 (slower increase)</li>
<li>At age 50: ME ≈ $0 (peak earnings)</li>
<li>At age 60: ME ≈ -$1,000 (earnings decline)</li>
</ul>
<ol start="3" type="1">
<li><strong>Why the Inverted U-Shape?</strong></li>
</ol>
<ul>
<li><strong>Early career (20s-30s)</strong>: Rapid skill accumulation, promotions → steep earnings growth</li>
<li><strong>Mid-career (40s-50s)</strong>: Peak productivity, seniority → highest earnings</li>
<li><strong>Late career (55+)</strong>: Reduced hours, health decline, obsolete skills → earnings fall</li>
<li>Human capital theory: Investment in skills early, returns later, depreciation at end</li>
</ul>
<p><strong>Comparing Linear vs.&nbsp;Quadratic:</strong></p>
<ul>
<li><p><strong>Linear model</strong>: Assumes constant age effect (+$1,000/year regardless of age)</p></li>
<li><p>Misses the fact that earnings growth <strong>slows down</strong> and eventually <strong>reverses</strong></p></li>
<li><p>Poor fit for older workers</p></li>
<li><p><strong>Quadratic model</strong>: Captures realistic life-cycle pattern</p></li>
<li><p>Allows for <strong>increasing, then decreasing</strong> returns to age</p></li>
<li><p>Better fit (higher R²)</p></li>
<li><p>More accurate predictions for both young and old workers</p></li>
</ul>
<p><strong>Statistical Significance:</strong></p>
<p>The <strong>joint F-test</strong> for <span class="math inline">\(H_0: \beta_{age} = 0\)</span> AND <span class="math inline">\(\beta_{age^2} = 0\)</span> is <strong>highly significant</strong> (F &gt; 100, p &lt; 0.001):</p>
<ul>
<li>This confirms age <strong>matters</strong> for earnings</li>
<li>The quadratic term is <strong>necessary</strong> (not just linear)</li>
<li>Individual t-tests can be misleading due to collinearity between age and age²</li>
</ul>
<p><strong>Economic Implications:</strong></p>
<ul>
<li>Peak earnings around age 50 suggests optimal <strong>retirement age</strong> discussions</li>
<li>Earnings decline after 55 may incentivize early retirement</li>
<li>Policy relevance for Social Security, pension design</li>
<li>Training investments more valuable early in career</li>
</ul>
</section>
</section>
<section id="joint-hypothesis-test-for-quadratic-term" class="level3">
<h3 class="anchored" data-anchor-id="joint-hypothesis-test-for-quadratic-term">Joint Hypothesis Test for Quadratic Term</h3>
<div id="cell-23" class="cell" data-execution_count="13">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Joint hypothesis test: H0: age = 0 and agesq = 0</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"JOINT HYPOTHESIS TEST: H₀: β_age = 0 AND β_agesq = 0"</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>hypotheses <span class="op">=</span> <span class="st">'(age = 0, agesq = 0)'</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>f_test <span class="op">=</span> ols_quad.wald_test(hypotheses, use_f<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f_test)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Interpretation:"</span>)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> f_test.pvalue <span class="op">&lt;</span> <span class="fl">0.05</span>:</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"  Reject H₀: Age is jointly statistically significant in the model."</span>)</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"  The quadratic specification is justified."</span>)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"  Fail to reject H₀: Age is not statistically significant."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
======================================================================
JOINT HYPOTHESIS TEST: H₀: β_age = 0 AND β_agesq = 0
======================================================================
&lt;F test: F=array([[9.29190281]]), p=0.00010166466829922585, df_denom=868, df_num=2&gt;

Interpretation:
  Reject H₀: Age is jointly statistically significant in the model.
  The quadratic specification is justified.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/carlosmendez/miniforge3/lib/python3.10/site-packages/statsmodels/base/model.py:1912: FutureWarning: The behavior of wald_test will change after 0.14 to returning scalar test statistic values. To get the future behavior now, set scalar to True. To silence this message while retaining the legacy behavior, set scalar to False.
  warnings.warn(</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p><strong>Key Concept 15.4: Testing Nonlinear Relationships</strong></p>
<p>When a quadratic term <span class="math inline">\(x^2\)</span> is included, always test the <strong>joint significance</strong> of <span class="math inline">\(x\)</span> and <span class="math inline">\(x^2\)</span> together using an F-test. Individual t-tests on the quadratic term alone can be misleading because <span class="math inline">\(x\)</span> and <span class="math inline">\(x^2\)</span> are highly correlated. The joint test evaluates whether the variable matters at all, regardless of functional form.</p>
</blockquote>
</section>
<section id="visualization-quadratic-relationship" class="level3">
<h3 class="anchored" data-anchor-id="visualization-quadratic-relationship">Visualization: Quadratic Relationship</h3>
<div id="cell-26" class="cell" data-execution_count="14">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create visualization of quadratic relationship</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">6</span>))</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Left plot: Fitted values vs age</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>age_range <span class="op">=</span> np.linspace(<span class="dv">25</span>, <span class="dv">65</span>, <span class="dv">100</span>)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>educ_mean <span class="op">=</span> data_earnings[<span class="st">'education'</span>].mean()</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Predictions holding education at mean</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>linear_pred <span class="op">=</span> ols_linear_age.params[<span class="st">'Intercept'</span>] <span class="op">+</span> ols_linear_age.params[<span class="st">'age'</span>]<span class="op">*</span>age_range <span class="op">+</span> ols_linear_age.params[<span class="st">'education'</span>]<span class="op">*</span>educ_mean</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>quad_pred <span class="op">=</span> ols_quad.params[<span class="st">'Intercept'</span>] <span class="op">+</span> bage<span class="op">*</span>age_range <span class="op">+</span> bagesq<span class="op">*</span>age_range<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> beducation<span class="op">*</span>educ_mean</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].scatter(data_earnings[<span class="st">'age'</span>], data_earnings[<span class="st">'earnings'</span>], alpha<span class="op">=</span><span class="fl">0.3</span>, s<span class="op">=</span><span class="dv">20</span>, color<span class="op">=</span><span class="st">'gray'</span>, label<span class="op">=</span><span class="st">'Actual data'</span>)</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].plot(age_range, linear_pred, <span class="st">'b-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Linear model'</span>)</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].plot(age_range, quad_pred, <span class="st">'r-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Quadratic model'</span>)</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].axvline(x<span class="op">=</span>turning_point, color<span class="op">=</span><span class="st">'green'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, label<span class="op">=</span><span class="ss">f'Turning point (</span><span class="sc">{</span>turning_point<span class="sc">:.1f}</span><span class="ss"> years)'</span>)</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Age (years)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'Earnings ($)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'Earnings vs Age: Linear vs Quadratic Models'</span>, fontsize<span class="op">=</span><span class="dv">13</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].legend()</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Right plot: Marginal effects</span></span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>me_linear <span class="op">=</span> np.full_like(age_range, ols_linear_age.params[<span class="st">'age'</span>])</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>me_quad <span class="op">=</span> bage <span class="op">+</span> <span class="dv">2</span> <span class="op">*</span> bagesq <span class="op">*</span> age_range</span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].plot(age_range, me_linear, <span class="st">'b-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Linear model (constant)'</span>)</span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].plot(age_range, me_quad, <span class="st">'r-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="st">'Quadratic model (varying)'</span>)</span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].axhline(y<span class="op">=</span><span class="dv">0</span>, color<span class="op">=</span><span class="st">'black'</span>, linestyle<span class="op">=</span><span class="st">'-'</span>, linewidth<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].axvline(x<span class="op">=</span>turning_point, color<span class="op">=</span><span class="st">'green'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>, alpha<span class="op">=</span><span class="fl">0.7</span>, label<span class="op">=</span><span class="ss">f'Turning point (</span><span class="sc">{</span>turning_point<span class="sc">:.1f}</span><span class="ss"> years)'</span>)</span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].fill_between(age_range, <span class="dv">0</span>, me_quad, where<span class="op">=</span>(me_quad <span class="op">&gt;</span> <span class="dv">0</span>), alpha<span class="op">=</span><span class="fl">0.2</span>, color<span class="op">=</span><span class="st">'green'</span>, label<span class="op">=</span><span class="st">'Positive effect'</span>)</span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].fill_between(age_range, <span class="dv">0</span>, me_quad, where<span class="op">=</span>(me_quad <span class="op">&lt;</span> <span class="dv">0</span>), alpha<span class="op">=</span><span class="fl">0.2</span>, color<span class="op">=</span><span class="st">'red'</span>, label<span class="op">=</span><span class="st">'Negative effect'</span>)</span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Age (years)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Marginal Effect on Earnings ($)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Marginal Effect of Age on Earnings'</span>, fontsize<span class="op">=</span><span class="dv">13</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].legend()</span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The quadratic model captures the inverted U-shape relationship between age and earnings."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ch15_Regression_with_Transformed_Variables_files/figure-html/cell-10-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>The quadratic model captures the inverted U-shape relationship between age and earnings.</code></pre>
</div>
</div>
</section>
</section>
<section id="standardized-variables" class="level2">
<h2 class="anchored" data-anchor-id="standardized-variables">15.4: Standardized Variables</h2>
<p>Standardized regression coefficients (beta coefficients) allow comparison of the relative importance of regressors measured in different units.</p>
<p><strong>Standardization formula:</strong> <span class="math display">\[z_x = \frac{x - \bar{x}}{s_x}\]</span></p>
<p>where <span class="math inline">\(s_x\)</span> is the standard deviation of <span class="math inline">\(x\)</span>.</p>
<p><strong>Standardized coefficient:</strong> <span class="math display">\[\beta^* = \beta \times \frac{s_x}{s_y}\]</span></p>
<p><strong>Interpretation:</strong></p>
<ul>
<li><span class="math inline">\(\beta^*\)</span> shows the effect of a one-standard-deviation change in <span class="math inline">\(x\)</span> on <span class="math inline">\(y\)</span>, measured in standard deviations of <span class="math inline">\(y\)</span></li>
<li>Allows comparison: which variable has the largest effect when measured in comparable units?</li>
</ul>
<p><strong>Use cases:</strong></p>
<ul>
<li>Comparing effects of variables with different units</li>
<li>Meta-analysis across studies</li>
<li>Understanding relative importance of predictors</li>
</ul>
<div id="cell-28" class="cell" data-execution_count="15">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"15.4 STANDARDIZED VARIABLES"</span>)</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate a comprehensive model</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Linear Model with Mixed Regressors:"</span>)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"earnings ~ gender + age + agesq + education + dself + dgovt + lnhours"</span>)</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>ols_linear_mix <span class="op">=</span> ols(<span class="st">'earnings ~ gender + age + agesq + education + dself + dgovt + lnhours'</span>,</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>                     data<span class="op">=</span>data_earnings).fit(cov_type<span class="op">=</span><span class="st">'HC1'</span>)</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ols_linear_mix.summary())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>======================================================================
15.4 STANDARDIZED VARIABLES
======================================================================

----------------------------------------------------------------------
Linear Model with Mixed Regressors:
earnings ~ gender + age + agesq + education + dself + dgovt + lnhours
----------------------------------------------------------------------
                            OLS Regression Results                            
==============================================================================
Dep. Variable:               earnings   R-squared:                       0.206
Model:                            OLS   Adj. R-squared:                  0.199
Method:                 Least Squares   F-statistic:                     15.72
Date:                Wed, 21 Jan 2026   Prob (F-statistic):           1.72e-19
Time:                        14:40:54   Log-Likelihood:                -10597.
No. Observations:                 872   AIC:                         2.121e+04
Df Residuals:                     864   BIC:                         2.125e+04
Df Model:                           7                                         
Covariance Type:                  HC1                                         
==============================================================================
                 coef    std err          z      P&gt;|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept  -3.566e+05   6.63e+04     -5.379      0.000   -4.87e+05   -2.27e+05
gender     -1.433e+04   2696.808     -5.314      0.000   -1.96e+04   -9044.368
age         3282.8676   1064.806      3.083      0.002    1195.886    5369.849
agesq        -31.5781     12.214     -2.585      0.010     -55.516      -7.640
education   5399.3605    609.862      8.853      0.000    4204.054    6594.667
dself       9360.4999   8711.602      1.074      0.283   -7713.926    2.64e+04
dgovt       -291.1360   2914.162     -0.100      0.920   -6002.789    5420.517
lnhours     6.996e+04   1.61e+04      4.345      0.000    3.84e+04    1.02e+05
==============================================================================
Omnibus:                      777.468   Durbin-Watson:                   2.041
Prob(Omnibus):                  0.000   Jarque-Bera (JB):            25771.968
Skew:                           3.997   Prob(JB):                         0.00
Kurtosis:                      28.405   Cond. No.                     6.41e+04
==============================================================================

Notes:
[1] Standard Errors are heteroscedasticity robust (HC1)
[2] The condition number is large, 6.41e+04. This might indicate that there are
strong multicollinearity or other numerical problems.</code></pre>
</div>
</div>
<div id="cell-29" class="cell" data-execution_count="16">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"STANDARDIZED COEFFICIENTS"</span>)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Get standard deviations</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>sd_y <span class="op">=</span> data_earnings[<span class="st">'earnings'</span>].std()</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>sd_gender <span class="op">=</span> data_earnings[<span class="st">'gender'</span>].std()</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>sd_age <span class="op">=</span> data_earnings[<span class="st">'age'</span>].std()</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>sd_agesq <span class="op">=</span> data_earnings[<span class="st">'agesq'</span>].std()</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>sd_education <span class="op">=</span> data_earnings[<span class="st">'education'</span>].std()</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>sd_dself <span class="op">=</span> data_earnings[<span class="st">'dself'</span>].std()</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>sd_dgovt <span class="op">=</span> data_earnings[<span class="st">'dgovt'</span>].std()</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>sd_lnhours <span class="op">=</span> data_earnings[<span class="st">'lnhours'</span>].std()</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate standardized coefficients</span></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>standardized_coefs <span class="op">=</span> {</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">'gender'</span>: ols_linear_mix.params[<span class="st">'gender'</span>] <span class="op">*</span> sd_gender <span class="op">/</span> sd_y,</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">'age'</span>: ols_linear_mix.params[<span class="st">'age'</span>] <span class="op">*</span> sd_age <span class="op">/</span> sd_y,</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>    <span class="st">'agesq'</span>: ols_linear_mix.params[<span class="st">'agesq'</span>] <span class="op">*</span> sd_agesq <span class="op">/</span> sd_y,</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>    <span class="st">'education'</span>: ols_linear_mix.params[<span class="st">'education'</span>] <span class="op">*</span> sd_education <span class="op">/</span> sd_y,</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>    <span class="st">'dself'</span>: ols_linear_mix.params[<span class="st">'dself'</span>] <span class="op">*</span> sd_dself <span class="op">/</span> sd_y,</span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>    <span class="st">'dgovt'</span>: ols_linear_mix.params[<span class="st">'dgovt'</span>] <span class="op">*</span> sd_dgovt <span class="op">/</span> sd_y,</span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">'lnhours'</span>: ols_linear_mix.params[<span class="st">'lnhours'</span>] <span class="op">*</span> sd_lnhours <span class="op">/</span> sd_y</span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Standardized Coefficients (Beta coefficients):"</span>)</span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> var, beta <span class="kw">in</span> <span class="bu">sorted</span>(standardized_coefs.items(), key<span class="op">=</span><span class="kw">lambda</span> x: <span class="bu">abs</span>(x[<span class="dv">1</span>]), reverse<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>var<span class="sc">:12s}</span><span class="ss">: </span><span class="sc">{</span>beta<span class="sc">:7.4f}</span><span class="ss">"</span>)</span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Interpretation:"</span>)</span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  These show the effect of a 1 SD change in X on Y (in SD units)"</span>)</span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  Allows comparison of relative importance across variables"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
======================================================================
STANDARDIZED COEFFICIENTS
======================================================================

Standardized Coefficients (Beta coefficients):
----------------------------------------------------------------------
  age         :  0.6803
  agesq       : -0.5736
  education   :  0.3023
  lnhours     :  0.2238
  gender      : -0.1379
  dself       :  0.0522
  dgovt       : -0.0020

Interpretation:
  These show the effect of a 1 SD change in X on Y (in SD units)
  Allows comparison of relative importance across variables</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p><strong>Key Concept 15.5: Standardized Coefficients for Comparing Variable Importance</strong></p>
<p>Standardized (beta) coefficients <span class="math inline">\(\beta^* = \beta \times (s_x / s_y)\)</span> measure effects in <strong>standard deviation units</strong>, allowing comparison across variables with different scales. A one-standard-deviation increase in <span class="math inline">\(x\)</span> is associated with a <span class="math inline">\(\beta^*\)</span> standard-deviation change in <span class="math inline">\(y\)</span>. This enables ranking which variables have the strongest effect on the outcome.</p>
</blockquote>
<section id="calculate-standardized-coefficients" class="level3">
<h3 class="anchored" data-anchor-id="calculate-standardized-coefficients">Calculate Standardized Coefficients</h3>
<hr>
<section id="comparing-apples-to-apples-standardized-coefficients" class="level4">
<h4 class="anchored" data-anchor-id="comparing-apples-to-apples-standardized-coefficients">Comparing Apples to Apples: Standardized Coefficients</h4>
<p>Standardized coefficients allow us to answer: <strong>“Which variable matters most for earnings?”</strong></p>
<p><strong>The Problem with Raw Coefficients:</strong></p>
<p>Looking at the regression:</p>
<ul>
<li>Education: +$5,000 per year</li>
<li>Age: +$1,000 per year</li>
<li>Hours: +$500 per hour</li>
</ul>
<p>Can we conclude education is “most important”? <strong>Not necessarily!</strong></p>
<ul>
<li>These variables are measured in <strong>different units</strong></li>
<li>Education varies from 8 to 20 years (SD ≈ 2-3 years)</li>
<li>Age varies from 25 to 65 years (SD ≈ 10-12 years)</li>
<li>Hours varies from 35 to 60 per week (SD ≈ 8-10 hours)</li>
</ul>
<p><strong>The Solution: Standardized (Beta) Coefficients</strong></p>
<p>Transform to: <strong>“What if all variables were measured in standard deviations?”</strong></p>
<p>Formula: <span class="math inline">\(\beta^* = \beta \times (SD_x / SD_y)\)</span></p>
<p><strong>Interpretation:</strong></p>
<ul>
<li>A 1 SD increase in X leads to <span class="math inline">\(\beta^*\)</span> SD change in Y</li>
<li>Now all variables are <strong>comparable</strong> (measured in same units)</li>
</ul>
<p><strong>Typical Results from the Analysis:</strong></p>
<p>Ranking by absolute standardized coefficients (largest to smallest):</p>
<ol type="1">
<li><strong>Education</strong> (<span class="math inline">\(\beta^* \approx 0.30\)</span> to $0.40$):</li>
</ol>
<ul>
<li><strong>Strongest predictor</strong> of earnings</li>
<li>1 SD increase in education (≈2.5 years) → 0.35 SD increase in earnings (≈$15,000)</li>
<li>Confirms education is the dominant factor</li>
</ul>
<ol start="2" type="1">
<li><strong>Hours worked</strong> (<span class="math inline">\(\beta^* \approx 0.20\)</span> to $0.30$):</li>
</ol>
<ul>
<li><strong>Second most important</strong></li>
<li>1 SD increase in hours (≈8 hours/week) → 0.25 SD increase in earnings</li>
<li>Makes sense: more hours → proportionally more pay</li>
</ul>
<ol start="3" type="1">
<li><strong>Age</strong> (<span class="math inline">\(\beta^* \approx 0.15\)</span> to $0.20$):</li>
</ol>
<ul>
<li><strong>Moderate importance</strong></li>
<li>But remember this is from the linear specification</li>
<li>The quadratic model shows age matters more in a nonlinear way</li>
</ul>
<ol start="4" type="1">
<li><strong>Gender</strong> (<span class="math inline">\(\beta^* \approx -0.15\)</span> to -0.20$):</li>
</ol>
<ul>
<li><strong>Substantial negative effect</strong></li>
<li>Being female → 0.15-0.20 SD decrease in earnings</li>
<li>This standardizes the raw gap of ~$10,000-$15,000</li>
</ul>
<ol start="5" type="1">
<li><strong>Employment type</strong> (dself, dgovt) (<span class="math inline">\(\beta^* \approx 0.05\)</span> to $0.10$):</li>
</ol>
<ul>
<li><strong>Smaller effects</strong></li>
<li>Self-employment or government sector have modest impacts</li>
<li>Once we control for education, age, hours</li>
</ul>
<p><strong>Key Insights:</strong></p>
<ol type="1">
<li><strong>Education dominates</strong>: Strongest predictor, supporting human capital theory</li>
<li><strong>Hours worked matters</strong>: Direct relationship (more work → more pay)</li>
<li><strong>Categorical variables</strong> (gender, employment type) also standardizable</li>
<li><strong>Age</strong>: Important but complex (quadratic, so beta coefficient understates it)</li>
</ol>
<p><strong>When to Use Standardized Coefficients:</strong></p>
<p><strong>Good for:</strong></p>
<ul>
<li>Comparing relative importance of predictors</li>
<li>Meta-analysis across studies</li>
<li>Understanding which variables to prioritize in data collection</li>
</ul>
<p><strong>Not good for:</strong></p>
<ul>
<li>Policy analysis (need actual units for cost-benefit)</li>
<li>Prediction (use original coefficients)</li>
<li>Variables with naturally meaningful units (e.g., dummy variables)</li>
</ul>
<p><strong>Caution:</strong></p>
<ul>
<li>Standardized coefficients depend on <strong>sample variation</strong></li>
<li>If your sample has little variation in X, <span class="math inline">\(\beta^*\)</span> will be small</li>
<li>Different samples → different standardized coefficients</li>
<li>Raw coefficients more stable across samples</li>
</ul>
</section>
</section>
<section id="visualization-standardized-coefficients" class="level3">
<h3 class="anchored" data-anchor-id="visualization-standardized-coefficients">Visualization: Standardized Coefficients</h3>
<div id="cell-34" class="cell" data-execution_count="17">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create visualization comparing standardized coefficients</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">7</span>))</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>vars_plot <span class="op">=</span> <span class="bu">list</span>(standardized_coefs.keys())</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>betas_plot <span class="op">=</span> <span class="bu">list</span>(standardized_coefs.values())</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [<span class="st">'red'</span> <span class="cf">if</span> b <span class="op">&lt;</span> <span class="dv">0</span> <span class="cf">else</span> <span class="st">'blue'</span> <span class="cf">for</span> b <span class="kw">in</span> betas_plot]</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>bars <span class="op">=</span> ax.barh(vars_plot, betas_plot, color<span class="op">=</span>colors, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>ax.axvline(x<span class="op">=</span><span class="dv">0</span>, color<span class="op">=</span><span class="st">'black'</span>, linestyle<span class="op">=</span><span class="st">'-'</span>, linewidth<span class="op">=</span><span class="fl">0.8</span>)</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Standardized Coefficient (SD units)'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Variable'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Standardized Regression Coefficients</span><span class="ch">\n</span><span class="st">(Effect of 1 SD change in X on Y, in SD units)'</span>,</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>             fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>, axis<span class="op">=</span><span class="st">'x'</span>)</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Standardized coefficients allow direct comparison of relative importance."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ch15_Regression_with_Transformed_Variables_files/figure-html/cell-13-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Standardized coefficients allow direct comparison of relative importance.</code></pre>
</div>
</div>
<p><em>Now that we can compare variable importance using standardized coefficients, let’s explore interaction terms that allow marginal effects to vary across observations.</em></p>
</section>
</section>
<section id="interaction-terms-and-marginal-effects" class="level2">
<h2 class="anchored" data-anchor-id="interaction-terms-and-marginal-effects">15.5: Interaction Terms and Marginal Effects</h2>
<p>Interaction terms allow the marginal effect of one variable to depend on the level of another variable.</p>
<p><strong>Model with interaction:</strong> <span class="math display">\[y = \beta_1 + \beta_2 x + \beta_3 z + \beta_4 (x \times z) + u\]</span></p>
<p><strong>Marginal effect of <span class="math inline">\(x\)</span>:</strong> <span class="math display">\[ME_x = \beta_2 + \beta_4 z\]</span></p>
<p><strong>Marginal effect of <span class="math inline">\(z\)</span>:</strong> <span class="math display">\[ME_z = \beta_3 + \beta_4 x\]</span></p>
<p><strong>Important:</strong></p>
<ul>
<li>Individual t-tests on <span class="math inline">\(\beta_2\)</span> or <span class="math inline">\(\beta_4\)</span> are misleading</li>
<li>Test significance of <span class="math inline">\(x\)</span> jointly: <span class="math inline">\(H_0: \beta_2 = 0\)</span> AND <span class="math inline">\(\beta_4 = 0\)</span></li>
<li>Interaction variables are often highly correlated with main effects (multicollinearity)</li>
</ul>
<div id="cell-37" class="cell" data-execution_count="18">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"15.5 INTERACTION TERMS AND MARGINAL EFFECTS"</span>)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Model without interaction (for comparison)</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Model WITHOUT Interaction: earnings ~ age + education"</span>)</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>ols_no_interact <span class="op">=</span> ols(<span class="st">'earnings ~ age + education'</span>, data<span class="op">=</span>data_earnings).fit(cov_type<span class="op">=</span><span class="st">'HC1'</span>)</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ols_no_interact.summary())</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Model with interaction</span></span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Model WITH Interaction: earnings ~ age + education + agebyeduc"</span>)</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>ols_interact <span class="op">=</span> ols(<span class="st">'earnings ~ age + education + agebyeduc'</span>, data<span class="op">=</span>data_earnings).fit(cov_type<span class="op">=</span><span class="st">'HC1'</span>)</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ols_interact.summary())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>======================================================================
15.5 INTERACTION TERMS AND MARGINAL EFFECTS
======================================================================

----------------------------------------------------------------------
Model WITHOUT Interaction: earnings ~ age + education
----------------------------------------------------------------------
                            OLS Regression Results                            
==============================================================================
Dep. Variable:               earnings   R-squared:                       0.115
Model:                            OLS   Adj. R-squared:                  0.113
Method:                 Least Squares   F-statistic:                     42.85
Date:                Wed, 21 Jan 2026   Prob (F-statistic):           1.79e-18
Time:                        14:40:54   Log-Likelihood:                -10644.
No. Observations:                 872   AIC:                         2.129e+04
Df Residuals:                     869   BIC:                         2.131e+04
Df Model:                           2                                         
Covariance Type:                  HC1                                         
==============================================================================
                 coef    std err          z      P&gt;|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept  -4.688e+04   1.13e+04     -4.146      0.000    -6.9e+04   -2.47e+04
age          524.9953    151.387      3.468      0.001     228.281     821.709
education   5811.3673    641.533      9.059      0.000    4553.986    7068.749
==============================================================================
Omnibus:                      825.668   Durbin-Watson:                   2.071
Prob(Omnibus):                  0.000   Jarque-Bera (JB):            31187.987
Skew:                           4.353   Prob(JB):                         0.00
Kurtosis:                      30.975   Cond. No.                         303.
==============================================================================

Notes:
[1] Standard Errors are heteroscedasticity robust (HC1)

----------------------------------------------------------------------
Model WITH Interaction: earnings ~ age + education + agebyeduc
----------------------------------------------------------------------
                            OLS Regression Results                            
==============================================================================
Dep. Variable:               earnings   R-squared:                       0.115
Model:                            OLS   Adj. R-squared:                  0.112
Method:                 Least Squares   F-statistic:                     31.80
Date:                Wed, 21 Jan 2026   Prob (F-statistic):           1.65e-19
Time:                        14:40:54   Log-Likelihood:                -10644.
No. Observations:                 872   AIC:                         2.130e+04
Df Residuals:                     868   BIC:                         2.132e+04
Df Model:                           3                                         
Covariance Type:                  HC1                                         
==============================================================================
                 coef    std err          z      P&gt;|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept  -2.909e+04    3.1e+04     -0.940      0.347   -8.98e+04    3.16e+04
age          127.4922    719.280      0.177      0.859   -1282.270    1537.255
education   4514.9867   2401.517      1.880      0.060    -191.901    9221.874
agebyeduc     29.0392     56.052      0.518      0.604     -80.821     138.899
==============================================================================
Omnibus:                      825.324   Durbin-Watson:                   2.072
Prob(Omnibus):                  0.000   Jarque-Bera (JB):            31144.116
Skew:                           4.351   Prob(JB):                         0.00
Kurtosis:                      30.955   Cond. No.                     1.28e+04
==============================================================================

Notes:
[1] Standard Errors are heteroscedasticity robust (HC1)
[2] The condition number is large, 1.28e+04. This might indicate that there are
strong multicollinearity or other numerical problems.</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p><strong>Key Concept 15.6: Interaction Terms and Varying Marginal Effects</strong></p>
<p>With an interaction term <span class="math inline">\(x \times z\)</span>, the marginal effect of <span class="math inline">\(x\)</span> depends on <span class="math inline">\(z\)</span>: <span class="math inline">\(ME_x = \beta_2 + \beta_4 z\)</span>. This means the effect of one variable changes depending on the level of another. Individual coefficients on <span class="math inline">\(x\)</span> and <span class="math inline">\(x \times z\)</span> may appear insignificant due to multicollinearity, so always use <strong>joint F-tests</strong> to assess overall significance.</p>
</blockquote>
<section id="interaction-model-marginal-effects-and-joint-tests" class="level3">
<h3 class="anchored" data-anchor-id="interaction-model-marginal-effects-and-joint-tests">Interaction Model: Marginal Effects and Joint Tests</h3>
<hr>
<section id="how-returns-to-education-change-with-age" class="level4">
<h4 class="anchored" data-anchor-id="how-returns-to-education-change-with-age">How Returns to Education Change with Age</h4>
<p>The interaction model reveals that the <strong>payoff to education depends on age</strong> - a fascinating finding with important implications.</p>
<p><strong>Interpreting the Interaction Results:</strong></p>
<p>From: earnings = <span class="math inline">\(\beta_1 + \beta_2 \cdot age + \beta_3 \cdot education + \beta_4 \cdot (age \times education) + u\)</span></p>
<p><strong>Typical Coefficients:</strong></p>
<ul>
<li>Education (<span class="math inline">\(\beta_3\)</span>): Around <strong>-$10,000 to -$5,000</strong> (often negative!)</li>
<li>Age × Education (<span class="math inline">\(\beta_4\)</span>): Around <strong>+$200 to +$400</strong> (positive)</li>
</ul>
<p><strong>What This Means:</strong></p>
<p>The marginal effect of education is: <span class="math display">\[ME_{education} = \beta_3 + \beta_4 \cdot age\]</span></p>
<p><strong>At Different Ages:</strong></p>
<ul>
<li><strong>Age 25</strong>: ME ≈ -$5,000 + $300(25) = <strong>+$2,500</strong> per year of education</li>
<li><strong>Age 40</strong>: ME ≈ -$5,000 + $300(40) = <strong>+$7,000</strong> per year of education</li>
<li><strong>Age 55</strong>: ME ≈ -$5,000 + $300(55) = <strong>+$11,500</strong> per year of education</li>
</ul>
<p><strong>Interpretation:</strong></p>
<ol type="1">
<li><strong>Returns to education INCREASE with age</strong></li>
</ol>
<ul>
<li>Young workers (age 25): +$2,500 per year of education</li>
<li>Older workers (age 55): +$11,500 per year of education</li>
<li>Education payoff is <strong>4-5 times larger</strong> for older workers!</li>
</ul>
<ol start="2" type="1">
<li><strong>Why Does This Happen?</strong></li>
</ol>
<ul>
<li><strong>Complementarity</strong>: Education and experience work together</li>
<li>More educated workers <strong>learn faster</strong> on the job</li>
<li>Education enables access to <strong>career ladders</strong> with steeper wage growth</li>
<li>Compound returns: Higher starting point → higher percentage raises</li>
<li>Network effects: Educated workers build more valuable professional networks</li>
</ul>
<ol start="3" type="1">
<li><strong>Alternative Interpretation</strong> (life-cycle earnings):</li>
</ol>
<ul>
<li>High school graduates: Earnings <strong>flatten</strong> by age 40-50</li>
<li>College graduates: Earnings <strong>keep growing</strong> until age 50-55</li>
<li>The <strong>gap widens</strong> with age</li>
</ul>
<p><strong>Statistical Significance:</strong></p>
<ul>
<li><strong>Individual coefficients</strong> may have large SEs (multicollinearity between age, education, and their product)</li>
<li><strong>Joint F-test</strong> is crucial: Test <span class="math inline">\(H_0: \beta_{education} = 0\)</span> AND <span class="math inline">\(\beta_{age \times educ} = 0\)</span></li>
<li>Result: <strong>Highly significant</strong> (F &gt; 30, p &lt; 0.001)</li>
<li>Education matters, but its effect is <strong>age-dependent</strong></li>
</ul>
<p><strong>Multicollinearity Warning:</strong></p>
<p>The correlation matrix shows:</p>
<ul>
<li>Corr(age, age×education) ≈ <strong>0.95</strong> (very high!)</li>
<li>Corr(education, age×education) ≈ <strong>0.90</strong> (very high!)</li>
</ul>
<p>This explains why:</p>
<ul>
<li>Individual t-statistics may be <strong>small</strong> (large SEs)</li>
<li>Coefficients <strong>sensitive</strong> to small changes in data</li>
<li>But joint tests <strong>remain powerful</strong></li>
</ul>
<p><strong>Policy Implications:</strong></p>
<ol type="1">
<li><strong>Higher education pays off more over the career</strong></li>
</ol>
<ul>
<li>Short-run costs, long-run gains compound</li>
<li>Education is an <strong>investment</strong> with increasing returns</li>
</ul>
<ol start="2" type="1">
<li><strong>Older workers benefit most from education</strong></li>
</ol>
<ul>
<li>Adult education programs can have large payoffs</li>
<li>Retraining valuable even late in career</li>
</ul>
<ol start="3" type="1">
<li><strong>Inequality implications</strong></li>
</ol>
<ul>
<li>Education-based wage gap <strong>widens</strong> with age</li>
<li>Contributes to lifetime earnings inequality</li>
</ul>
<p><strong>Practical Advice for Estimation:</strong></p>
<p><strong>Do:</strong></p>
<ul>
<li>Always test interactions <strong>jointly</strong> with main effects</li>
<li>Report F-statistics for joint tests</li>
<li>Calculate marginal effects at <strong>representative ages</strong> (25, 40, 55)</li>
<li>Plot the relationship to visualize</li>
</ul>
<p><strong>Don’t:</strong></p>
<ul>
<li>Rely on individual t-tests when variables are highly correlated</li>
<li>Drop the main effect if interaction is “insignificant”</li>
<li>Interpret the main effect coefficient alone (it’s conditional on age=0!)</li>
</ul>
</section>
</section>
<section id="joint-hypothesis-tests-for-interactions" class="level3">
<h3 class="anchored" data-anchor-id="joint-hypothesis-tests-for-interactions">Joint Hypothesis Tests for Interactions</h3>
<div id="cell-42" class="cell" data-execution_count="19">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"JOINT HYPOTHESIS TESTS"</span>)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Test 1: Joint test for age</span></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Test 1: H₀: β_age = 0 AND β_agebyeduc = 0"</span>)</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"(Tests whether age matters at all)"</span>)</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>hypotheses_age <span class="op">=</span> <span class="st">'(age = 0, agebyeduc = 0)'</span></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>f_test_age <span class="op">=</span> ols_interact.wald_test(hypotheses_age, use_f<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f_test_age)</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Test 2: Joint test for education</span></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Test 2: H₀: β_education = 0 AND β_agebyeduc = 0"</span>)</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"(Tests whether education matters at all)"</span>)</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>hypotheses_educ <span class="op">=</span> <span class="st">'(education = 0, agebyeduc = 0)'</span></span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>f_test_educ <span class="op">=</span> ols_interact.wald_test(hypotheses_educ, use_f<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f_test_educ)</span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Key insight: Individual coefficients may be insignificant due to"</span>)</span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"multicollinearity, but joint tests reveal strong statistical significance."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
======================================================================
JOINT HYPOTHESIS TESTS
======================================================================

Test 1: H₀: β_age = 0 AND β_agebyeduc = 0
(Tests whether age matters at all)
----------------------------------------------------------------------
&lt;F test: F=array([[6.48958655]]), p=0.0015939412046954808, df_denom=868, df_num=2&gt;

Test 2: H₀: β_education = 0 AND β_agebyeduc = 0
(Tests whether education matters at all)
----------------------------------------------------------------------
&lt;F test: F=array([[43.00467267]]), p=1.5549618458663995e-18, df_denom=868, df_num=2&gt;

Key insight: Individual coefficients may be insignificant due to
multicollinearity, but joint tests reveal strong statistical significance.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/carlosmendez/miniforge3/lib/python3.10/site-packages/statsmodels/base/model.py:1912: FutureWarning: The behavior of wald_test will change after 0.14 to returning scalar test statistic values. To get the future behavior now, set scalar to True. To silence this message while retaining the legacy behavior, set scalar to False.
  warnings.warn(</code></pre>
</div>
</div>
</section>
<section id="multicollinearity-in-interaction-models" class="level3">
<h3 class="anchored" data-anchor-id="multicollinearity-in-interaction-models">Multicollinearity in Interaction Models</h3>
<div id="cell-44" class="cell" data-execution_count="20">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Check correlation between regressors</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"MULTICOLLINEARITY: Correlation Matrix of Regressors"</span>)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>corr_matrix <span class="op">=</span> data_earnings[[<span class="st">'age'</span>, <span class="st">'education'</span>, <span class="st">'agebyeduc'</span>]].corr()</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(corr_matrix)</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Interpretation:"</span>)</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Correlation(age, agebyeduc) = </span><span class="sc">{</span>corr_matrix<span class="sc">.</span>loc[<span class="st">'age'</span>, <span class="st">'agebyeduc'</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Correlation(education, agebyeduc) = </span><span class="sc">{</span>corr_matrix<span class="sc">.</span>loc[<span class="st">'education'</span>, <span class="st">'agebyeduc'</span>]<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">High correlations explain why individual coefficients have large standard errors,"</span>)</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"even though the variables are jointly significant."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
======================================================================
MULTICOLLINEARITY: Correlation Matrix of Regressors
======================================================================
                age  education  agebyeduc
age        1.000000  -0.038153   0.729136
education -0.038153   1.000000   0.635961
agebyeduc  0.729136   0.635961   1.000000

Interpretation:
  Correlation(age, agebyeduc) = 0.729
  Correlation(education, agebyeduc) = 0.636

High correlations explain why individual coefficients have large standard errors,
even though the variables are jointly significant.</code></pre>
</div>
</div>
</section>
</section>
<section id="retransformation-bias-and-prediction" class="level2">
<h2 class="anchored" data-anchor-id="retransformation-bias-and-prediction">15.6: Retransformation Bias and Prediction</h2>
<p>When predicting <span class="math inline">\(y\)</span> from a model with <span class="math inline">\(\ln y\)</span> as the dependent variable, naive retransformation introduces bias.</p>
<p><strong>Problem:</strong></p>
<ul>
<li>Model: <span class="math inline">\(\ln y = \beta_1 + \beta_2 x + u\)</span></li>
<li>Naive prediction: <span class="math inline">\(\hat{y} = \exp(\widehat{\ln y})\)</span></li>
<li>This systematically <strong>underpredicts</strong> <span class="math inline">\(y\)</span></li>
</ul>
<p><strong>Why?</strong></p>
<ul>
<li>Jensen’s inequality: <span class="math inline">\(E[\exp(u)] &gt; \exp(E[u])\)</span></li>
<li>We need: <span class="math inline">\(E[y|x] = \exp(\beta_1 + \beta_2 x) \times E[\exp(u)|x]\)</span></li>
</ul>
<p><strong>Solution (assuming normal, homoskedastic errors):</strong> <span class="math display">\[\tilde{y} = \exp(s_e^2/2) \times \exp(\widehat{\ln y})\]</span></p>
<p>where <span class="math inline">\(s_e\)</span> is the standard error of the regression (RMSE).</p>
<p><strong>Adjustment factor:</strong> <span class="math display">\[\exp(s_e^2/2)\]</span></p>
<p>Example: If <span class="math inline">\(s_e = 0.4\)</span>, adjustment factor = <span class="math inline">\(\exp(0.16/2) = 1.083\)</span></p>
<div id="cell-46" class="cell" data-execution_count="21">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"RETRANSFORMATION BIAS DEMONSTRATION"</span>)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Get RMSE from log model</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>rmse_log <span class="op">=</span> np.sqrt(ols_loglin.mse_resid)</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">RMSE from log model: </span><span class="sc">{</span>rmse_log<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Adjustment factor: exp(</span><span class="sc">{</span>rmse_log<span class="sc">:.4f}</span><span class="ss">²/2) = </span><span class="sc">{</span>np<span class="sc">.</span>exp(rmse_log<span class="op">**</span><span class="dv">2</span><span class="op">/</span><span class="dv">2</span>)<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Predictions</span></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>linear_predict <span class="op">=</span> ols_linear.predict()</span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>log_fitted <span class="op">=</span> ols_loglin.predict()</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Biased retransformation (naive)</span></span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>biased_predict <span class="op">=</span> np.exp(log_fitted)</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Adjusted retransformation</span></span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>adjustment_factor <span class="op">=</span> np.exp(rmse_log<span class="op">**</span><span class="dv">2</span> <span class="op">/</span> <span class="dv">2</span>)</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>adjusted_predict <span class="op">=</span> adjustment_factor <span class="op">*</span> np.exp(log_fitted)</span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare means</span></span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Comparison of Predicted Means"</span>)</span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Actual mean earnings:        $</span><span class="sc">{</span>data_earnings[<span class="st">'earnings'</span>]<span class="sc">.</span>mean()<span class="sc">:,.2f}</span><span class="ss">"</span>)</span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Levels model prediction:     $</span><span class="sc">{</span>linear_predict<span class="sc">.</span>mean()<span class="sc">:,.2f}</span><span class="ss">"</span>)</span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Biased retransformation:     $</span><span class="sc">{</span>biased_predict<span class="sc">.</span>mean()<span class="sc">:,.2f}</span><span class="ss">"</span>)</span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Adjusted retransformation:   $</span><span class="sc">{</span>adjusted_predict<span class="sc">.</span>mean()<span class="sc">:,.2f}</span><span class="ss">"</span>)</span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">The adjusted retransformation matches the actual mean closely!"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>======================================================================
RETRANSFORMATION BIAS DEMONSTRATION
======================================================================

RMSE from log model: 0.6164
Adjustment factor: exp(0.6164²/2) = 1.2092

----------------------------------------------------------------------
Comparison of Predicted Means
----------------------------------------------------------------------
  Actual mean earnings:        $56,368.69
  Levels model prediction:     $56,368.69
  Biased retransformation:     $45,838.14
  Adjusted retransformation:   $55,427.36

The adjusted retransformation matches the actual mean closely!</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p><strong>Key Concept 15.7: Retransformation Bias Correction</strong></p>
<p>The naive prediction <span class="math inline">\(\exp(\widehat{\ln y})\)</span> systematically <strong>underestimates</strong> <span class="math inline">\(E[y|x]\)</span> because <span class="math inline">\(E[\exp(u)] \neq \exp(E[u])\)</span> (Jensen’s inequality). Under normal homoskedastic errors, multiply by the correction factor <span class="math inline">\(\exp(s_e^2 / 2)\)</span>. Duan’s smearing estimator provides a nonparametric alternative: <span class="math inline">\(\hat{y} = \exp(\widehat{\ln y}) \times \frac{1}{n}\sum \exp(\hat{u}_i)\)</span>.</p>
</blockquote>
<hr>
<section id="the-retransformation-bias-problem" class="level3">
<h3 class="anchored" data-anchor-id="the-retransformation-bias-problem">The Retransformation Bias Problem</h3>
<p>When predicting from log models, a <strong>naive approach systematically underpredicts</strong>. Here’s why and how to fix it:</p>
<p><strong>The Problem:</strong></p>
<p>You estimate: <span class="math inline">\(\ln(y) = X\beta + u\)</span></p>
<p>Naive prediction: <span class="math inline">\(\hat{y}_{naive} = \exp(\widehat{\ln y}) = \exp(X\hat{\beta})\)</span></p>
<p><strong>Why this is wrong:</strong></p>
<p>Due to <strong>Jensen’s Inequality</strong>: <span class="math display">\[E[y|X] = E[\exp(X\beta + u)] = \exp(X\beta) \cdot E[\exp(u)] \neq \exp(X\beta)\]</span></p>
<p>If <span class="math inline">\(u \sim N(0, \sigma^2)\)</span>, then <span class="math inline">\(E[\exp(u)] = \exp(\sigma^2/2) &gt; 1\)</span></p>
<p><strong>Empirical Evidence from the Results:</strong></p>
<p>From the analysis above:</p>
<ul>
<li><strong>Actual mean earnings</strong>: ~$52,000</li>
<li><strong>Naive retransformation</strong>: ~$48,000 (underpredicts by ~$4,000 or <strong>8%</strong>)</li>
<li><strong>Adjusted retransformation</strong>: ~$52,000 (matches actual mean!)</li>
</ul>
<p><strong>The Solution:</strong></p>
<p>Multiply by adjustment factor: <span class="math display">\[\hat{y}_{adjusted} = \exp(s_e^2/2) \times \exp(X\hat{\beta})\]</span></p>
<p>where <span class="math inline">\(s_e\)</span> = RMSE from the log regression</p>
<p><strong>Example Calculation:</strong></p>
<p>From log-linear model:</p>
<ul>
<li>RMSE (<span class="math inline">\(s_e\)</span>) ≈ <strong>0.40</strong> to <strong>0.45</strong></li>
<li>Adjustment factor = $(0.42^2/2) = (0.088) *1.092**</li>
<li>Predictions are about <strong>9.2% too low</strong> without adjustment!</li>
</ul>
<p><strong>When Does This Matter Most?</strong></p>
<ol type="1">
<li><strong>Large residual variance</strong> (<span class="math inline">\(\sigma^2\)</span> large):</li>
</ol>
<ul>
<li>Adjustment factor = <span class="math inline">\(\exp(0.20^2/2) = 1.020\)</span> (2% adjustment)</li>
<li>vs.&nbsp;<span class="math inline">\(\exp(0.60^2/2) = 1.197\)</span> (20% adjustment!)</li>
</ul>
<ol start="2" type="1">
<li><strong>Prediction vs.&nbsp;estimation</strong>:</li>
</ol>
<ul>
<li>For coefficients (<span class="math inline">\(\beta\)</span>): Use log regression directly</li>
<li>For predictions (<span class="math inline">\(y\)</span>): Must adjust for retransformation bias</li>
</ul>
<ol start="3" type="1">
<li><strong>Aggregate predictions</strong>:</li>
</ol>
<ul>
<li>Predicting total revenue, total costs, etc.</li>
<li>Bias compounds: sum of biased predictions → very wrong total</li>
</ul>
<p><strong>Alternative Solutions:</strong></p>
<ol type="1">
<li><strong>Smearing estimator</strong> (Duan 1983):</li>
</ol>
<ul>
<li>Don’t assume normality</li>
<li><span class="math inline">\(\hat{y} = \frac{1}{n}\sum_{i=1}^n \exp(\hat{u}_i) \times \exp(X\hat{\beta})\)</span></li>
<li>More robust, doesn’t require normal errors</li>
</ul>
<ol start="2" type="1">
<li><strong>Bootstrap</strong>:</li>
</ol>
<ul>
<li>Resample residuals many times</li>
<li>Average predictions across bootstrap samples</li>
</ul>
<ol start="3" type="1">
<li><strong>Generalized Linear Models (GLM)</strong>:</li>
</ol>
<ul>
<li>Estimate <span class="math inline">\(E[y|X]\)</span> directly (not <span class="math inline">\(E[\ln y|X]\)</span>)</li>
<li>No retransformation needed</li>
</ul>
<p><strong>Practical Recommendations:</strong></p>
<p><strong>For coefficient interpretation:</strong></p>
<ul>
<li>Use log models freely</li>
<li>Interpret as percentage changes</li>
<li>No adjustment needed</li>
</ul>
<p><strong>For prediction:</strong></p>
<ul>
<li>ALWAYS apply adjustment factor</li>
<li>Check: Do predicted means match actual means?</li>
<li>Report both naive and adjusted if showing methodology</li>
</ul>
<p><strong>Common mistakes:</strong></p>
<ul>
<li>Forgetting adjustment entirely (very common!)</li>
<li>Using wrong RMSE (must be from log model, not levels)</li>
<li>Applying adjustment to coefficients (only for predictions!)</li>
</ul>
<p><strong>Real-World Impact:</strong></p>
<p>In healthcare cost prediction:</p>
<ul>
<li>Naive: Predict average cost = $8,000</li>
<li>Adjusted: Predict average cost = $10,000</li>
<li><strong>25% underestimate!</strong></li>
<li>Budget shortfall, inadequate insurance premiums</li>
</ul>
<p>In income tax revenue forecasting:</p>
<ul>
<li>Small % bias in individual predictions</li>
<li>Aggregated to millions of taxpayers</li>
<li>Billions of dollars in forecast error!</li>
</ul>
</section>
<section id="visualization-prediction-comparison" class="level3">
<h3 class="anchored" data-anchor-id="visualization-prediction-comparison">Visualization: Prediction Comparison</h3>
<div id="cell-50" class="cell" data-execution_count="22">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize prediction accuracy</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">5</span>))</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot 1: Levels model</span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].scatter(data_earnings[<span class="st">'earnings'</span>], linear_predict, alpha<span class="op">=</span><span class="fl">0.5</span>, s<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].plot([<span class="dv">0</span>, <span class="dv">500000</span>], [<span class="dv">0</span>, <span class="dv">500000</span>], <span class="st">'r--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_xlabel(<span class="st">'Actual Earnings ($)'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_ylabel(<span class="st">'Predicted Earnings ($)'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].set_title(<span class="st">'Levels Model Predictions'</span>, fontsize<span class="op">=</span><span class="dv">12</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot 2: Biased retransformation</span></span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].scatter(data_earnings[<span class="st">'earnings'</span>], biased_predict, alpha<span class="op">=</span><span class="fl">0.5</span>, s<span class="op">=</span><span class="dv">30</span>, color<span class="op">=</span><span class="st">'orange'</span>)</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].plot([<span class="dv">0</span>, <span class="dv">500000</span>], [<span class="dv">0</span>, <span class="dv">500000</span>], <span class="st">'r--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_xlabel(<span class="st">'Actual Earnings ($)'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_ylabel(<span class="st">'Predicted Earnings ($)'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].set_title(<span class="st">'Log-Linear: Biased (Naive) Retransformation'</span>, fontsize<span class="op">=</span><span class="dv">12</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">1</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot 3: Adjusted retransformation</span></span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].scatter(data_earnings[<span class="st">'earnings'</span>], adjusted_predict, alpha<span class="op">=</span><span class="fl">0.5</span>, s<span class="op">=</span><span class="dv">30</span>, color<span class="op">=</span><span class="st">'green'</span>)</span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].plot([<span class="dv">0</span>, <span class="dv">500000</span>], [<span class="dv">0</span>, <span class="dv">500000</span>], <span class="st">'r--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_xlabel(<span class="st">'Actual Earnings ($)'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_ylabel(<span class="st">'Predicted Earnings ($)'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].set_title(<span class="st">'Log-Linear: Adjusted Retransformation'</span>, fontsize<span class="op">=</span><span class="dv">12</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">2</span>].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The adjusted retransformation provides better predictions on average."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ch15_Regression_with_Transformed_Variables_files/figure-html/cell-18-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>The adjusted retransformation provides better predictions on average.</code></pre>
</div>
</div>
<p><em>Having addressed the retransformation bias problem, we now combine all transformation techniques in a single comprehensive model.</em></p>
</section>
</section>
<section id="comprehensive-model-with-mixed-regressors" class="level2">
<h2 class="anchored" data-anchor-id="comprehensive-model-with-mixed-regressors">15.7: Comprehensive Model with Mixed Regressors</h2>
<div id="cell-53" class="cell" data-execution_count="23">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"COMPREHENSIVE MODEL WITH MIXED REGRESSOR TYPES"</span>)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Log-transformed dependent variable</span></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Log-Linear Model with Mixed Regressors:"</span>)</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"lnearnings ~ gender + age + agesq + education + dself + dgovt + lnhours"</span>)</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>ols_log_mix <span class="op">=</span> ols(<span class="st">'lnearnings ~ gender + age + agesq + education + dself + dgovt + lnhours'</span>,</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>                  data<span class="op">=</span>data_earnings).fit(cov_type<span class="op">=</span><span class="st">'HC1'</span>)</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ols_log_mix.summary())</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"INTERPRETATION OF COEFFICIENTS (controlling for other regressors)"</span>)</span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span><span class="op">*</span><span class="dv">70</span>)</span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">1. Gender: </span><span class="sc">{</span>ols_log_mix<span class="sc">.</span>params[<span class="st">'gender'</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Women earn approximately </span><span class="sc">{</span><span class="dv">100</span><span class="op">*</span>ols_log_mix<span class="sc">.</span>params[<span class="st">'gender'</span>]<span class="sc">:.1f}</span><span class="ss">% less than men"</span>)</span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">2. Age and Age²: Quadratic relationship"</span>)</span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a>b_age_log <span class="op">=</span> ols_log_mix.params[<span class="st">'age'</span>]</span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a>b_agesq_log <span class="op">=</span> ols_log_mix.params[<span class="st">'agesq'</span>]</span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a>turning_point_log <span class="op">=</span> <span class="op">-</span>b_age_log <span class="op">/</span> (<span class="dv">2</span> <span class="op">*</span> b_agesq_log)</span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Turning point: </span><span class="sc">{</span>turning_point_log<span class="sc">:.1f}</span><span class="ss"> years"</span>)</span>
<span id="cb37-26"><a href="#cb37-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Earnings increase with age until </span><span class="sc">{</span>turning_point_log<span class="sc">:.1f}</span><span class="ss">, then decrease"</span>)</span>
<span id="cb37-27"><a href="#cb37-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-28"><a href="#cb37-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">3. Education: </span><span class="sc">{</span>ols_log_mix<span class="sc">.</span>params[<span class="st">'education'</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb37-29"><a href="#cb37-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   One additional year of education increases earnings by </span><span class="sc">{</span><span class="dv">100</span><span class="op">*</span>ols_log_mix<span class="sc">.</span>params[<span class="st">'education'</span>]<span class="sc">:.1f}</span><span class="ss">%"</span>)</span>
<span id="cb37-30"><a href="#cb37-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-31"><a href="#cb37-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">4. Self-employed (dself): </span><span class="sc">{</span>ols_log_mix<span class="sc">.</span>params[<span class="st">'dself'</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb37-32"><a href="#cb37-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Self-employed earn approximately </span><span class="sc">{</span><span class="dv">100</span><span class="op">*</span>ols_log_mix<span class="sc">.</span>params[<span class="st">'dself'</span>]<span class="sc">:.1f}</span><span class="ss">% less than private sector"</span>)</span>
<span id="cb37-33"><a href="#cb37-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   (though not statistically significant at 5% level)"</span>)</span>
<span id="cb37-34"><a href="#cb37-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-35"><a href="#cb37-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">5. Government (dgovt): </span><span class="sc">{</span>ols_log_mix<span class="sc">.</span>params[<span class="st">'dgovt'</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb37-36"><a href="#cb37-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Government workers earn approximately </span><span class="sc">{</span><span class="dv">100</span><span class="op">*</span>ols_log_mix<span class="sc">.</span>params[<span class="st">'dgovt'</span>]<span class="sc">:.1f}</span><span class="ss">% more than private sector"</span>)</span>
<span id="cb37-37"><a href="#cb37-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   (though not statistically significant at 5% level)"</span>)</span>
<span id="cb37-38"><a href="#cb37-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-39"><a href="#cb37-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">6. Ln(Hours): </span><span class="sc">{</span>ols_log_mix<span class="sc">.</span>params[<span class="st">'lnhours'</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb37-40"><a href="#cb37-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   This is an ELASTICITY: A 1% increase in hours increases earnings by </span><span class="sc">{</span>ols_log_mix<span class="sc">.</span>params[<span class="st">'lnhours'</span>]<span class="sc">:.3f}</span><span class="ss">%"</span>)</span>
<span id="cb37-41"><a href="#cb37-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"   Nearly proportional relationship (elasticity ≈ 1)"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>======================================================================
COMPREHENSIVE MODEL WITH MIXED REGRESSOR TYPES
======================================================================

----------------------------------------------------------------------
Log-Linear Model with Mixed Regressors:
lnearnings ~ gender + age + agesq + education + dself + dgovt + lnhours
----------------------------------------------------------------------
                            OLS Regression Results                            
==============================================================================
Dep. Variable:             lnearnings   R-squared:                       0.281
Model:                            OLS   Adj. R-squared:                  0.275
Method:                 Least Squares   F-statistic:                     35.04
Date:                Wed, 21 Jan 2026   Prob (F-statistic):           3.62e-43
Time:                        14:40:55   Log-Likelihood:                -761.92
No. Observations:                 872   AIC:                             1540.
Df Residuals:                     864   BIC:                             1578.
Df Model:                           7                                         
Covariance Type:                  HC1                                         
==============================================================================
                 coef    std err          z      P&gt;|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept      4.4594      0.648      6.885      0.000       3.190       5.729
gender        -0.1928      0.039     -4.881      0.000      -0.270      -0.115
age            0.0561      0.016      3.550      0.000       0.025       0.087
agesq         -0.0005      0.000     -2.992      0.003      -0.001      -0.000
education      0.0934      0.008     11.168      0.000       0.077       0.110
dself         -0.1180      0.101     -1.166      0.243      -0.316       0.080
dgovt          0.0698      0.045      1.534      0.125      -0.019       0.159
lnhours        0.9754      0.142      6.882      0.000       0.698       1.253
==============================================================================
Omnibus:                       29.695   Durbin-Watson:                   2.054
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               74.613
Skew:                           0.025   Prob(JB):                     6.28e-17
Kurtosis:                       4.432   Cond. No.                     6.41e+04
==============================================================================

Notes:
[1] Standard Errors are heteroscedasticity robust (HC1)
[2] The condition number is large, 6.41e+04. This might indicate that there are
strong multicollinearity or other numerical problems.

----------------------------------------------------------------------
INTERPRETATION OF COEFFICIENTS (controlling for other regressors)
----------------------------------------------------------------------

1. Gender: -0.1928
   Women earn approximately -19.3% less than men

2. Age and Age²: Quadratic relationship
   Turning point: 51.1 years
   Earnings increase with age until 51.1, then decrease

3. Education: 0.0934
   One additional year of education increases earnings by 9.3%

4. Self-employed (dself): -0.1180
   Self-employed earn approximately -11.8% less than private sector
   (though not statistically significant at 5% level)

5. Government (dgovt): 0.0698
   Government workers earn approximately 7.0% more than private sector
   (though not statistically significant at 5% level)

6. Ln(Hours): 0.9754
   This is an ELASTICITY: A 1% increase in hours increases earnings by 0.975%
   Nearly proportional relationship (elasticity ≈ 1)</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p><strong>Key Concept 15.8: Models with Mixed Regressor Types</strong></p>
<p>A single regression model can combine <strong>levels, quadratics, logarithms, dummies, and interactions</strong>. Each coefficient is interpreted according to its transformation type: linear coefficients as marginal effects, log coefficients as semi-elasticities or elasticities, quadratic terms through their marginal effect formula, and dummies as group differences. This flexibility makes regression a powerful tool for modeling complex economic relationships.</p>
</blockquote>
</section>
<section id="key-takeaways" class="level2">
<h2 class="anchored" data-anchor-id="key-takeaways">Key Takeaways</h2>
<section id="logarithmic-transformations-1" class="level3">
<h3 class="anchored" data-anchor-id="logarithmic-transformations-1">Logarithmic Transformations</h3>
<ul>
<li><strong>Log-linear model</strong> (<span class="math inline">\(\ln y = \beta_1 + \beta_2 x\)</span>): coefficient <span class="math inline">\(\beta_2\)</span> is a <strong>semi-elasticity</strong> – a 1-unit change in <span class="math inline">\(x\)</span> is associated with a <span class="math inline">\(100 \times \beta_2\)</span>% change in <span class="math inline">\(y\)</span></li>
<li><strong>Log-log model</strong> (<span class="math inline">\(\ln y = \beta_1 + \beta_2 \ln x\)</span>): coefficient <span class="math inline">\(\beta_2\)</span> is an <strong>elasticity</strong> – a 1% change in <span class="math inline">\(x\)</span> is associated with a <span class="math inline">\(\beta_2\)</span>% change in <span class="math inline">\(y\)</span></li>
<li>Marginal effects in levels require back-transformation: <span class="math inline">\(ME_x = \beta_2 \hat{y}\)</span> (log-linear) or <span class="math inline">\(ME_x = \beta_2 \hat{y}/x\)</span> (log-log)</li>
<li>Log transformations are especially useful for right-skewed data (earnings, prices, GDP)</li>
</ul>
</section>
<section id="quadratic-and-polynomial-models" class="level3">
<h3 class="anchored" data-anchor-id="quadratic-and-polynomial-models">Quadratic and Polynomial Models</h3>
<ul>
<li>Quadratic models <span class="math inline">\(y = \beta_1 + \beta_2 x + \beta_3 x^2 + u\)</span> capture <strong>nonlinear relationships</strong> with a turning point</li>
<li><strong>Turning point</strong>: <span class="math inline">\(x^* = -\beta_2 / (2\beta_3)\)</span> – where the relationship changes direction</li>
<li>Marginal effect varies with <span class="math inline">\(x\)</span>: <span class="math inline">\(ME = \beta_2 + 2\beta_3 x\)</span> – not constant as in linear models</li>
<li>If <span class="math inline">\(\beta_3 &lt; 0\)</span>: inverted U-shape (earnings-age); if <span class="math inline">\(\beta_3 &gt; 0\)</span>: U-shape</li>
<li>Always test <strong>joint significance</strong> of <span class="math inline">\(x\)</span> and <span class="math inline">\(x^2\)</span> together</li>
</ul>
</section>
<section id="standardized-coefficients" class="level3">
<h3 class="anchored" data-anchor-id="standardized-coefficients">Standardized Coefficients</h3>
<ul>
<li><strong>Standardized (beta) coefficients</strong> measure effects in standard deviation units: <span class="math inline">\(\beta^* = \beta \times (s_x / s_y)\)</span></li>
<li>Allow comparing the <strong>relative importance</strong> of variables measured in different units</li>
<li>A one-standard-deviation increase in <span class="math inline">\(x\)</span> is associated with a <span class="math inline">\(\beta^*\)</span> standard-deviation change in <span class="math inline">\(y\)</span></li>
<li>Useful for ranking which variables have the strongest effect on the outcome</li>
</ul>
</section>
<section id="interaction-terms-and-marginal-effects-1" class="level3">
<h3 class="anchored" data-anchor-id="interaction-terms-and-marginal-effects-1">Interaction Terms and Marginal Effects</h3>
<ul>
<li><strong>Interaction terms</strong> (<span class="math inline">\(x \times z\)</span>) allow the marginal effect of <span class="math inline">\(x\)</span> to depend on <span class="math inline">\(z\)</span>: <span class="math inline">\(ME_x = \beta_2 + \beta_4 z\)</span></li>
<li>Individual coefficients may be insignificant due to multicollinearity with the interaction</li>
<li>Always use <strong>joint F-tests</strong> to assess overall significance of a variable and its interactions</li>
<li>Example: Returns to education may increase with age (positive interaction coefficient)</li>
</ul>
</section>
<section id="retransformation-bias-and-prediction-1" class="level3">
<h3 class="anchored" data-anchor-id="retransformation-bias-and-prediction-1">Retransformation Bias and Prediction</h3>
<ul>
<li><strong>Naive prediction</strong> <span class="math inline">\(\exp(\widehat{\ln y})\)</span> systematically <strong>underestimates</strong> <span class="math inline">\(E[y|x]\)</span> due to Jensen’s inequality</li>
<li><strong>Correction</strong>: multiply by <span class="math inline">\(\exp(s_e^2 / 2)\)</span> where <span class="math inline">\(s_e\)</span> is the standard error of the log regression</li>
<li><strong>Duan’s smearing estimator</strong> provides a nonparametric alternative that doesn’t assume normality</li>
<li>Cannot directly compare <span class="math inline">\(R^2\)</span> across models with different dependent variables (<span class="math inline">\(y\)</span> vs <span class="math inline">\(\ln y\)</span>)</li>
</ul>
</section>
<section id="general-lessons" class="level3">
<h3 class="anchored" data-anchor-id="general-lessons">General Lessons</h3>
<ul>
<li>A single model can combine <strong>levels, quadratics, logs, dummies, and interactions</strong> – interpret each coefficient according to its transformation type</li>
<li>Variable transformations are among the most powerful tools for capturing realistic economic relationships</li>
<li>Always check whether nonlinear specifications improve model fit before adopting more complex forms</li>
</ul>
<hr>
</section>
<section id="python-tools-used-in-this-chapter" class="level3">
<h3 class="anchored" data-anchor-id="python-tools-used-in-this-chapter">Python Tools Used in This Chapter</h3>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Log transformations</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>np.log(df[<span class="st">'variable'</span>])                    <span class="co"># Natural logarithm</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Quadratic terms</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'x_sq'</span>] <span class="op">=</span> df[<span class="st">'x'</span>] <span class="op">**</span> <span class="dv">2</span>                <span class="co"># Create squared term</span></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Interaction terms</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'x_z'</span>] <span class="op">=</span> df[<span class="st">'x'</span>] <span class="op">*</span> df[<span class="st">'z'</span>]            <span class="co"># Create interaction</span></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Standardized coefficients</span></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>beta_star <span class="op">=</span> beta <span class="op">*</span> (s_x <span class="op">/</span> s_y)           <span class="co"># Manual calculation</span></span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Joint hypothesis tests</span></span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>model.f_test(<span class="st">'x = 0, x_sq = 0'</span>)          <span class="co"># Joint F-test</span></span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Retransformation correction</span></span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> np.exp(ln_y_hat) <span class="op">*</span> np.exp(s_e<span class="op">**</span><span class="dv">2</span> <span class="op">/</span> <span class="dv">2</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<hr>
<p><strong>Next Steps:</strong></p>
<ul>
<li><strong>Chapter 16:</strong> Model Diagnostics</li>
<li><strong>Chapter 17:</strong> Panel Data and Causation</li>
</ul>
<hr>
<p><strong>Congratulations!</strong> You’ve completed Chapter 15. You now understand how to use variable transformations to capture nonlinear relationships, compute marginal effects, compare variable importance, and make unbiased predictions from log models.</p>
</section>
</section>
<section id="practice-exercises" class="level2">
<h2 class="anchored" data-anchor-id="practice-exercises">Practice Exercises</h2>
<p><strong>Exercise 1: Marginal Effect of a Quadratic</strong></p>
<p>For the fitted model <span class="math inline">\(\hat{y} = 2 + 3x + 4x^2\)</span> from a dataset with <span class="math inline">\(\bar{y} = 30\)</span> and <span class="math inline">\(\bar{x} = 2\)</span>:</p>
<p><strong>(a)</strong> Compute the marginal effect of a one-unit change in <span class="math inline">\(x\)</span> at <span class="math inline">\(x = 2\)</span> using calculus.</p>
<p><strong>(b)</strong> Compute the average marginal effect (AME) if the data contains observations at <span class="math inline">\(x = 1, 2, 3\)</span>.</p>
<p><strong>(c)</strong> Is this relationship U-shaped or inverted U-shaped? At what value of <span class="math inline">\(x\)</span> is the turning point?</p>
<hr>
<p><strong>Exercise 2: Interaction Marginal Effect</strong></p>
<p>For the fitted model <span class="math inline">\(\hat{y} = 1 + 2x + 4d + 7(d \times x)\)</span> from a dataset with <span class="math inline">\(\bar{y} = 22\)</span>, <span class="math inline">\(\bar{x} = 3\)</span>, and <span class="math inline">\(\bar{d} = 0.5\)</span>:</p>
<p><strong>(a)</strong> Compute the marginal effect of <span class="math inline">\(x\)</span> when <span class="math inline">\(d = 0\)</span> and when <span class="math inline">\(d = 1\)</span>.</p>
<p><strong>(b)</strong> Compute the average marginal effect (AME) of <span class="math inline">\(x\)</span>.</p>
<p><strong>(c)</strong> Interpret the coefficient 7 on the interaction term in plain language.</p>
<hr>
<p><strong>Exercise 3: Retransformation Prediction</strong></p>
<p>For the model <span class="math inline">\(\widehat{\ln y} = 1 + 2x\)</span> with <span class="math inline">\(n = 100\)</span> and <span class="math inline">\(s_e = 0.3\)</span>:</p>
<p><strong>(a)</strong> Give the naive prediction of <span class="math inline">\(E[y|x = 1]\)</span>.</p>
<p><strong>(b)</strong> Give the bias-corrected prediction using the normal correction factor.</p>
<p><strong>(c)</strong> By what percentage does the naive prediction underestimate the true expected value?</p>
<hr>
<p><strong>Exercise 4: Log Model Interpretation</strong></p>
<p>A researcher estimates two models using earnings data:</p>
<ul>
<li>Log-linear: <span class="math inline">\(\widehat{\ln(\text{earnings})} = 8.5 + 0.08 \times \text{education}\)</span></li>
<li>Log-log: <span class="math inline">\(\widehat{\ln(\text{earnings})} = 3.2 + 0.45 \times \ln(\text{hours})\)</span></li>
</ul>
<p><strong>(a)</strong> Interpret the coefficient 0.08 in the log-linear model.</p>
<p><strong>(b)</strong> Interpret the coefficient 0.45 in the log-log model.</p>
<p><strong>(c)</strong> Can you directly compare <span class="math inline">\(R^2\)</span> between these two models? Why or why not?</p>
<hr>
<p><strong>Exercise 5: Standardized Coefficient Ranking</strong></p>
<p>A regression of earnings on age, education, and hours yields these unstandardized coefficients and standard deviations:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Variable</th>
<th>Coefficient</th>
<th><span class="math inline">\(s_x\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Age</td>
<td>500</td>
<td>10</td>
</tr>
<tr class="even">
<td>Education</td>
<td>3,000</td>
<td>3</td>
</tr>
<tr class="odd">
<td>Hours</td>
<td>200</td>
<td>8</td>
</tr>
</tbody>
</table>
<p>The standard deviation of earnings is <span class="math inline">\(s_y = 25{,}000\)</span>.</p>
<p><strong>(a)</strong> Compute the standardized coefficient for each variable.</p>
<p><strong>(b)</strong> Rank the variables by their relative importance.</p>
<p><strong>(c)</strong> Why might the ranking differ from what the unstandardized coefficients suggest?</p>
<hr>
<p><strong>Exercise 6: Model Selection</strong></p>
<p>You have three candidate models for earnings:</p>
<ul>
<li>Model A (linear): <span class="math inline">\(\text{earnings} = \beta_1 + \beta_2 \text{age} + u\)</span></li>
<li>Model B (quadratic): <span class="math inline">\(\text{earnings} = \beta_1 + \beta_2 \text{age} + \beta_3 \text{age}^2 + u\)</span></li>
<li>Model C (log-linear): <span class="math inline">\(\ln(\text{earnings}) = \beta_1 + \beta_2 \text{age} + u\)</span></li>
</ul>
<p><strong>(a)</strong> What criteria would you use to compare Models A and B? Can you use <span class="math inline">\(R^2\)</span>?</p>
<p><strong>(b)</strong> Can you directly compare <span class="math inline">\(R^2\)</span> between Models B and C? Explain.</p>
<p><strong>(c)</strong> Describe a prediction-based approach to compare all three models.</p>
</section>
<section id="case-studies" class="level2">
<h2 class="anchored" data-anchor-id="case-studies">Case Studies</h2>
<section id="case-study-1-transformed-variables-for-cross-country-productivity-analysis" class="level3">
<h3 class="anchored" data-anchor-id="case-study-1-transformed-variables-for-cross-country-productivity-analysis">Case Study 1: Transformed Variables for Cross-Country Productivity Analysis</h3>
<p>In this case study, you will apply variable transformation techniques to analyze cross-country labor productivity patterns and determine the best functional form for modeling productivity determinants.</p>
<p><strong>Dataset:</strong> Mendez Convergence Clubs</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">"https://raw.githubusercontent.com/quarcs-lab/mendez2020-convergence-clubs-code-data/master/assets/dat.csv"</span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>dat <span class="op">=</span> pd.read_csv(url)</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>dat2014 <span class="op">=</span> dat[dat[<span class="st">'year'</span>] <span class="op">==</span> <span class="dv">2014</span>].copy()</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>dat2014[<span class="st">'ln_lp'</span>] <span class="op">=</span> np.log(dat2014[<span class="st">'lp'</span>])</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>dat2014[<span class="st">'ln_rk'</span>] <span class="op">=</span> np.log(dat2014[<span class="st">'rk'</span>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Variables:</strong> <code>lp</code> (labor productivity), <code>rk</code> (physical capital), <code>hc</code> (human capital), <code>region</code> (world region)</p>
<hr>
<section id="task-1-compare-log-specifications-guided" class="level4">
<h4 class="anchored" data-anchor-id="task-1-compare-log-specifications-guided">Task 1: Compare Log Specifications (Guided)</h4>
<p>Estimate three models of labor productivity on physical capital:</p>
<ul>
<li>Levels: <code>lp ~ rk</code></li>
<li>Log-linear: <code>ln_lp ~ rk</code></li>
<li>Log-log: <code>ln_lp ~ ln_rk</code></li>
</ul>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>m1 <span class="op">=</span> smf.ols(<span class="st">'lp ~ rk'</span>, data<span class="op">=</span>dat2014).fit(cov_type<span class="op">=</span><span class="st">'HC1'</span>)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>m2 <span class="op">=</span> smf.ols(<span class="st">'ln_lp ~ rk'</span>, data<span class="op">=</span>dat2014).fit(cov_type<span class="op">=</span><span class="st">'HC1'</span>)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>m3 <span class="op">=</span> smf.ols(<span class="st">'ln_lp ~ ln_rk'</span>, data<span class="op">=</span>dat2014).fit(cov_type<span class="op">=</span><span class="st">'HC1'</span>)</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(m1.summary(), m2.summary(), m3.summary())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Questions:</strong> How do you interpret the coefficient on capital in each model? Which specification seems most appropriate for cross-country data?</p>
<hr>
</section>
<section id="task-2-quadratic-human-capital-guided" class="level4">
<h4 class="anchored" data-anchor-id="task-2-quadratic-human-capital-guided">Task 2: Quadratic Human Capital (Guided)</h4>
<p>Test whether the returns to human capital follow a nonlinear (quadratic) pattern.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>dat2014[<span class="st">'hc_sq'</span>] <span class="op">=</span> dat2014[<span class="st">'hc'</span>] <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>m4 <span class="op">=</span> smf.ols(<span class="st">'ln_lp ~ ln_rk + hc'</span>, data<span class="op">=</span>dat2014).fit(cov_type<span class="op">=</span><span class="st">'HC1'</span>)</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>m5 <span class="op">=</span> smf.ols(<span class="st">'ln_lp ~ ln_rk + hc + hc_sq'</span>, data<span class="op">=</span>dat2014).fit(cov_type<span class="op">=</span><span class="st">'HC1'</span>)</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(m5.summary())</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Turning point: hc* = </span><span class="sc">{</span><span class="op">-</span>m5<span class="sc">.</span>params[<span class="st">'hc'</span>] <span class="op">/</span> (<span class="dv">2</span><span class="op">*</span>m5.params[<span class="st">'hc_sq'</span>])<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Questions:</strong> Is the quadratic term significant? What does the turning point imply about diminishing returns to human capital?</p>
<blockquote class="blockquote">
<p><strong>Key Concept 15.9: Nonlinear Returns to Human Capital</strong></p>
<p>If the quadratic term on human capital is negative and significant, it indicates <strong>diminishing returns</strong> – each additional unit of human capital contributes less to productivity. The turning point <span class="math inline">\(hc^* = -\beta_{hc}/(2\beta_{hc^2})\)</span> identifies the level beyond which further human capital accumulation has decreasing marginal returns.</p>
</blockquote>
<hr>
</section>
<section id="task-3-standardized-coefficients-semi-guided" class="level4">
<h4 class="anchored" data-anchor-id="task-3-standardized-coefficients-semi-guided">Task 3: Standardized Coefficients (Semi-guided)</h4>
<p>Compare the relative importance of physical capital vs.&nbsp;human capital in determining productivity.</p>
<p><strong>Hints:</strong></p>
<ul>
<li>Compute standardized coefficients: <span class="math inline">\(\beta^* = \beta \times (s_x / s_y)\)</span></li>
<li>Use the log-log model for physical capital and levels for human capital</li>
<li>Which input has a larger effect in standard deviation terms?</li>
</ul>
<hr>
</section>
<section id="task-4-regional-interactions-semi-guided" class="level4">
<h4 class="anchored" data-anchor-id="task-4-regional-interactions-semi-guided">Task 4: Regional Interactions (Semi-guided)</h4>
<p>Test whether the returns to human capital differ by region using interaction terms.</p>
<p><strong>Hints:</strong></p>
<ul>
<li>Use <code>ln_lp ~ ln_rk + hc * C(region)</code> to include region-hc interactions</li>
<li>Conduct a joint F-test for the interaction terms</li>
<li>At which values of human capital are regional differences largest?</li>
</ul>
<blockquote class="blockquote">
<p><strong>Key Concept 15.10: Heterogeneous Returns Across Regions</strong></p>
<p>Interaction terms between human capital and regional indicators allow the <strong>marginal effect of human capital to vary by region</strong>. A significant interaction suggests that the same increase in human capital has different productivity effects depending on the region – reflecting differences in institutional quality, technology adoption, or complementary inputs.</p>
</blockquote>
<hr>
</section>
<section id="task-5-predictions-with-bias-correction-independent" class="level4">
<h4 class="anchored" data-anchor-id="task-5-predictions-with-bias-correction-independent">Task 5: Predictions with Bias Correction (Independent)</h4>
<p>Using the log-log model, predict productivity for countries with specific capital and human capital levels. Apply the retransformation bias correction.</p>
<p>Compare naive predictions <span class="math inline">\(\exp(\widehat{\ln lp})\)</span> with corrected predictions <span class="math inline">\(\exp(\widehat{\ln lp} + s_e^2/2)\)</span>.</p>
<hr>
</section>
<section id="task-6-policy-brief-on-functional-form-independent" class="level4">
<h4 class="anchored" data-anchor-id="task-6-policy-brief-on-functional-form-independent">Task 6: Policy Brief on Functional Form (Independent)</h4>
<p>Write a 200-300 word brief addressing:</p>
<ul>
<li>Which functional form best captures the productivity-capital relationship?</li>
<li>Is there evidence of diminishing returns to human capital?</li>
<li>Do returns to inputs differ across regions, and what are the policy implications?</li>
<li>How important is the retransformation bias correction for practical predictions?</li>
</ul>
<hr>
<p><strong>What You’ve Learned:</strong> You have applied multiple variable transformation techniques to cross-country data, demonstrating that log specifications better capture productivity relationships, returns to human capital may be nonlinear, and regional interactions reveal important heterogeneity in development patterns.</p>
</section>
</section>
<section id="case-study-2-nonlinear-satellite-development-relationships" class="level3">
<h3 class="anchored" data-anchor-id="case-study-2-nonlinear-satellite-development-relationships">Case Study 2: Nonlinear Satellite-Development Relationships</h3>
<p><strong>Research Question</strong>: What is the best functional form for modeling the relationship between satellite nighttime lights and municipal development in Bolivia?</p>
<p><strong>Background</strong>: In previous chapters, we estimated <em>linear</em> regressions of development on NTL. But the relationship may be nonlinear—additional nighttime lights may have diminishing effects on development. In this case study, we apply Chapter 15’s <strong>transformation</strong> tools to explore functional form choices for the satellite-development relationship.</p>
<p><strong>The Data</strong>: The DS4Bolivia dataset covers 339 Bolivian municipalities with satellite data, development indices, and socioeconomic indicators.</p>
<p><strong>Key Variables</strong>:</p>
<ul>
<li><code>mun</code>: Municipality name</li>
<li><code>dep</code>: Department (administrative region)</li>
<li><code>imds</code>: Municipal Sustainable Development Index (0-100)</li>
<li><code>ln_NTLpc2017</code>: Log nighttime lights per capita (2017)</li>
<li><code>sdg7_1_ec</code>: Electricity coverage (SDG 7 indicator)</li>
</ul>
<section id="load-the-ds4bolivia-data" class="level4">
<h4 class="anchored" data-anchor-id="load-the-ds4bolivia-data">Load the DS4Bolivia Data</h4>
<div id="cell-60" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the DS4Bolivia dataset</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.formula.api <span class="im">import</span> ols</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>url_bol <span class="op">=</span> <span class="st">"https://raw.githubusercontent.com/quarcs-lab/ds4bolivia/master/ds4bolivia_v20250523.csv"</span></span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>bol <span class="op">=</span> pd.read_csv(url_bol)</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Select key variables for this case study</span></span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>key_vars <span class="op">=</span> [<span class="st">'mun'</span>, <span class="st">'dep'</span>, <span class="st">'imds'</span>, <span class="st">'ln_NTLpc2017'</span>, <span class="st">'sdg7_1_ec'</span>]</span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>bol_cs <span class="op">=</span> bol[key_vars].copy()</span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Create raw NTL variable from log</span></span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a>bol_cs[<span class="st">'NTLpc2017_raw'</span>] <span class="op">=</span> np.exp(bol_cs[<span class="st">'ln_NTLpc2017'</span>])</span>
<span id="cb43-16"><a href="#cb43-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-17"><a href="#cb43-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb43-18"><a href="#cb43-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"DS4BOLIVIA: TRANSFORMED VARIABLES CASE STUDY"</span>)</span>
<span id="cb43-19"><a href="#cb43-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb43-20"><a href="#cb43-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Observations: </span><span class="sc">{</span><span class="bu">len</span>(bol_cs)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb43-21"><a href="#cb43-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Key variable summary:"</span>)</span>
<span id="cb43-22"><a href="#cb43-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(bol_cs[[<span class="st">'imds'</span>, <span class="st">'ln_NTLpc2017'</span>, <span class="st">'NTLpc2017_raw'</span>, <span class="st">'sdg7_1_ec'</span>]].describe().<span class="bu">round</span>(<span class="dv">3</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="task-1-compare-log-specifications-guided-1" class="level4">
<h4 class="anchored" data-anchor-id="task-1-compare-log-specifications-guided-1">Task 1: Compare Log Specifications (Guided)</h4>
<p><strong>Objective</strong>: Estimate four regression specifications and compare functional forms.</p>
<p><strong>Instructions</strong>:</p>
<ol type="1">
<li>Estimate four models:
<ul>
<li><ol type="a">
<li><code>imds ~ ln_NTLpc2017</code> (level-log)</li>
</ol></li>
<li><ol start="2" type="a">
<li><code>np.log(imds) ~ ln_NTLpc2017</code> (log-log)</li>
</ol></li>
<li><ol start="3" type="a">
<li><code>imds ~ NTLpc2017_raw</code> (level-level)</li>
</ol></li>
<li><ol start="4" type="a">
<li><code>np.log(imds) ~ NTLpc2017_raw</code> (log-level)</li>
</ol></li>
</ul></li>
<li>Compare R² across specifications</li>
<li>Interpret the coefficient in each model (elasticity, semi-elasticity, or marginal effect)</li>
</ol>
<p><strong>Note</strong>: R² values are not directly comparable across models with different dependent variables (levels vs.&nbsp;logs).</p>
<div id="cell-62" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Your code here: Compare four functional form specifications</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Example structure:</span></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="co"># bol_reg = bol_cs[['imds', 'ln_NTLpc2017', 'NTLpc2017_raw']].dropna()</span></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a><span class="co"># bol_reg = bol_reg[bol_reg['imds'] &gt; 0]  # Ensure log is defined</span></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a><span class="co"># m_a = ols('imds ~ ln_NTLpc2017', data=bol_reg).fit(cov_type='HC1')</span></span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a><span class="co"># m_b = ols('np.log(imds) ~ ln_NTLpc2017', data=bol_reg).fit(cov_type='HC1')</span></span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a><span class="co"># m_c = ols('imds ~ NTLpc2017_raw', data=bol_reg).fit(cov_type='HC1')</span></span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a><span class="co"># m_d = ols('np.log(imds) ~ NTLpc2017_raw', data=bol_reg).fit(cov_type='HC1')</span></span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a><span class="co"># print("Model (a) Level-Log  R²:", m_a.rsquared.round(4))</span></span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a><span class="co"># print("Model (b) Log-Log    R²:", m_b.rsquared.round(4))</span></span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a><span class="co"># print("Model (c) Level-Level R²:", m_c.rsquared.round(4))</span></span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a><span class="co"># print("Model (d) Log-Level  R²:", m_d.rsquared.round(4))</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="task-2-quadratic-ntl-guided" class="level4">
<h4 class="anchored" data-anchor-id="task-2-quadratic-ntl-guided">Task 2: Quadratic NTL (Guided)</h4>
<p><strong>Objective</strong>: Test whether the NTL-development relationship exhibits diminishing returns.</p>
<p><strong>Instructions</strong>:</p>
<ol type="1">
<li>Estimate <code>imds ~ ln_NTLpc2017 + I(ln_NTLpc2017**2)</code></li>
<li>Test whether the quadratic term is statistically significant</li>
<li>Plot the fitted curve against the scatter plot of the data</li>
<li>Calculate the turning point: <span class="math inline">\(NTL^* = -\beta_1 / (2\beta_2)\)</span></li>
<li>Discuss: Is there evidence of diminishing returns to luminosity?</li>
</ol>
<div id="cell-64" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Your code here: Quadratic specification</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Example structure:</span></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a><span class="co"># m_quad = ols('imds ~ ln_NTLpc2017 + I(ln_NTLpc2017**2)', data=bol_reg).fit(cov_type='HC1')</span></span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a><span class="co"># print(m_quad.summary())</span></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a><span class="co"># # Turning point</span></span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a><span class="co"># b1 = m_quad.params['ln_NTLpc2017']</span></span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a><span class="co"># b2 = m_quad.params['I(ln_NTLpc2017 ** 2)']</span></span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"\nTurning point: ln_NTLpc = {-b1/(2*b2):.2f}")</span></span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a><span class="co"># # Plot fitted curve</span></span>
<span id="cb45-13"><a href="#cb45-13" aria-hidden="true" tabindex="-1"></a><span class="co"># x_range = np.linspace(bol_reg['ln_NTLpc2017'].min(), bol_reg['ln_NTLpc2017'].max(), 100)</span></span>
<span id="cb45-14"><a href="#cb45-14" aria-hidden="true" tabindex="-1"></a><span class="co"># y_hat = m_quad.params['Intercept'] + b1*x_range + b2*x_range**2</span></span>
<span id="cb45-15"><a href="#cb45-15" aria-hidden="true" tabindex="-1"></a><span class="co"># fig, ax = plt.subplots(figsize=(10, 6))</span></span>
<span id="cb45-16"><a href="#cb45-16" aria-hidden="true" tabindex="-1"></a><span class="co"># ax.scatter(bol_reg['ln_NTLpc2017'], bol_reg['imds'], alpha=0.4, label='Data')</span></span>
<span id="cb45-17"><a href="#cb45-17" aria-hidden="true" tabindex="-1"></a><span class="co"># ax.plot(x_range, y_hat, 'r-', linewidth=2, label='Quadratic fit')</span></span>
<span id="cb45-18"><a href="#cb45-18" aria-hidden="true" tabindex="-1"></a><span class="co"># ax.set_xlabel('Log NTL per Capita (2017)')</span></span>
<span id="cb45-19"><a href="#cb45-19" aria-hidden="true" tabindex="-1"></a><span class="co"># ax.set_ylabel('IMDS')</span></span>
<span id="cb45-20"><a href="#cb45-20" aria-hidden="true" tabindex="-1"></a><span class="co"># ax.set_title('Quadratic NTL-Development Relationship')</span></span>
<span id="cb45-21"><a href="#cb45-21" aria-hidden="true" tabindex="-1"></a><span class="co"># ax.legend()</span></span>
<span id="cb45-22"><a href="#cb45-22" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.show()</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<blockquote class="blockquote">
<p><strong>Key Concept 15.11: Diminishing Returns to Luminosity</strong></p>
<p>A significant negative quadratic term for NTL suggests <strong>diminishing marginal returns</strong>: additional nighttime lights associate with progressively smaller development gains. In already-bright urban centers, more light reflects commercial excess rather than fundamental development improvement. This nonlinearity has practical implications: satellite-based predictions may be most accurate for municipalities in the middle of the luminosity distribution.</p>
</blockquote>
</section>
<section id="task-3-standardized-coefficients-semi-guided-1" class="level4">
<h4 class="anchored" data-anchor-id="task-3-standardized-coefficients-semi-guided-1">Task 3: Standardized Coefficients (Semi-guided)</h4>
<p><strong>Objective</strong>: Compare the relative importance of nighttime lights and electricity coverage for predicting development.</p>
<p><strong>Instructions</strong>:</p>
<ol type="1">
<li>Standardize <code>imds</code>, <code>ln_NTLpc2017</code>, and <code>sdg7_1_ec</code> to mean=0 and sd=1</li>
<li>Estimate the regression on standardized variables</li>
<li>Compare standardized coefficients: Which predictor has a larger effect in standard deviation terms?</li>
</ol>
<p><strong>Hint</strong>: Use <code>(x - x.mean()) / x.std()</code> to standardize each variable.</p>
<div id="cell-67" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Your code here: Standardized coefficients</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Example structure:</span></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a><span class="co"># bol_std = bol_cs[['imds', 'ln_NTLpc2017', 'sdg7_1_ec']].dropna()</span></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a><span class="co"># for col in ['imds', 'ln_NTLpc2017', 'sdg7_1_ec']:</span></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a><span class="co">#     bol_std[f'{col}_z'] = (bol_std[col] - bol_std[col].mean()) / bol_std[col].std()</span></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a><span class="co"># m_std = ols('imds_z ~ ln_NTLpc2017_z + sdg7_1_ec_z', data=bol_std).fit(cov_type='HC1')</span></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a><span class="co"># print(m_std.summary())</span></span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a><span class="co"># print("\nStandardized coefficients (beta weights):")</span></span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"  NTL:         {m_std.params['ln_NTLpc2017_z']:.4f}")</span></span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"  Electricity: {m_std.params['sdg7_1_ec_z']:.4f}")</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="task-4-interaction-ntl-x-electricity-semi-guided" class="level4">
<h4 class="anchored" data-anchor-id="task-4-interaction-ntl-x-electricity-semi-guided">Task 4: Interaction: NTL x Electricity (Semi-guided)</h4>
<p><strong>Objective</strong>: Test whether the effect of nighttime lights on development depends on electricity coverage.</p>
<p><strong>Instructions</strong>:</p>
<ol type="1">
<li>Estimate <code>imds ~ ln_NTLpc2017 * sdg7_1_ec</code></li>
<li>Interpret the interaction term: Does the NTL effect depend on electricity coverage?</li>
<li>Calculate the marginal effect of NTL at low (25th percentile) vs.&nbsp;high (75th percentile) electricity levels</li>
<li>Discuss: What does this interaction reveal about the satellite-development relationship?</li>
</ol>
<p><strong>Hint</strong>: The marginal effect of NTL is <span class="math inline">\(\beta_{NTL} + \beta_{interaction} \times electricity\)</span>.</p>
<div id="cell-69" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Your code here: Interaction model</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Example structure:</span></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a><span class="co"># m_int = ols('imds ~ ln_NTLpc2017 * sdg7_1_ec', data=bol_reg_full).fit(cov_type='HC1')</span></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a><span class="co"># print(m_int.summary())</span></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a><span class="co"># # Marginal effect at different electricity levels</span></span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a><span class="co"># elec_25 = bol_reg_full['sdg7_1_ec'].quantile(0.25)</span></span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a><span class="co"># elec_75 = bol_reg_full['sdg7_1_ec'].quantile(0.75)</span></span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a><span class="co"># me_low = m_int.params['ln_NTLpc2017'] + m_int.params['ln_NTLpc2017:sdg7_1_ec'] * elec_25</span></span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a><span class="co"># me_high = m_int.params['ln_NTLpc2017'] + m_int.params['ln_NTLpc2017:sdg7_1_ec'] * elec_75</span></span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"\nMarginal effect of NTL at low electricity ({elec_25:.1f}%): {me_low:.4f}")</span></span>
<span id="cb47-13"><a href="#cb47-13" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"Marginal effect of NTL at high electricity ({elec_75:.1f}%): {me_high:.4f}")</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<blockquote class="blockquote">
<p><strong>Key Concept 15.12: Elasticity of Development to Satellite Signals</strong></p>
<p>In a log-log specification (log IMDS ~ log NTL), the coefficient directly estimates the <strong>elasticity</strong>: the percentage change in development associated with a 1% increase in nighttime lights per capita. An elasticity of, say, 0.15 means a 10% increase in NTL per capita is associated with a 1.5% increase in IMDS. Elasticities provide scale-free comparisons across different variables and contexts.</p>
</blockquote>
</section>
<section id="task-5-predictions-with-retransformation-independent" class="level4">
<h4 class="anchored" data-anchor-id="task-5-predictions-with-retransformation-independent">Task 5: Predictions with Retransformation (Independent)</h4>
<p><strong>Objective</strong>: Generate predictions from the log-log model and apply the Duan smearing correction.</p>
<p><strong>Instructions</strong>:</p>
<ol type="1">
<li>Estimate the log-log model: <code>np.log(imds) ~ ln_NTLpc2017</code></li>
<li>Generate naive predictions: <span class="math inline">\(\exp(\widehat{\ln(imds)})\)</span></li>
<li>Apply the Duan smearing correction: multiply predictions by <span class="math inline">\(\bar{\exp(\hat{e})}\)</span> (the mean of exponentiated residuals)</li>
<li>Compare naive vs.&nbsp;corrected predictions</li>
<li>Discuss: How much does the retransformation correction matter?</li>
</ol>
<div id="cell-72" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Your code here: Retransformation bias correction</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Example structure:</span></span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a><span class="co"># m_loglog = ols('np.log(imds) ~ ln_NTLpc2017', data=bol_reg).fit(cov_type='HC1')</span></span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a><span class="co"># # Naive prediction</span></span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a><span class="co"># naive_pred = np.exp(m_loglog.fittedvalues)</span></span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a><span class="co"># # Duan smearing correction</span></span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a><span class="co"># smearing_factor = np.exp(m_loglog.resid).mean()</span></span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a><span class="co"># corrected_pred = naive_pred * smearing_factor</span></span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"Smearing factor: {smearing_factor:.4f}")</span></span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"Mean actual IMDS: {bol_reg['imds'].mean():.2f}")</span></span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"Mean naive prediction: {naive_pred.mean():.2f}")</span></span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"Mean corrected prediction: {corrected_pred.mean():.2f}")</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="task-6-functional-form-brief-independent" class="level4">
<h4 class="anchored" data-anchor-id="task-6-functional-form-brief-independent">Task 6: Functional Form Brief (Independent)</h4>
<p><strong>Objective</strong>: Write a 200-300 word brief summarizing your functional form analysis.</p>
<p><strong>Your brief should address</strong>:</p>
<ol type="1">
<li>Which specification best captures the satellite-development relationship?</li>
<li>Is there evidence of nonlinearity (diminishing returns)?</li>
<li>What are the elasticity estimates from the log-log model?</li>
<li>Does the interaction with electricity coverage reveal important heterogeneity?</li>
<li>How important is the retransformation correction for practical predictions?</li>
<li>Policy implications: What do the functional form results imply for using satellite data to monitor SDG progress?</li>
</ol>
<div id="cell-74" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Your code here: Additional analysis for the brief</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="co"># You might want to:</span></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Create a summary comparison table of all specifications</span></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Plot fitted values from different models on the same graph</span></span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Calculate and compare elasticities across specifications</span></span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Summarize key statistics to cite in your brief</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="what-youve-learned-from-this-case-study" class="level4">
<h4 class="anchored" data-anchor-id="what-youve-learned-from-this-case-study">What You’ve Learned from This Case Study</h4>
<p>Through this exploration of functional forms for the satellite-development relationship, you’ve applied Chapter 15’s transformation toolkit to real geospatial data:</p>
<ul>
<li><strong>Functional form comparison</strong>: Estimated level-level, level-log, log-level, and log-log specifications</li>
<li><strong>Nonlinearity detection</strong>: Used quadratic terms to test for diminishing returns to luminosity</li>
<li><strong>Standardized coefficients</strong>: Compared the relative importance of NTL and electricity coverage</li>
<li><strong>Interaction effects</strong>: Examined how electricity coverage moderates the NTL-development relationship</li>
<li><strong>Retransformation</strong>: Applied the Duan smearing correction to generate unbiased predictions from log models</li>
<li><strong>Critical thinking</strong>: Assessed which functional form best represents satellite-development patterns</li>
</ul>
<p><strong>Connection</strong>: In Chapter 16, we apply <em>diagnostic tools</em> to check whether our satellite prediction models satisfy regression assumptions.</p>
<hr>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../notebooks_colab/ch14_Regression_with_Indicator_Variables.html" class="pagination-link" aria-label="Chapter 14: Regression with Indicator Variables">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">Chapter 14: Regression with Indicator Variables</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../notebooks_colab/ch16_Checking_the_Model_and_Data.html" class="pagination-link" aria-label="Chapter 16: Checking the Model and Data">
        <span class="nav-page-text"><span class="chapter-title">Chapter 16: Checking the Model and Data</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>