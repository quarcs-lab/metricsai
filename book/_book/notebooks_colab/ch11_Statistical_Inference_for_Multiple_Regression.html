<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Chapter 11: Statistical Inference for Multiple Regression – Econometrics Powered by AI</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../notebooks_colab/ch12_Further_Topics_in_Multiple_Regression.html" rel="next">
<link href="../notebooks_colab/ch10_Data_Summary_for_Multiple_Regression.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-27c261d06b905028a18691de25d09dde.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../custom.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../notebooks_colab/ch10_Data_Summary_for_Multiple_Regression.html">Multiple Regression</a></li><li class="breadcrumb-item"><a href="../notebooks_colab/ch11_Statistical_Inference_for_Multiple_Regression.html"><span class="chapter-title">Chapter 11: Statistical Inference for Multiple Regression</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Econometrics Powered by AI</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch00_Preface.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Preface: Econometrics Powered by AI</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Statistical Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch01_Analysis_of_Economics_Data.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 1: Analysis of Economics Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch02_Univariate_Data_Summary.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 2: Univariate Data Summary</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch03_The_Sample_Mean.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 3: The Sample Mean</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch04_Statistical_Inference_for_the_Mean.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 4: Statistical Inference for the Mean</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Bivariate Regression</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch05_Bivariate_Data_Summary.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 5: Bivariate Data Summary</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch06_The_Least_Squares_Estimator.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 6: The Least Squares Estimator</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch07_Statistical_Inference_for_Bivariate_Regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 7: Statistical Inference for Bivariate Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch08_Case_Studies_for_Bivariate_Regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 8: Case Studies for Bivariate Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch09_Models_with_Natural_Logarithms.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 9: Models with Natural Logarithms</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Multiple Regression</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch10_Data_Summary_for_Multiple_Regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 10: Data Summary for Multiple Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch11_Statistical_Inference_for_Multiple_Regression.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">Chapter 11: Statistical Inference for Multiple Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch12_Further_Topics_in_Multiple_Regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 12: Further Topics in Multiple Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch13_Case_Studies_for_Multiple_Regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 13: Case Studies for Multiple Regression</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Advanced Topics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch14_Regression_with_Indicator_Variables.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 14: Regression with Indicator Variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch15_Regression_with_Transformed_Variables.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 15: Regression with Transformed Variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch16_Checking_the_Model_and_Data.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 16: Checking the Model and Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch17_Panel_Data_Time_Series_Data_Causation.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Chapter 17: Panel Data, Time Series Data, Causation</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#chapter-overview" id="toc-chapter-overview" class="nav-link active" data-scroll-target="#chapter-overview">Chapter Overview</a></li>
  <li><a href="#setup" id="toc-setup" class="nav-link" data-scroll-target="#setup">Setup</a></li>
  <li><a href="#data-preparation" id="toc-data-preparation" class="nav-link" data-scroll-target="#data-preparation">Data Preparation</a></li>
  <li><a href="#properties-of-the-least-squares-estimator" id="toc-properties-of-the-least-squares-estimator" class="nav-link" data-scroll-target="#properties-of-the-least-squares-estimator">11.1: Properties of the Least Squares Estimator</a></li>
  <li><a href="#estimators-of-model-parameters" id="toc-estimators-of-model-parameters" class="nav-link" data-scroll-target="#estimators-of-model-parameters">11.2: Estimators of Model Parameters</a></li>
  <li><a href="#interpreting-the-regression-results" id="toc-interpreting-the-regression-results" class="nav-link" data-scroll-target="#interpreting-the-regression-results">Interpreting the Regression Results</a></li>
  <li><a href="#model-diagnostics" id="toc-model-diagnostics" class="nav-link" data-scroll-target="#model-diagnostics">Model Diagnostics</a></li>
  <li><a href="#economic-interpretation" id="toc-economic-interpretation" class="nav-link" data-scroll-target="#economic-interpretation">Economic Interpretation</a></li>
  <li><a href="#confidence-intervals" id="toc-confidence-intervals" class="nav-link" data-scroll-target="#confidence-intervals">11.3: Confidence Intervals</a></li>
  <li><a href="#interpreting-the-confidence-intervals" id="toc-interpreting-the-confidence-intervals" class="nav-link" data-scroll-target="#interpreting-the-confidence-intervals">Interpreting the Confidence Intervals</a></li>
  <li><a href="#manual-calculation-of-confidence-interval" id="toc-manual-calculation-of-confidence-interval" class="nav-link" data-scroll-target="#manual-calculation-of-confidence-interval">Manual Calculation of Confidence Interval</a></li>
  <li><a href="#comprehensive-table-with-confidence-intervals" id="toc-comprehensive-table-with-confidence-intervals" class="nav-link" data-scroll-target="#comprehensive-table-with-confidence-intervals">Comprehensive Table with Confidence Intervals</a></li>
  <li><a href="#interpreting-the-hypothesis-test-result" id="toc-interpreting-the-hypothesis-test-result" class="nav-link" data-scroll-target="#interpreting-the-hypothesis-test-result">Interpreting the Hypothesis Test Result</a></li>
  <li><a href="#hypothesis-tests-on-a-single-parameter" id="toc-hypothesis-tests-on-a-single-parameter" class="nav-link" data-scroll-target="#hypothesis-tests-on-a-single-parameter">11.4: Hypothesis Tests on a Single Parameter</a></li>
  <li><a href="#test-of-statistical-significance-β-0" id="toc-test-of-statistical-significance-β-0" class="nav-link" data-scroll-target="#test-of-statistical-significance-β-0">Test of Statistical Significance (β = 0)</a></li>
  <li><a href="#using-statsmodels-t_test" id="toc-using-statsmodels-t_test" class="nav-link" data-scroll-target="#using-statsmodels-t_test">Using statsmodels t_test</a></li>
  <li><a href="#interpreting-the-overall-f-test" id="toc-interpreting-the-overall-f-test" class="nav-link" data-scroll-target="#interpreting-the-overall-f-test">Interpreting the Overall F-test</a></li>
  <li><a href="#interpreting-the-joint-test-of-subset-variables" id="toc-interpreting-the-joint-test-of-subset-variables" class="nav-link" data-scroll-target="#interpreting-the-joint-test-of-subset-variables">Interpreting the Joint Test of Subset Variables</a></li>
  <li><a href="#joint-hypothesis-tests" id="toc-joint-hypothesis-tests" class="nav-link" data-scroll-target="#joint-hypothesis-tests">11.5: Joint Hypothesis Tests</a></li>
  <li><a href="#interpreting-the-sum-of-squares-decomposition" id="toc-interpreting-the-sum-of-squares-decomposition" class="nav-link" data-scroll-target="#interpreting-the-sum-of-squares-decomposition">Interpreting the Sum of Squares Decomposition</a></li>
  <li><a href="#joint-test-of-subset-of-coefficients" id="toc-joint-test-of-subset-of-coefficients" class="nav-link" data-scroll-target="#joint-test-of-subset-of-coefficients">Joint Test of Subset of Coefficients</a></li>
  <li><a href="#interpreting-the-subset-f-test" id="toc-interpreting-the-subset-f-test" class="nav-link" data-scroll-target="#interpreting-the-subset-f-test">Interpreting the Subset F-test</a></li>
  <li><a href="#f-statistic-under-assumptions-1-4" id="toc-f-statistic-under-assumptions-1-4" class="nav-link" data-scroll-target="#f-statistic-under-assumptions-1-4">11.6: F Statistic Under Assumptions 1-4</a></li>
  <li><a href="#subset-f-test-restricted-vs-unrestricted-model" id="toc-subset-f-test-restricted-vs-unrestricted-model" class="nav-link" data-scroll-target="#subset-f-test-restricted-vs-unrestricted-model">Subset F-test: Restricted vs Unrestricted Model</a></li>
  <li><a href="#interpreting-the-model-comparison" id="toc-interpreting-the-model-comparison" class="nav-link" data-scroll-target="#interpreting-the-model-comparison">Interpreting the Model Comparison</a></li>
  <li><a href="#interpreting-coefficient-stability-across-models" id="toc-interpreting-coefficient-stability-across-models" class="nav-link" data-scroll-target="#interpreting-coefficient-stability-across-models">Interpreting Coefficient Stability Across Models</a></li>
  <li><a href="#manual-f-test-calculation" id="toc-manual-f-test-calculation" class="nav-link" data-scroll-target="#manual-f-test-calculation">Manual F-test Calculation</a></li>
  <li><a href="#interpreting-robust-standard-errors" id="toc-interpreting-robust-standard-errors" class="nav-link" data-scroll-target="#interpreting-robust-standard-errors">Interpreting Robust Standard Errors</a></li>
  <li><a href="#anova-table-comparison" id="toc-anova-table-comparison" class="nav-link" data-scroll-target="#anova-table-comparison">ANOVA Table Comparison</a></li>
  <li><a href="#presentation-of-regression-results" id="toc-presentation-of-regression-results" class="nav-link" data-scroll-target="#presentation-of-regression-results">11.7: Presentation of Regression Results</a></li>
  <li><a href="#detailed-coefficient-comparison-across-models" id="toc-detailed-coefficient-comparison-across-models" class="nav-link" data-scroll-target="#detailed-coefficient-comparison-across-models">Detailed Coefficient Comparison Across Models</a></li>
  <li><a href="#robust-standard-errors-heteroskedasticity-robust" id="toc-robust-standard-errors-heteroskedasticity-robust" class="nav-link" data-scroll-target="#robust-standard-errors-heteroskedasticity-robust">Robust Standard Errors (Heteroskedasticity-Robust)</a></li>
  <li><a href="#visualization-confidence-intervals-for-all-coefficients" id="toc-visualization-confidence-intervals-for-all-coefficients" class="nav-link" data-scroll-target="#visualization-confidence-intervals-for-all-coefficients">Visualization: Confidence Intervals for All Coefficients</a></li>
  <li><a href="#visualization-f-distribution" id="toc-visualization-f-distribution" class="nav-link" data-scroll-target="#visualization-f-distribution">Visualization: F-Distribution</a></li>
  <li><a href="#visualization-model-comparison-actual-vs-predicted" id="toc-visualization-model-comparison-actual-vs-predicted" class="nav-link" data-scroll-target="#visualization-model-comparison-actual-vs-predicted">Visualization: Model Comparison (Actual vs Predicted)</a></li>
  <li><a href="#key-takeaways" id="toc-key-takeaways" class="nav-link" data-scroll-target="#key-takeaways">Key Takeaways</a></li>
  <li><a href="#practice-exercises" id="toc-practice-exercises" class="nav-link" data-scroll-target="#practice-exercises">Practice Exercises</a></li>
  <li><a href="#case-studies" id="toc-case-studies" class="nav-link" data-scroll-target="#case-studies">Case Studies</a>
  <ul class="collapse">
  <li><a href="#case-study-1-statistical-inference-for-cross-country-productivity" id="toc-case-study-1-statistical-inference-for-cross-country-productivity" class="nav-link" data-scroll-target="#case-study-1-statistical-inference-for-cross-country-productivity">Case Study 1: Statistical Inference for Cross-Country Productivity</a></li>
  <li><a href="#what-youve-learned" id="toc-what-youve-learned" class="nav-link" data-scroll-target="#what-youve-learned">What You’ve Learned</a></li>
  <li><a href="#case-study-2-which-satellite-features-matter-joint-tests-for-predictive-power" id="toc-case-study-2-which-satellite-features-matter-joint-tests-for-predictive-power" class="nav-link" data-scroll-target="#case-study-2-which-satellite-features-matter-joint-tests-for-predictive-power">Case Study 2: Which Satellite Features Matter? Joint Tests for Predictive Power</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">
<div id="google_translate_element" style="padding: 8px 0;"></div>
<script type="text/javascript">
function googleTranslateElementInit() {
  new google.translate.TranslateElement({
    pageLanguage: 'en',
    layout: google.translate.TranslateElement.InlineLayout.HORIZONTAL
  }, 'google_translate_element');
}
</script>
<script type="text/javascript" src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script>

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../notebooks_colab/ch10_Data_Summary_for_Multiple_Regression.html">Multiple Regression</a></li><li class="breadcrumb-item"><a href="../notebooks_colab/ch11_Statistical_Inference_for_Multiple_Regression.html"><span class="chapter-title">Chapter 11: Statistical Inference for Multiple Regression</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-title">Chapter 11: Statistical Inference for Multiple Regression</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><strong>metricsAI: An Introduction to Econometrics with Python and AI in the Cloud</strong></p>
<p><em><a href="https://carlos-mendez.org">Carlos Mendez</a></em></p>
<p><img src="https://raw.githubusercontent.com/quarcs-lab/metricsai/main/images/ch11_visual_summary.jpg" alt="Chapter 11 Visual Summary" width="65%"></p>
<p>This notebook provides an interactive introduction to extending inference to models with multiple regressors. All code runs directly in Google Colab without any local setup.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="https://colab.research.google.com/github/quarcs-lab/metricsai/blob/main/notebooks_colab/ch11_Statistical_Inference_for_Multiple_Regression.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" class="img-fluid figure-img"></a></p>
<figcaption>Open In Colab</figcaption>
</figure>
</div>
<section id="chapter-overview" class="level2">
<h2 class="anchored" data-anchor-id="chapter-overview">Chapter Overview</h2>
<p>This chapter extends statistical inference to models with multiple regressors. You’ll learn to construct confidence intervals, conduct hypothesis tests on individual and groups of parameters, and present regression results professionally.</p>
<p><strong>Learning Objectives:</strong></p>
<p>By the end of this chapter, you will be able to:</p>
<ol type="1">
<li>Extend statistical inference from bivariate regression to multiple regression with <span class="math inline">\(k\)</span> regressors</li>
<li>Understand the <span class="math inline">\(t\)</span>-statistic for individual coefficients following a <span class="math inline">\(T(n-k)\)</span> distribution</li>
<li>Calculate and interpret standard errors for OLS slope coefficients: <span class="math inline">\(se(b_j) = s_e / \sqrt{\sum \widetilde{x}_{ji}^2}\)</span></li>
<li>Construct confidence intervals using <span class="math inline">\(b_j \pm t_{n-k, \alpha/2} \times se(b_j)\)</span></li>
<li>Conduct hypothesis tests on individual parameters to determine statistical significance</li>
<li>Understand and apply F-tests for joint hypotheses involving multiple parameter restrictions</li>
<li>Interpret the F distribution with two degrees of freedom (<span class="math inline">\(v_1\)</span> = restrictions, <span class="math inline">\(v_2 = n-k\)</span>)</li>
<li>Perform the test of overall statistical significance using <span class="math inline">\(H_0: \beta_2 = \cdots = \beta_k = 0\)</span></li>
<li>Test whether subsets of regressors are jointly significant using nested model comparisons</li>
<li>Present regression results in standard formats (standard errors, t-statistics, p-values, confidence intervals, asterisks)</li>
</ol>
<p><strong>Dataset used:</strong> - <strong>AED_HOUSE.DTA</strong>: 29 houses sold in Davis, California (1999)</p>
<p><strong>Key economic questions:</strong> - Is house size a statistically significant predictor of price? - Are additional variables (bedrooms, bathrooms, age) jointly significant? - What is a reasonable range for the effect of size on price?</p>
<p><strong>Chapter outline:</strong> - 11.1 Properties of the Least Squares Estimator - 11.2 Estimators of Model Parameters - 11.3 Confidence Intervals - 11.4 Hypothesis Tests on a Single Parameter - 11.5 Joint Hypothesis Tests - 11.6 F Statistic Under Assumptions 1-4 - 11.7 Presentation of Regression Results - Key Takeaways - Practice Exercises - Case Studies</p>
<p><strong>Estimated time:</strong> 60-90 minutes</p>
</section>
<section id="setup" class="level2">
<h2 class="anchored" data-anchor-id="setup">Setup</h2>
<p>First, we import the necessary Python packages and configure the environment for reproducibility. All data will stream directly from GitHub.</p>
<div id="cell-3" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import required packages</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.formula.api <span class="im">import</span> ols</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.stats.anova <span class="im">import</span> anova_lm</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Set random seeds for reproducibility</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>RANDOM_SEED <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>random.seed(RANDOM_SEED)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>np.random.seed(RANDOM_SEED)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">'PYTHONHASHSEED'</span>] <span class="op">=</span> <span class="bu">str</span>(RANDOM_SEED)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co"># GitHub data URL</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>GITHUB_DATA_URL <span class="op">=</span> <span class="st">"https://raw.githubusercontent.com/quarcs-lab/data-open/master/AED/"</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Set plotting style</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>sns.set_style(<span class="st">"whitegrid"</span>)</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'figure.figsize'</span>] <span class="op">=</span> (<span class="dv">10</span>, <span class="dv">6</span>)</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Setup complete! Ready to explore statistical inference for multiple regression."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Setup complete! Ready to explore statistical inference for multiple regression.</code></pre>
</div>
</div>
</section>
<section id="data-preparation" class="level2">
<h2 class="anchored" data-anchor-id="data-preparation">Data Preparation</h2>
<p>We’ll work with the same house price dataset from Chapter 10, which contains information on 29 houses sold in Davis, California in 1999.</p>
<div id="cell-5" class="cell" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Read in the house data</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>data_house <span class="op">=</span> pd.read_stata(GITHUB_DATA_URL <span class="op">+</span> <span class="st">'AED_HOUSE.DTA'</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Data summary:"</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>data_summary <span class="op">=</span> data_house.describe()</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data_summary)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">First few observations:"</span>)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data_house[[<span class="st">'price'</span>, <span class="st">'size'</span>, <span class="st">'bedrooms'</span>, <span class="st">'bathrooms'</span>, <span class="st">'lotsize'</span>, <span class="st">'age'</span>, <span class="st">'monthsold'</span>]].head())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Data summary:
               price         size   bedrooms  bathrooms    lotsize        age  \
count      29.000000    29.000000  29.000000  29.000000  29.000000  29.000000   
mean   253910.344828  1882.758621   3.793103   2.206897   2.137931  36.413792   
std     37390.710695   398.272130   0.675030   0.341144   0.693034   7.118975   
min    204000.000000  1400.000000   3.000000   2.000000   1.000000  23.000000   
25%    233000.000000  1600.000000   3.000000   2.000000   2.000000  31.000000   
50%    244000.000000  1800.000000   4.000000   2.000000   2.000000  35.000000   
75%    270000.000000  2000.000000   4.000000   2.500000   3.000000  39.000000   
max    375000.000000  3300.000000   6.000000   3.000000   3.000000  51.000000   

       monthsold           list  
count  29.000000      29.000000  
mean    5.965517  257824.137931  
std     1.679344   40860.264099  
min     3.000000  199900.000000  
25%     5.000000  239000.000000  
50%     6.000000  245000.000000  
75%     7.000000  269000.000000  
max     8.000000  386000.000000  

First few observations:
    price  size  bedrooms  bathrooms  lotsize   age  monthsold
0  204000  1400         3        2.0        1  31.0          7
1  212000  1600         3        3.0        2  33.0          5
2  213000  1800         3        2.0        2  51.0          4
3  220000  1600         3        2.0        1  49.0          4
4  224500  2100         4        2.5        2  47.0          6</code></pre>
</div>
</div>
</section>
<section id="properties-of-the-least-squares-estimator" class="level2">
<h2 class="anchored" data-anchor-id="properties-of-the-least-squares-estimator">11.1: Properties of the Least Squares Estimator</h2>
<p>Before conducting inference, we need to understand the statistical properties of the OLS estimator. Under the classical linear regression assumptions, OLS has desirable properties.</p>
<p><strong>Classical Assumptions (1-4):</strong></p>
<ol type="1">
<li><p><strong>Linearity</strong>: The population model is linear in parameters: <span class="math display">\[y = \beta_1 + \beta_2 x_2 + \beta_3 x_3 + \cdots + \beta_k x_k + u\]</span></p></li>
<li><p><strong>Random sampling</strong>: Data are randomly sampled from the population</p></li>
<li><p><strong>No perfect collinearity</strong>: No exact linear relationships among regressors</p></li>
<li><p><strong>Zero conditional mean</strong>: <span class="math inline">\(E[u | x_2, \ldots, x_k] = 0\)</span></p></li>
</ol>
<p><strong>Properties of OLS under these assumptions:</strong></p>
<ul>
<li><strong>Unbiased</strong>: <span class="math inline">\(E[\hat{\beta}_j] = \beta_j\)</span> (centered on true value)</li>
<li><strong>Consistent</strong>: <span class="math inline">\(\hat{\beta}_j \rightarrow \beta_j\)</span> as <span class="math inline">\(n \rightarrow \infty\)</span></li>
<li><strong>Efficient (BLUE)</strong>: Best Linear Unbiased Estimator (Gauss-Markov Theorem)
<ul>
<li>Has minimum variance among all linear unbiased estimators</li>
</ul></li>
</ul>
<p><strong>Standard error of coefficient <span class="math inline">\(\hat{\beta}_j\)</span>:</strong></p>
<p><span class="math display">\[se(\hat{\beta}_j) = \frac{s_e}{\sqrt{\sum_{i=1}^n \tilde{x}_{ji}^2}}\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(s_e\)</span> is the standard error of the regression</li>
<li><span class="math inline">\(\tilde{x}_{ji}\)</span> is the residual from regressing <span class="math inline">\(x_j\)</span> on all other regressors</li>
</ul>
<p><strong>Smaller standard errors occur when:</strong></p>
<ul>
<li>Model fits well (small <span class="math inline">\(s_e\)</span>)</li>
<li>Large sample size (large <span class="math inline">\(\sum \tilde{x}_{ji}^2\)</span>)</li>
<li>Variable <span class="math inline">\(x_j\)</span> has high variation after controlling for other regressors</li>
</ul>
<div id="cell-7" class="cell" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"11.1 PROPERTIES OF THE LEAST SQUARES ESTIMATOR"</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Under assumptions 1-4:"</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  1. Linearity: y = β₀ + β₁x₁ + ... + βₖxₖ + u"</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  2. Random sampling from population"</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  3. No perfect collinearity"</span>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  4. Zero conditional mean: E[u|X] = 0"</span>)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">The OLS estimator is:"</span>)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  - Unbiased: E[β̂] = β"</span>)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  - Consistent: plim(β̂) = β"</span>)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  - Efficient (BLUE under Gauss-Markov theorem)"</span>)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">These properties allow us to conduct valid statistical inference."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>======================================================================
11.1 PROPERTIES OF THE LEAST SQUARES ESTIMATOR
======================================================================

Under assumptions 1-4:
  1. Linearity: y = β₀ + β₁x₁ + ... + βₖxₖ + u
  2. Random sampling from population
  3. No perfect collinearity
  4. Zero conditional mean: E[u|X] = 0

The OLS estimator is:
  - Unbiased: E[β̂] = β
  - Consistent: plim(β̂) = β
  - Efficient (BLUE under Gauss-Markov theorem)

These properties allow us to conduct valid statistical inference.</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p><strong>Key Concept 11.1: Classical Assumptions for Statistical Inference</strong></p>
<p>Four assumptions underpin valid inference in multiple regression: (1) linearity in parameters, (2) random sampling, (3) no perfect collinearity among regressors, and (4) zero conditional mean of errors <span class="math inline">\(E[u|X] = 0\)</span>. Under these assumptions, OLS is unbiased (<span class="math inline">\(E[b_j] = \beta_j\)</span>), consistent, and the Best Linear Unbiased Estimator (BLUE) by the Gauss-Markov theorem.</p>
</blockquote>
</section>
<section id="estimators-of-model-parameters" class="level2">
<h2 class="anchored" data-anchor-id="estimators-of-model-parameters">11.2: Estimators of Model Parameters</h2>
<p>Now we estimate the full multiple regression model and examine the parameter estimates, standard errors, and related statistics.</p>
<p><strong>The full model:</strong></p>
<p><span class="math display">\[\text{price} = \beta_1 + \beta_2 \times \text{size} + \beta_3 \times \text{bedrooms} + \beta_4 \times \text{bathrooms} + \beta_5 \times \text{lotsize} + \beta_6 \times \text{age} + \beta_7 \times \text{monthsold} + u\]</span></p>
<p><strong>Key statistics:</strong></p>
<ul>
<li><strong>Coefficients</strong> (<span class="math inline">\(\hat{\beta}_j\)</span>): Point estimates of partial effects</li>
<li><strong>Standard errors</strong> (<span class="math inline">\(se(\hat{\beta}_j)\)</span>): Measure of estimation uncertainty</li>
<li><strong>t-statistics</strong>: Coefficient divided by standard error</li>
<li><strong>p-values</strong>: Probability of observing such extreme values under <span class="math inline">\(H_0: \beta_j = 0\)</span></li>
<li><strong>Root MSE</strong> (<span class="math inline">\(s_e\)</span>): Standard deviation of residuals, measures typical prediction error</li>
</ul>
<div id="cell-10" class="cell" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Full multiple regression model</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>model_full <span class="op">=</span> ols(<span class="st">'price ~ size + bedrooms + bathrooms + lotsize + age + monthsold'</span>,</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>                 data<span class="op">=</span>data_house).fit()</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"11.2 ESTIMATORS OF MODEL PARAMETERS"</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Full Multiple Regression Results:"</span>)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model_full.summary())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>======================================================================
11.2 ESTIMATORS OF MODEL PARAMETERS
======================================================================

Full Multiple Regression Results:
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  price   R-squared:                       0.651
Model:                            OLS   Adj. R-squared:                  0.555
Method:                 Least Squares   F-statistic:                     6.826
Date:                Wed, 21 Jan 2026   Prob (F-statistic):           0.000342
Time:                        15:15:57   Log-Likelihood:                -330.74
No. Observations:                  29   AIC:                             675.5
Df Residuals:                      22   BIC:                             685.1
Df Model:                           6                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept   1.378e+05   6.15e+04      2.242      0.035    1.03e+04    2.65e+05
size          68.3694     15.389      4.443      0.000      36.454     100.285
bedrooms    2685.3151   9192.526      0.292      0.773   -1.64e+04    2.17e+04
bathrooms   6832.8800   1.57e+04      0.435      0.668   -2.58e+04    3.94e+04
lotsize     2303.2214   7226.535      0.319      0.753   -1.27e+04    1.73e+04
age         -833.0386    719.335     -1.158      0.259   -2324.847     658.770
monthsold  -2088.5036   3520.898     -0.593      0.559   -9390.399    5213.392
==============================================================================
Omnibus:                        1.317   Durbin-Watson:                   1.259
Prob(Omnibus):                  0.518   Jarque-Bera (JB):                0.980
Skew:                           0.151   Prob(JB):                        0.612
Kurtosis:                       2.152   Cond. No.                     2.59e+04
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 2.59e+04. This might indicate that there are
strong multicollinearity or other numerical problems.</code></pre>
</div>
</div>
</section>
<section id="interpreting-the-regression-results" class="level2">
<h2 class="anchored" data-anchor-id="interpreting-the-regression-results">Interpreting the Regression Results</h2>
<p><strong>What these results tell us:</strong></p>
<p>The regression output reveals several important findings about the house price data:</p>
<ol type="1">
<li><p><strong>Size coefficient = $68.37 (p &lt; 0.001)</strong>: Each additional square foot increases house price by $68.37 on average, holding all other variables constant. This effect is highly statistically significant (p = 0.0002), meaning we can be very confident this relationship is not due to chance.</p></li>
<li><p><strong>Other variables are not statistically significant</strong>:</p>
<ul>
<li><strong>Bedrooms coefficient = $2,685 (p = 0.773)</strong>: Surprisingly, the number of bedrooms doesn’t significantly affect price once we control for size. The p-value of 0.773 means we cannot reject the hypothesis that this coefficient is zero.</li>
<li><strong>Bathrooms coefficient = $6,833 (p = 0.668)</strong>: Similarly, bathrooms show no significant effect.</li>
<li><strong>Age coefficient = -$833 (p = 0.259)</strong>: Older homes tend to sell for less, but this effect is not statistically significant.</li>
</ul></li>
<li><p><strong>Model fit: R² = 0.651</strong>: The model explains 65.1% of the variation in house prices, which is quite good for cross-sectional real estate data.</p></li>
<li><p><strong>Overall F-statistic = 6.83 (p = 0.0003)</strong>: The model as a whole is highly significant, meaning at least one of our predictors has a real effect on price.</p></li>
</ol>
<p><strong>Economic Interpretation</strong>:</p>
<p>Size dominates all other house characteristics in determining price in this market. Features like number of bedrooms and bathrooms don’t add explanatory power beyond what size already captures. This likely reflects multicollinearity—larger houses naturally tend to have more bedrooms and bathrooms, so once we control for size, these other features provide little additional information.</p>
<p>The large standard errors on most coefficients (relative to the coefficient values) suggest imprecise estimation, common in small samples (n=29) with correlated predictors.</p>
</section>
<section id="model-diagnostics" class="level2">
<h2 class="anchored" data-anchor-id="model-diagnostics">Model Diagnostics</h2>
<p>Let’s extract and display key model diagnostics to understand the estimation.</p>
<div id="cell-13" class="cell" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract key statistics</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="bu">len</span>(data_house)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>k <span class="op">=</span> <span class="bu">len</span>(model_full.params)</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> n <span class="op">-</span> k</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Model diagnostics:"</span>)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Sample size (n): </span><span class="sc">{</span>n<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Number of parameters (k): </span><span class="sc">{</span>k<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Degrees of freedom (n-k): </span><span class="sc">{</span>df<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Root MSE (σ̂): $</span><span class="sc">{</span>np<span class="sc">.</span>sqrt(model_full.mse_resid)<span class="sc">:,.2f}</span><span class="ss">"</span>)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  R-squared: </span><span class="sc">{</span>model_full<span class="sc">.</span>rsquared<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Adjusted R-squared: </span><span class="sc">{</span>model_full<span class="sc">.</span>rsquared_adj<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Create comprehensive coefficient table</span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Coefficient Table"</span>)</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>coef_table <span class="op">=</span> pd.DataFrame({</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Coefficient'</span>: model_full.params,</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Std. Error'</span>: model_full.bse,</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>    <span class="st">'t-statistic'</span>: model_full.tvalues,</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>    <span class="st">'p-value'</span>: model_full.pvalues</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(coef_table)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model diagnostics:
  Sample size (n): 29
  Number of parameters (k): 7
  Degrees of freedom (n-k): 22
  Root MSE (σ̂): $24,935.73
  R-squared: 0.6506
  Adjusted R-squared: 0.5552

======================================================================
Coefficient Table
======================================================================
             Coefficient    Std. Error  t-statistic   p-value
Intercept  137791.065699  61464.951869     2.241783  0.035387
size           68.369419     15.389472     4.442610  0.000205
bedrooms     2685.315122   9192.525674     0.292119  0.772932
bathrooms    6832.880015  15721.191544     0.434629  0.668065
lotsize      2303.221371   7226.535205     0.318717  0.752947
age          -833.038602    719.334544    -1.158068  0.259254
monthsold   -2088.503625   3520.897859    -0.593174  0.559114</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p><strong>Key Concept 11.2: Precision of Coefficient Estimates</strong></p>
<p>The standard error <span class="math inline">\(se(b_j) = s_e / \sqrt{\sum \widetilde{x}_{ji}^2}\)</span> reveals what makes estimates precise: (1) a well-fitting model (small <span class="math inline">\(s_e\)</span>), (2) large sample size, (3) high variation in <span class="math inline">\(x_j\)</span> after controlling for other regressors, and (4) low multicollinearity. When regressors are highly correlated, <span class="math inline">\(\sum \widetilde{x}_{ji}^2\)</span> shrinks and standard errors inflate.</p>
</blockquote>
</section>
<section id="economic-interpretation" class="level2">
<h2 class="anchored" data-anchor-id="economic-interpretation">Economic Interpretation</h2>
<p><strong>Key findings:</strong></p>
<ol type="1">
<li><p><strong>Size coefficient</strong> (≈ $68.37): Each additional square foot increases house price by approximately $68, holding other factors constant.</p></li>
<li><p><strong>Statistical significance</strong>: Only the size variable appears statistically significant at conventional levels (p &lt; 0.05).</p></li>
<li><p><strong>Other variables</strong>: Bedrooms, bathrooms, lot size, age, and month sold show large standard errors relative to their coefficients, suggesting imprecise estimates.</p></li>
</ol>
<p>This pattern is common in small samples with correlated regressors (multicollinearity).</p>
<p>Now that we understand the properties and interpretation of OLS estimates, let’s quantify uncertainty through confidence intervals.</p>
</section>
<section id="confidence-intervals" class="level2">
<h2 class="anchored" data-anchor-id="confidence-intervals">11.3: Confidence Intervals</h2>
<p>A confidence interval provides a range of plausible values for a population parameter.</p>
<p><strong>Formula for a $100(1-)%$ confidence interval:</strong></p>
<p><span class="math display">\[\hat{\beta}_j \pm t_{n-k, \alpha/2} \times se(\hat{\beta}_j)\]</span></p>
<p>where: - <span class="math inline">\(\hat{\beta}_j\)</span> is the coefficient estimate - <span class="math inline">\(t_{n-k, \alpha/2}\)</span> is the critical value from Student’s t-distribution - <span class="math inline">\(se(\hat{\beta}_j)\)</span> is the standard error</p>
<p><strong>95% confidence interval (approximate):</strong></p>
<p><span class="math display">\[\hat{\beta}_j \pm 2 \times se(\hat{\beta}_j)\]</span></p>
<p><strong>Interpretation</strong>: If we repeatedly sampled from the population and constructed 95% CIs, approximately 95% would contain the true parameter value.</p>
<p><strong>Key points:</strong> - Narrower intervals indicate more precise estimates - If the interval excludes zero, the coefficient is statistically significant at that level</p>
</section>
<section id="interpreting-the-confidence-intervals" class="level2">
<h2 class="anchored" data-anchor-id="interpreting-the-confidence-intervals">Interpreting the Confidence Intervals</h2>
<p><strong>What these confidence intervals tell us:</strong></p>
<p>Looking at the 95% confidence intervals, we can identify which variables have statistically significant effects:</p>
<ol type="1">
<li><p><strong>Size: [$36.45, $100.29]</strong> - This interval excludes zero, confirming that size has a statistically significant positive effect on price. We are 95% confident that each additional square foot increases price by between $36 and $100.</p></li>
<li><p><strong>Intercept: [$10,321, $265,262]</strong> - The wide interval reflects high uncertainty about the base price level, but it excludes zero.</p></li>
<li><p><strong>All other variables</strong>: The confidence intervals for bedrooms, bathrooms, lotsize, age, and monthsold all <strong>contain zero</strong>, which means these coefficients are not statistically significant at the 5% level.</p></li>
</ol>
<p><strong>Practical Meaning</strong>:</p>
<p>If we repeatedly sampled 29 houses from this market and calculated 95% confidence intervals, approximately 95% of those intervals would contain the true population parameter. For the size coefficient, this means we’re quite certain about its effect—even in the worst case (lower bound), an extra square foot adds at least $36 to the price.</p>
<p>The fact that only the size interval excludes zero provides strong evidence that, in this dataset, size is the only reliable predictor of house prices among the variables we measured.</p>
<div id="cell-19" class="cell" data-execution_count="6">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"11.3 CONFIDENCE INTERVALS"</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 95% confidence intervals</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>conf_int <span class="op">=</span> model_full.conf_int(alpha<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">95% Confidence Intervals:"</span>)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(conf_int)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>======================================================================
11.3 CONFIDENCE INTERVALS
======================================================================

95% Confidence Intervals:
                      0              1
Intercept  10320.557398  265261.573999
size          36.453608     100.285230
bedrooms  -16378.816300   21749.446543
bathrooms -25770.875723   39436.635753
lotsize   -12683.695364   17290.138107
age        -2324.847139     658.769936
monthsold  -9390.398871    5213.391620</code></pre>
</div>
</div>
</section>
<section id="manual-calculation-of-confidence-interval" class="level2">
<h2 class="anchored" data-anchor-id="manual-calculation-of-confidence-interval">Manual Calculation of Confidence Interval</h2>
<p>Let’s manually calculate the confidence interval for the size coefficient to understand the mechanics.</p>
<div id="cell-21" class="cell" data-execution_count="7">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Detailed confidence interval calculation for 'size'</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>coef_size <span class="op">=</span> model_full.params[<span class="st">'size'</span>]</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>se_size <span class="op">=</span> model_full.bse[<span class="st">'size'</span>]</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>t_crit <span class="op">=</span> stats.t.ppf(<span class="fl">0.975</span>, df)  <span class="co"># 97.5th percentile for two-sided 95% CI</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>ci_lower <span class="op">=</span> coef_size <span class="op">-</span> t_crit <span class="op">*</span> se_size</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>ci_upper <span class="op">=</span> coef_size <span class="op">+</span> t_crit <span class="op">*</span> se_size</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Manual calculation for 'size' coefficient:"</span>)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Coefficient: $</span><span class="sc">{</span>coef_size<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Standard error: $</span><span class="sc">{</span>se_size<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Degrees of freedom: </span><span class="sc">{</span>df<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Critical t-value (α=0.05): </span><span class="sc">{</span>t_crit<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Margin of error: </span><span class="sc">{</span>t_crit <span class="op">*</span> se_size<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  95% CI: [$</span><span class="sc">{</span>ci_lower<span class="sc">:.2f}</span><span class="ss">, $</span><span class="sc">{</span>ci_upper<span class="sc">:.2f}</span><span class="ss">]"</span>)</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Interpretation:"</span>)</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"We are 95% confident that each additional square foot increases"</span>)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"house price by between $</span><span class="sc">{</span>ci_lower<span class="sc">:.2f}</span><span class="ss"> and $</span><span class="sc">{</span>ci_upper<span class="sc">:.2f}</span><span class="ss">."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Manual calculation for 'size' coefficient:
  Coefficient: $68.37
  Standard error: $15.39
  Degrees of freedom: 22
  Critical t-value (α=0.05): 2.0739
  Margin of error: 31.92
  95% CI: [$36.45, $100.29]

Interpretation:
We are 95% confident that each additional square foot increases
house price by between $36.45 and $100.29.</code></pre>
</div>
</div>
</section>
<section id="comprehensive-table-with-confidence-intervals" class="level2">
<h2 class="anchored" data-anchor-id="comprehensive-table-with-confidence-intervals">Comprehensive Table with Confidence Intervals</h2>
<div id="cell-23" class="cell" data-execution_count="8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create comprehensive coefficient table</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Comprehensive Coefficient Table with 95% Confidence Intervals"</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>coef_table_full <span class="op">=</span> pd.DataFrame({</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Coefficient'</span>: model_full.params,</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Std. Error'</span>: model_full.bse,</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'t-statistic'</span>: model_full.tvalues,</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'p-value'</span>: model_full.pvalues,</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'CI Lower'</span>: conf_int.iloc[:, <span class="dv">0</span>],</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'CI Upper'</span>: conf_int.iloc[:, <span class="dv">1</span>]</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(coef_table_full)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Note: Coefficients with CIs that exclude zero are statistically significant at 5%."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>======================================================================
Comprehensive Coefficient Table with 95% Confidence Intervals
======================================================================
             Coefficient    Std. Error  t-statistic   p-value      CI Lower  \
Intercept  137791.065699  61464.951869     2.241783  0.035387  10320.557398   
size           68.369419     15.389472     4.442610  0.000205     36.453608   
bedrooms     2685.315122   9192.525674     0.292119  0.772932 -16378.816300   
bathrooms    6832.880015  15721.191544     0.434629  0.668065 -25770.875723   
lotsize      2303.221371   7226.535205     0.318717  0.752947 -12683.695364   
age          -833.038602    719.334544    -1.158068  0.259254  -2324.847139   
monthsold   -2088.503625   3520.897859    -0.593174  0.559114  -9390.398871   

                CI Upper  
Intercept  265261.573999  
size          100.285230  
bedrooms    21749.446543  
bathrooms   39436.635753  
lotsize     17290.138107  
age           658.769936  
monthsold    5213.391620  

Note: Coefficients with CIs that exclude zero are statistically significant at 5%.</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p><strong>Key Concept 11.3: Confidence Intervals in Multiple Regression</strong></p>
<p>A 95% confidence interval <span class="math inline">\(b_j \pm t_{n-k, 0.025} \times se(b_j)\)</span> provides a range of plausible values for <span class="math inline">\(\beta_j\)</span>. If the interval excludes zero, the coefficient is statistically significant at 5%. Narrower intervals indicate more precise estimation, which improves with larger samples and lower multicollinearity.</p>
</blockquote>
</section>
<section id="interpreting-the-hypothesis-test-result" class="level2">
<h2 class="anchored" data-anchor-id="interpreting-the-hypothesis-test-result">Interpreting the Hypothesis Test Result</h2>
<p><strong>What this test tells us:</strong></p>
<p>We tested whether the size coefficient equals 50 (H₀: β_size = 50):</p>
<ul>
<li><p><strong>t-statistic = 1.19</strong>: This measures how many standard errors our estimate ($68.37) is away from the hypothesized value (50). The difference is 1.19 standard errors.</p></li>
<li><p><strong>p-value = 0.245</strong>: This is the probability of observing a coefficient as extreme as $68.37 (or more extreme) if the true value were actually $50. A p-value of 0.245 means there’s about a 25% chance we’d see this result by random sampling variation alone.</p></li>
<li><p><strong>Decision</strong>: Since p = 0.245 &gt; 0.05, we <strong>fail to reject</strong> H₀ at the 5% significance level.</p></li>
</ul>
<p><strong>Economic Interpretation</strong>:</p>
<p>The data are consistent with the hypothesis that each square foot adds $50 to house price. Even though our point estimate is $68.37, the difference from $50 is not statistically significant. This doesn’t mean β = 50 is correct—it simply means our data don’t provide strong enough evidence to rule it out.</p>
<p>This illustrates an important principle: <strong>failing to reject H₀ is NOT the same as proving H₀ is true</strong>. We simply lack sufficient evidence to reject it given our sample size and estimation precision.</p>
</section>
<section id="hypothesis-tests-on-a-single-parameter" class="level2">
<h2 class="anchored" data-anchor-id="hypothesis-tests-on-a-single-parameter">11.4: Hypothesis Tests on a Single Parameter</h2>
<p>Hypothesis testing allows us to make formal inferences about population parameters.</p>
<p><strong>General two-sided test:</strong></p>
<p><span class="math display">\[H_0: \beta_j = \beta_j^* \quad \text{vs.} \quad H_a: \beta_j \neq \beta_j^*\]</span></p>
<p><strong>Test statistic:</strong></p>
<p><span class="math display">\[t = \frac{\hat{\beta}_j - \beta_j^*}{se(\hat{\beta}_j)} \sim t(n-k)\]</span></p>
<p><strong>Decision rules:</strong></p>
<ol type="1">
<li><strong>p-value approach</strong>: Reject <span class="math inline">\(H_0\)</span> if <span class="math inline">\(p\)</span>-value <span class="math inline">\(&lt; \alpha\)</span></li>
<li><strong>Critical value approach</strong>: Reject <span class="math inline">\(H_0\)</span> if <span class="math inline">\(|t| &gt; t_{n-k, \alpha/2}\)</span></li>
</ol>
<p><strong>Test of statistical significance</strong> (most common):</p>
<p><span class="math display">\[H_0: \beta_j = 0 \quad \text{vs.} \quad H_a: \beta_j \neq 0\]</span></p>
<p>This tests whether variable <span class="math inline">\(x_j\)</span> has any relationship with <span class="math inline">\(y\)</span> after controlling for other regressors.</p>
<p><strong>Example</strong>: Test whether the size coefficient equals 50.</p>
<div id="cell-27" class="cell" data-execution_count="9">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"11.4 HYPOTHESIS TESTS ON A SINGLE PARAMETER"</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Test H₀: β_size = 50 vs H₁: β_size ≠ 50</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>null_value <span class="op">=</span> <span class="dv">50</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>t_stat_50 <span class="op">=</span> (coef_size <span class="op">-</span> null_value) <span class="op">/</span> se_size</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>p_value_50 <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> stats.t.cdf(<span class="bu">abs</span>(t_stat_50), df))</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Test: H₀: β_size = </span><span class="sc">{</span>null_value<span class="sc">}</span><span class="ss"> vs H₁: β_size ≠ </span><span class="sc">{</span>null_value<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Coefficient estimate: $</span><span class="sc">{</span>coef_size<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Standard error: $</span><span class="sc">{</span>se_size<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  t-statistic: </span><span class="sc">{</span>t_stat_50<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  p-value: </span><span class="sc">{</span>p_value_50<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Critical value (α=0.05): ±</span><span class="sc">{</span>t_crit<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="bu">abs</span>(t_stat_50) <span class="op">&gt;</span> t_crit:</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Result: Reject H₀ at 5% significance level"</span>)</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Conclusion: The size coefficient is significantly different from </span><span class="sc">{</span>null_value<span class="sc">}</span><span class="ss">."</span>)</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Result: Fail to reject H₀ at 5% significance level"</span>)</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Conclusion: The data are consistent with β_size = </span><span class="sc">{</span>null_value<span class="sc">}</span><span class="ss">."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>======================================================================
11.4 HYPOTHESIS TESTS ON A SINGLE PARAMETER
======================================================================

Test: H₀: β_size = 50 vs H₁: β_size ≠ 50
  Coefficient estimate: $68.37
  Standard error: $15.39
  t-statistic: 1.1936
  p-value: 0.2453
  Critical value (α=0.05): ±2.0739

Result: Fail to reject H₀ at 5% significance level
  Conclusion: The data are consistent with β_size = 50.</code></pre>
</div>
</div>
</section>
<section id="test-of-statistical-significance-β-0" class="level2">
<h2 class="anchored" data-anchor-id="test-of-statistical-significance-β-0">Test of Statistical Significance (β = 0)</h2>
<p>The most common hypothesis test examines whether a coefficient is zero.</p>
<div id="cell-29" class="cell" data-execution_count="10">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Test H₀: β_size = 0 (statistical significance)</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test of Statistical Significance: H₀: β_size = 0"</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>t_stat_zero <span class="op">=</span> coef_size <span class="op">/</span> se_size</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>p_value_zero <span class="op">=</span> model_full.pvalues[<span class="st">'size'</span>]</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">  t-statistic: </span><span class="sc">{</span>t_stat_zero<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  p-value: </span><span class="sc">{</span>p_value_zero<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Critical value (α=0.05): ±</span><span class="sc">{</span>t_crit<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> p_value_zero <span class="op">&lt;</span> <span class="fl">0.05</span>:</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Result: Reject H₀ - Size is statistically significant at 5% level"</span>)</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Interpretation: House size has a statistically significant effect on price."</span>)</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Result: Fail to reject H₀ - Size is not statistically significant"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>======================================================================
Test of Statistical Significance: H₀: β_size = 0
======================================================================

  t-statistic: 4.4426
  p-value: 0.000205
  Critical value (α=0.05): ±2.0739

Result: Reject H₀ - Size is statistically significant at 5% level
  Interpretation: House size has a statistically significant effect on price.</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p><strong>Key Concept 11.4: Tests of Statistical Significance</strong></p>
<p>The most common hypothesis test examines <span class="math inline">\(H_0: \beta_j = 0\)</span> — whether variable <span class="math inline">\(x_j\)</span> has any partial effect on <span class="math inline">\(y\)</span>. The <span class="math inline">\(t\)</span>-statistic <span class="math inline">\(t = b_j/se(b_j)\)</span> measures how many standard errors the estimate is from zero. Reject <span class="math inline">\(H_0\)</span> when <span class="math inline">\(|t| &gt; t_{\text{critical}}\)</span> or equivalently when the <span class="math inline">\(p\)</span>-value <span class="math inline">\(&lt; \alpha\)</span>.</p>
</blockquote>
</section>
<section id="using-statsmodels-t_test" class="level2">
<h2 class="anchored" data-anchor-id="using-statsmodels-t_test">Using statsmodels t_test</h2>
<p>Python’s statsmodels package provides convenient methods for hypothesis testing.</p>
</section>
<section id="interpreting-the-overall-f-test" class="level2">
<h2 class="anchored" data-anchor-id="interpreting-the-overall-f-test">Interpreting the Overall F-test</h2>
<p><strong>What this F-test tells us:</strong></p>
<p>The overall F-test examines whether our model has any explanatory power at all:</p>
<ul>
<li><strong>Null hypothesis</strong>: All slope coefficients equal zero (β₂ = β₃ = … = β₇ = 0)</li>
<li><strong>Alternative</strong>: At least one coefficient is non-zero</li>
</ul>
<p><strong>Results:</strong></p>
<ul>
<li><strong>F-statistic = 6.83</strong>: This compares the explained variation to unexplained variation</li>
<li><strong>p-value = 0.0003</strong>: Extremely small probability of observing such a large F-statistic if all coefficients were truly zero</li>
<li><strong>Critical value = 2.55</strong>: Our F-statistic (6.83) far exceeds this threshold</li>
</ul>
<p><strong>Decision</strong>: <strong>Reject H₀</strong> - The model is highly statistically significant.</p>
<p><strong>Economic Interpretation</strong>:</p>
<p>This result tells us that <strong>at least one</strong> of our house characteristics (size, bedrooms, bathrooms, lotsize, age, monthsold) has a real relationship with price. Given that we already know size is significant from individual t-tests, this makes sense.</p>
<p>However, this test doesn’t tell us <strong>which</strong> variables matter—just that the model as a whole provides useful information for predicting house prices. The very small p-value (0.0003) gives us high confidence that our model captures real economic relationships, not just random noise.</p>
<div id="cell-33" class="cell" data-execution_count="11">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Using statsmodels t_test</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Hypothesis test using statsmodels t_test:"</span>)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>hypothesis <span class="op">=</span> <span class="ss">f'size = </span><span class="sc">{</span>null_value<span class="sc">}</span><span class="ss">'</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>t_test_result <span class="op">=</span> model_full.t_test(hypothesis)</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(t_test_result)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">This confirms our manual calculation."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>======================================================================
Hypothesis test using statsmodels t_test:
======================================================================
                             Test for Constraints                             
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
c0            68.3694     15.389      1.194      0.245      36.454     100.285
==============================================================================

This confirms our manual calculation.</code></pre>
</div>
</div>
</section>
<section id="interpreting-the-joint-test-of-subset-variables" class="level2">
<h2 class="anchored" data-anchor-id="interpreting-the-joint-test-of-subset-variables">Interpreting the Joint Test of Subset Variables</h2>
<p><strong>What this joint test tells us:</strong></p>
<p>This F-test asks: “Can we exclude bedrooms, bathrooms, lotsize, age, and monthsold from the model and just keep size?”</p>
<p><strong>Results:</strong></p>
<ul>
<li><strong>F-statistic = 0.42</strong>: Very small F-statistic</li>
<li><strong>p-value = 0.832</strong>: Very high p-value (83.2%)</li>
<li><strong>Critical value = 2.66</strong>: Our F-statistic (0.42) is far below this threshold</li>
</ul>
<p><strong>Decision</strong>: <strong>Fail to reject H₀</strong> - These five variables are NOT jointly significant.</p>
<p><strong>Economic Interpretation</strong>:</p>
<p>This is a crucial finding for model selection. Even though we’re testing five variables simultaneously, they collectively add almost nothing to the model’s explanatory power beyond what size alone provides.</p>
<p><strong>What this means in practice:</strong></p>
<ul>
<li>A <strong>simpler model</strong> with only size as a predictor would be preferred</li>
<li>The additional variables (bedrooms, bathrooms, etc.) don’t improve our ability to predict house prices</li>
<li>Keeping these variables makes the model more complex without meaningful benefit</li>
</ul>
<p>This result demonstrates the power of joint testing: while we might hope that bedrooms or bathrooms would add information, when tested together, they fail to improve the model. This likely reflects the strong correlation between size and these other features—bigger houses tend to have more bedrooms and bathrooms, so these variables don’t provide independent information.</p>
<p>Having tested individual coefficients, we now turn to joint hypothesis tests that evaluate multiple restrictions simultaneously.</p>
</section>
<section id="joint-hypothesis-tests" class="level2">
<h2 class="anchored" data-anchor-id="joint-hypothesis-tests">11.5: Joint Hypothesis Tests</h2>
<p>Sometimes we want to test multiple restrictions simultaneously. Individual t-tests are insufficient for this purpose.</p>
<p><strong>Why joint tests?</strong> - Testing multiple individual hypotheses separately can be misleading - Joint tests account for correlation between coefficient estimates</p>
<p><strong>Examples of joint hypotheses:</strong> 1. All slope coefficients equal zero: <span class="math inline">\(\beta_2 = \beta_3 = \cdots = \beta_k = 0\)</span> 2. Subset of coefficients equal zero: <span class="math inline">\(\beta_3 = \beta_4 = \beta_5 = 0\)</span> 3. Linear restrictions: <span class="math inline">\(\beta_2 = -\beta_3\)</span> and $2_4 + _6 = 9$</p>
<p><strong>F-test procedure:</strong> - Test statistic follows the F-distribution: <span class="math inline">\(F(q, n-k)\)</span> - <span class="math inline">\(q\)</span> = number of restrictions - <span class="math inline">\(n-k\)</span> = degrees of freedom</p>
<p><strong>F-distribution properties:</strong> - Always positive (right-skewed) - Depends on two degrees of freedom parameters - As <span class="math inline">\(q\)</span> or <span class="math inline">\(n-k\)</span> increases, critical values change</p>
</section>
<section id="interpreting-the-sum-of-squares-decomposition" class="level2">
<h2 class="anchored" data-anchor-id="interpreting-the-sum-of-squares-decomposition">Interpreting the Sum of Squares Decomposition</h2>
<p><strong>What these calculations show:</strong></p>
<p>The sum of squares decomposition breaks down the total variation in house prices:</p>
<ul>
<li><strong>TSS = $39,145,826,897</strong> (Total Sum of Squares): Total variation in house prices around their mean</li>
<li><strong>ESS = $25,466,429,042</strong> (Explained Sum of Squares): Variation explained by our model (65.1%)</li>
<li><strong>RSS = $13,679,397,855</strong> (Residual Sum of Squares): Variation left unexplained (34.9%)</li>
</ul>
<p><strong>Verification</strong>: TSS = ESS + RSS (The identity holds perfectly)</p>
<p><strong>Understanding the F-statistic:</strong></p>
<p>The F-statistic compares explained variation per parameter to unexplained variation per degree of freedom:</p>
<p><span class="math display">\[F = \frac{ESS/(k-1)}{RSS/(n-k)} = \frac{25,466,429,042/6}{13,679,397,855/22} = 6.83\]</span></p>
<p><strong>Economic Interpretation</strong>:</p>
<p>Our model explains about 65% of the variation in house prices—a respectable amount for real estate data. The remaining 35% reflects unmeasured factors like neighborhood quality, interior condition, proximity to amenities, etc.</p>
<p>The F-statistic of 6.83 tells us that the explained variation (per parameter) is nearly 7 times larger than the unexplained variation (per degree of freedom). This ratio is large enough to conclude the model has genuine explanatory power, not just capturing random noise.</p>
<div id="cell-38" class="cell" data-execution_count="12">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"11.5 JOINT HYPOTHESIS TESTS"</span>)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Test 1: Joint significance of all slope coefficients</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="co"># H₀: β₁ = β₂ = ... = βₖ = 0</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"-"</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test 1: Overall F-test (all slopes = 0)"</span>)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>f_stat <span class="op">=</span> model_full.fvalue</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>f_pvalue <span class="op">=</span> model_full.f_pvalue</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>dfn <span class="op">=</span> k <span class="op">-</span> <span class="dv">1</span>  <span class="co"># numerator df (excluding intercept)</span></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>dfd <span class="op">=</span> df     <span class="co"># denominator df</span></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>f_crit <span class="op">=</span> stats.f.ppf(<span class="fl">0.95</span>, dfn, dfd)</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  H₀: All slope coefficients equal zero"</span>)</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  F-statistic: </span><span class="sc">{</span>f_stat<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  p-value: </span><span class="sc">{</span>f_pvalue<span class="sc">:.6e}</span><span class="ss">"</span>)</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Critical value (α=0.05): </span><span class="sc">{</span>f_crit<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Numerator df: </span><span class="sc">{</span>dfn<span class="sc">}</span><span class="ss">, Denominator df: </span><span class="sc">{</span>dfd<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> f_stat <span class="op">&gt;</span> f_crit:</span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Result: Reject H₀ - At least one coefficient is non-zero"</span>)</span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"  Interpretation: The regressors are jointly statistically significant."</span>)</span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Result: Fail to reject H₀"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>======================================================================
11.5 JOINT HYPOTHESIS TESTS
======================================================================

----------------------------------------------------------------------
Test 1: Overall F-test (all slopes = 0)
----------------------------------------------------------------------
  H₀: All slope coefficients equal zero
  F-statistic: 6.8261
  p-value: 3.424253e-04
  Critical value (α=0.05): 2.5491
  Numerator df: 6, Denominator df: 22

Result: Reject H₀ - At least one coefficient is non-zero
  Interpretation: The regressors are jointly statistically significant.</code></pre>
</div>
</div>
</section>
<section id="joint-test-of-subset-of-coefficients" class="level2">
<h2 class="anchored" data-anchor-id="joint-test-of-subset-of-coefficients">Joint Test of Subset of Coefficients</h2>
<p>Now test whether variables other than size are jointly significant.</p>
<div id="cell-40" class="cell" data-execution_count="13">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Test 2: Joint test of subset of coefficients</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="co"># H₀: β_bedrooms = β_bathrooms = β_lotsize = β_age = β_monthsold = 0</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"-"</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Test 2: Joint test - Are variables other than size significant?"</span>)</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>hypotheses <span class="op">=</span> [<span class="st">'bedrooms = 0'</span>, <span class="st">'bathrooms = 0'</span>, <span class="st">'lotsize = 0'</span>,</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>              <span class="st">'age = 0'</span>, <span class="st">'monthsold = 0'</span>]</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>f_test_result <span class="op">=</span> model_full.f_test(hypotheses)</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(f_test_result)</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Interpretation:"</span>)</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  This tests whether bedrooms, bathrooms, lotsize, age, and monthsold"</span>)</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  can jointly be excluded from the model (keeping only size)."</span>)</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> f_test_result.pvalue <span class="op">&lt;</span> <span class="fl">0.05</span>:</span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Result: These variables are jointly significant."</span>)</span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Result: These variables are NOT jointly significant."</span>)</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  A simpler model with only size may be preferred."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
----------------------------------------------------------------------
Test 2: Joint test - Are variables other than size significant?
----------------------------------------------------------------------
&lt;F test: F=0.41676518071663304, p=0.8319758671771483, df_denom=22, df_num=5&gt;

Interpretation:
  This tests whether bedrooms, bathrooms, lotsize, age, and monthsold
  can jointly be excluded from the model (keeping only size).
  Result: These variables are NOT jointly significant.
  A simpler model with only size may be preferred.</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p><strong>Key Concept 11.5: Joint Hypothesis Tests and the F Distribution</strong></p>
<p>Individual <span class="math inline">\(t\)</span>-tests cannot test multiple restrictions simultaneously because they ignore correlations between coefficient estimates. The F-test evaluates joint significance using the <span class="math inline">\(F(q, n-k)\)</span> distribution, where <span class="math inline">\(q\)</span> is the number of restrictions. It compares how much worse the restricted model fits relative to the unrestricted model.</p>
</blockquote>
</section>
<section id="interpreting-the-subset-f-test" class="level2">
<h2 class="anchored" data-anchor-id="interpreting-the-subset-f-test">Interpreting the Subset F-test</h2>
<p><strong>What this subset F-test tells us:</strong></p>
<p>We’re comparing two models: - <strong>Restricted model</strong>: price ~ size (2 parameters) - <strong>Unrestricted model</strong>: price ~ size + bedrooms + bathrooms + lotsize + age + monthsold (7 parameters)</p>
<p><strong>Key numbers:</strong> - <strong>RSS (restricted) = $14,975,101,655</strong>: Prediction errors when using only size - <strong>RSS (unrestricted) = $13,679,397,855</strong>: Prediction errors when using all variables - <strong>Increase in RSS = $1,295,703,800</strong>: How much worse the restricted model fits</p>
<p><strong>Test results:</strong> - <strong>F-statistic = 0.42</strong>: The increase in RSS is small relative to the baseline error - <strong>p-value = 0.832</strong>: 83.2% probability of seeing this result if the restrictions are true - <strong>Critical value = 2.66</strong>: Our F-statistic is far below the threshold</p>
<p><strong>Decision</strong>: <strong>Fail to reject H₀</strong> - The restricted model (only size) is NOT significantly worse.</p>
<p><strong>Economic Interpretation</strong>:</p>
<p>This is a powerful result for <strong>model selection</strong>. Adding five additional variables (bedrooms, bathrooms, lotsize, age, monthsold) reduces prediction errors by only $1.3 million out of $15 million total—a mere 8.7% improvement. This improvement is so small it could easily be due to random chance.</p>
<p><strong>Practical recommendation</strong>: Use the <strong>simpler model</strong> with only size. It’s easier to interpret, requires less data collection, and performs nearly as well as the complex model. This is an application of <strong>Occam’s Razor</strong> in econometrics: prefer simpler models when complex ones don’t provide meaningful improvement.</p>
</section>
<section id="f-statistic-under-assumptions-1-4" class="level2">
<h2 class="anchored" data-anchor-id="f-statistic-under-assumptions-1-4">11.6: F Statistic Under Assumptions 1-4</h2>
<p>Under the classical assumptions, the F-statistic has a specific formula based on sums of squares.</p>
<p><strong>Sum of Squares Decomposition:</strong></p>
<p><span class="math display">\[TSS = ESS + RSS\]</span></p>
<p>where:</p>
<ul>
<li><strong>TSS</strong> (Total Sum of Squares) = <span class="math inline">\(\sum (y_i - \bar{y})^2\)</span></li>
<li><strong>ESS</strong> (Explained Sum of Squares) = <span class="math inline">\(\sum (\hat{y}_i - \bar{y})^2\)</span></li>
<li><strong>RSS</strong> (Residual Sum of Squares) = <span class="math inline">\(\sum (y_i - \hat{y}_i)^2\)</span></li>
</ul>
<p><strong>F-statistic formula:</strong></p>
<p><span class="math display">\[F = \frac{(RSS_r - RSS_u) / q}{RSS_u / (n-k)} \sim F(q, n-k)\]</span></p>
<p>where:</p>
<ul>
<li><span class="math inline">\(RSS_r\)</span> = RSS from restricted model</li>
<li><span class="math inline">\(RSS_u\)</span> = RSS from unrestricted model</li>
<li><span class="math inline">\(q\)</span> = number of restrictions</li>
</ul>
<p><strong>Intuition</strong>: Reject restrictions if the restricted model fits much worse (large increase in RSS).</p>
<p><strong>Overall F-test formula:</strong></p>
<p><span class="math display">\[F = \frac{R^2 / (k-1)}{(1-R^2) / (n-k)} \sim F(k-1, n-k)\]</span></p>
<div id="cell-44" class="cell" data-execution_count="14">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"11.6 F STATISTIC UNDER ASSUMPTIONS 1-4"</span>)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Manual calculation of F-statistic using sums of squares</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"-"</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Manual F-statistic calculation"</span>)</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate sum of squares</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data_house[<span class="st">'price'</span>]</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>y_mean <span class="op">=</span> y.mean()</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> model_full.fittedvalues</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>resid <span class="op">=</span> model_full.resid</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Total sum of squares</span></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>TSS <span class="op">=</span> np.<span class="bu">sum</span>((y <span class="op">-</span> y_mean)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Explained sum of squares</span></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>ESS <span class="op">=</span> np.<span class="bu">sum</span>((y_pred <span class="op">-</span> y_mean)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Residual sum of squares</span></span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>RSS <span class="op">=</span> np.<span class="bu">sum</span>(resid<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Sum of Squares:"</span>)</span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Total (TSS): </span><span class="sc">{</span>TSS<span class="sc">:,.2f}</span><span class="ss">"</span>)</span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Explained (ESS): </span><span class="sc">{</span>ESS<span class="sc">:,.2f}</span><span class="ss">"</span>)</span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Residual (RSS): </span><span class="sc">{</span>RSS<span class="sc">:,.2f}</span><span class="ss">"</span>)</span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Check: TSS = ESS + RSS: </span><span class="sc">{</span>np<span class="sc">.</span>isclose(TSS, ESS <span class="op">+</span> RSS)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a><span class="co"># F-statistic</span></span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a>f_stat_manual <span class="op">=</span> (ESS <span class="op">/</span> (k<span class="op">-</span><span class="dv">1</span>)) <span class="op">/</span> (RSS <span class="op">/</span> df)</span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">F-statistic calculation:"</span>)</span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  F = (ESS/</span><span class="sc">{</span>k<span class="op">-</span><span class="dv">1</span><span class="sc">}</span><span class="ss">) / (RSS/</span><span class="sc">{</span>df<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  F = (</span><span class="sc">{</span>ESS<span class="sc">:,.2f}</span><span class="ss">/</span><span class="sc">{</span>k<span class="op">-</span><span class="dv">1</span><span class="sc">}</span><span class="ss">) / (</span><span class="sc">{</span>RSS<span class="sc">:,.2f}</span><span class="ss">/</span><span class="sc">{</span>df<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  F = </span><span class="sc">{</span>f_stat_manual<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  From model output: </span><span class="sc">{</span>f_stat<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Match: </span><span class="sc">{</span>np<span class="sc">.</span>isclose(f_stat_manual, f_stat)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Alternative formula using R²</span></span>
<span id="cb27-39"><a href="#cb27-39" aria-hidden="true" tabindex="-1"></a>r_squared <span class="op">=</span> model_full.rsquared</span>
<span id="cb27-40"><a href="#cb27-40" aria-hidden="true" tabindex="-1"></a>f_stat_rsq <span class="op">=</span> (r_squared <span class="op">/</span> (k<span class="op">-</span><span class="dv">1</span>)) <span class="op">/</span> ((<span class="dv">1</span> <span class="op">-</span> r_squared) <span class="op">/</span> df)</span>
<span id="cb27-41"><a href="#cb27-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Alternative formula using R²:"</span>)</span>
<span id="cb27-42"><a href="#cb27-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  F = (R²/(k-1)) / ((1-R²)/(n-k))"</span>)</span>
<span id="cb27-43"><a href="#cb27-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  F = (</span><span class="sc">{</span>r_squared<span class="sc">:.4f}</span><span class="ss">/</span><span class="sc">{</span>k<span class="op">-</span><span class="dv">1</span><span class="sc">}</span><span class="ss">) / (</span><span class="sc">{</span><span class="dv">1</span><span class="op">-</span>r_squared<span class="sc">:.4f}</span><span class="ss">/</span><span class="sc">{</span>df<span class="sc">}</span><span class="ss">)"</span>)</span>
<span id="cb27-44"><a href="#cb27-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  F = </span><span class="sc">{</span>f_stat_rsq<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb27-45"><a href="#cb27-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Match: </span><span class="sc">{</span>np<span class="sc">.</span>isclose(f_stat_rsq, f_stat)<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>======================================================================
11.6 F STATISTIC UNDER ASSUMPTIONS 1-4
======================================================================

----------------------------------------------------------------------
Manual F-statistic calculation
----------------------------------------------------------------------
Sum of Squares:
  Total (TSS): 39,145,826,896.55
  Explained (ESS): 25,466,429,041.83
  Residual (RSS): 13,679,397,854.73
  Check: TSS = ESS + RSS: True

F-statistic calculation:
  F = (ESS/6) / (RSS/22)
  F = (25,466,429,041.83/6) / (13,679,397,854.73/22)
  F = 6.8261
  From model output: 6.8261
  Match: True

Alternative formula using R²:
  F = (R²/(k-1)) / ((1-R²)/(n-k))
  F = (0.6506/6) / (0.3494/22)
  F = 6.8261
  Match: True</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p><strong>Key Concept 11.6: The F Statistic Under Homoskedasticity</strong></p>
<p>Under assumptions 1-4, the F-statistic can be computed from sums of squares: <span class="math inline">\(F = [(RSS_r - RSS_u)/q] / [RSS_u/(n-k)]\)</span>, or equivalently from <span class="math inline">\(R^2\)</span>: <span class="math inline">\(F = [(R_u^2 - R_r^2)/q] / [(1-R_u^2)/(n-k)]\)</span>. Larger F-values indicate the restrictions are inconsistent with the data.</p>
</blockquote>
</section>
<section id="subset-f-test-restricted-vs-unrestricted-model" class="level2">
<h2 class="anchored" data-anchor-id="subset-f-test-restricted-vs-unrestricted-model">Subset F-test: Restricted vs Unrestricted Model</h2>
<p>Now we compare the full model (unrestricted) with a simpler model containing only size (restricted).</p>
</section>
<section id="interpreting-the-model-comparison" class="level2">
<h2 class="anchored" data-anchor-id="interpreting-the-model-comparison">Interpreting the Model Comparison</h2>
<p><strong>What this comparison reveals:</strong></p>
<p>Comparing three nested models helps us understand the incremental value of adding variables:</p>
<p><strong>Model 1 (Simple): price ~ size</strong></p>
<ul>
<li><strong>R² = 0.618</strong>, <strong>Adj. R² = 0.603</strong>: Explains 61.8% of price variation</li>
<li><strong>F-stat = 43.58</strong>: Very strong overall significance</li>
<li><strong>Simplest and most parsimonious</strong></li>
</ul>
<p><strong>Model 2 (Intermediate): price ~ size + bedrooms</strong></p>
<ul>
<li><strong>R² = 0.618</strong>, <strong>Adj. R² = 0.589</strong>: Almost identical R² to Model 1</li>
<li><strong>F-stat = 21.03</strong>: Still significant, but weaker than Model 1</li>
<li><strong>Adding bedrooms barely improves fit</strong></li>
</ul>
<p><strong>Model 3 (Full): price ~ size + bedrooms + bathrooms + lotsize + age + monthsold</strong></p>
<ul>
<li><strong>R² = 0.651</strong>, <strong>Adj. R² = 0.555</strong>: Highest R², but <strong>lowest adjusted R²</strong></li>
<li><strong>F-stat = 6.83</strong>: Weakest overall significance (though still significant)</li>
<li><strong>Complexity penalty outweighs small improvement in fit</strong></li>
</ul>
<p><strong>Key insights:</strong></p>
<ol type="1">
<li><p><strong>Adjusted R² is crucial</strong>: While R² increases with more variables (always), adjusted R² accounts for the complexity penalty. Model 1 has the <strong>highest adjusted R²</strong>, indicating the best balance of fit and simplicity.</p></li>
<li><p><strong>Diminishing returns</strong>: Adding bedrooms (Model 2) provides essentially no improvement. Adding five more variables (Model 3) only increases R² from 0.618 to 0.651—a marginal gain.</p></li>
<li><p><strong>Statistical vs.&nbsp;practical significance</strong>: Model 3 is statistically significant overall (F = 6.83, p &lt; 0.001), but that doesn’t mean it’s the <strong>best</strong> model. Model 1 is superior on parsimony grounds.</p></li>
</ol>
<p><strong>Recommendation</strong>: <strong>Use Model 1</strong> (size only). It’s simpler, has the highest adjusted R², and loses almost nothing in explanatory power compared to more complex alternatives.</p>
<div id="cell-48" class="cell" data-execution_count="15">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Subset F-test using restricted and unrestricted models</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"-"</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Subset F-test: Restricted vs Unrestricted Model"</span>)</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Unrestricted model (already estimated as model_full)</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Restricted model (only size as regressor)</span></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>model_restricted <span class="op">=</span> ols(<span class="st">'price ~ size'</span>, data<span class="op">=</span>data_house).fit()</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Restricted model (only size):"</span>)</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model_restricted.summary())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
----------------------------------------------------------------------
Subset F-test: Restricted vs Unrestricted Model
----------------------------------------------------------------------

Restricted model (only size):
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  price   R-squared:                       0.617
Model:                            OLS   Adj. R-squared:                  0.603
Method:                 Least Squares   F-statistic:                     43.58
Date:                Wed, 21 Jan 2026   Prob (F-statistic):           4.41e-07
Time:                        15:15:57   Log-Likelihood:                -332.05
No. Observations:                  29   AIC:                             668.1
Df Residuals:                      27   BIC:                             670.8
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept    1.15e+05   2.15e+04      5.352      0.000    7.09e+04    1.59e+05
size          73.7710     11.175      6.601      0.000      50.842      96.700
==============================================================================
Omnibus:                        0.576   Durbin-Watson:                   1.219
Prob(Omnibus):                  0.750   Jarque-Bera (JB):                0.638
Skew:                          -0.078   Prob(JB):                        0.727
Kurtosis:                       2.290   Cond. No.                     9.45e+03
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 9.45e+03. This might indicate that there are
strong multicollinearity or other numerical problems.</code></pre>
</div>
</div>
</section>
<section id="interpreting-coefficient-stability-across-models" class="level2">
<h2 class="anchored" data-anchor-id="interpreting-coefficient-stability-across-models">Interpreting Coefficient Stability Across Models</h2>
<p><strong>What this table reveals about coefficient estimates:</strong></p>
<p>Tracking how coefficients change as we add variables helps diagnose <strong>multicollinearity</strong> and understand variable relationships:</p>
<p><strong>Size coefficient across models:</strong> - <strong>Model 1</strong>: $73.77 (SE = $11.17) - <strong>Model 2</strong>: $73.65 (SE = $11.50)<br>
- <strong>Model 3</strong>: $68.37 (SE = $15.39)</p>
<p><strong>What we observe:</strong></p>
<ol type="1">
<li><p><strong>Relatively stable point estimates</strong>: The size coefficient ranges from $68-$74 across models, suggesting the relationship is genuine and robust.</p></li>
<li><p><strong>Increasing standard errors</strong>: As we add variables, the SE increases from $11 to $15—a 38% increase. This reflects <strong>multicollinearity</strong>: size is correlated with other variables (larger houses have more bedrooms, bathrooms, etc.).</p></li>
<li><p><strong>Precision loss</strong>: In Model 1, we can estimate the size effect quite precisely (SE = $11). Adding correlated variables inflates uncertainty without improving the overall fit much.</p></li>
</ol>
<p><strong>Bedrooms paradox:</strong> - When added in Model 2, bedrooms show essentially no effect - In Model 3, the coefficient is $2,685 but with a huge SE of $9,193 - This means bedrooms add no information beyond what size already provides</p>
<p><strong>Economic lesson:</strong></p>
<p>This pattern is common in real estate data: once you control for total square footage, the number of rooms matters little. Two houses of identical size but different room configurations (e.g., one with 3 large bedrooms vs.&nbsp;one with 4 small bedrooms) sell for similar prices. <strong>Size is what buyers care about, not how that space is divided.</strong></p>
</section>
<section id="manual-f-test-calculation" class="level2">
<h2 class="anchored" data-anchor-id="manual-f-test-calculation">Manual F-test Calculation</h2>
</section>
<section id="interpreting-robust-standard-errors" class="level2">
<h2 class="anchored" data-anchor-id="interpreting-robust-standard-errors">Interpreting Robust Standard Errors</h2>
<p><strong>What robust standard errors tell us:</strong></p>
<p>Heteroskedasticity-robust (HC1) standard errors correct for potential violations of the constant variance assumption. Comparing standard vs.&nbsp;robust errors helps diagnose whether heteroskedasticity is a concern:</p>
<p><strong>Size coefficient:</strong> - <strong>Standard SE</strong>: $15.39 → <strong>Robust SE</strong>: $15.15 - <strong>Change</strong>: Slight decrease (1.6%) - <strong>Both t-stats highly significant</strong> (p ≈ 0.0002)</p>
<p><strong>Intercept:</strong> - <strong>Standard SE</strong>: $61,465 → <strong>Robust SE</strong>: $69,273 - <strong>Change</strong>: Increase of 12.7% - <strong>p-value changes</strong>: 0.035 → 0.047 (still significant, but closer to the boundary)</p>
<p><strong>Other variables:</strong> - Most show minor changes in SEs - All remain statistically insignificant with robust SEs - Conclusions unchanged</p>
<p><strong>What this means:</strong></p>
<ol type="1">
<li><p><strong>Mild heteroskedasticity</strong>: The fact that robust SEs are similar to standard SEs suggests heteroskedasticity is not a major problem in this dataset. If it were severe, we’d see much larger increases in robust SEs.</p></li>
<li><p><strong>Conclusions are robust</strong>: The key finding—that size is significant while other variables are not—holds regardless of which SE we use.</p></li>
<li><p><strong>Best practice</strong>: For cross-sectional data like housing prices, it’s wise to <strong>report robust SEs by default</strong>. They provide valid inference whether or not heteroskedasticity is present, with minimal cost.</p></li>
<li><p><strong>Intercept sensitivity</strong>: The intercept shows the largest change, but intercepts are rarely of economic interest. Our substantive conclusions about slope coefficients remain unchanged.</p></li>
</ol>
<div id="cell-52" class="cell" data-execution_count="16">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate F-statistic for subset test</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>k_unrest <span class="op">=</span> <span class="bu">len</span>(model_full.params)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>k_rest <span class="op">=</span> <span class="bu">len</span>(model_restricted.params)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>q <span class="op">=</span> k_unrest <span class="op">-</span> k_rest  <span class="co"># number of restrictions</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>RSS_unrest <span class="op">=</span> np.<span class="bu">sum</span>(model_full.resid<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>RSS_rest <span class="op">=</span> np.<span class="bu">sum</span>(model_restricted.resid<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>df_unrest <span class="op">=</span> n <span class="op">-</span> k_unrest</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>F_subset <span class="op">=</span> ((RSS_rest <span class="op">-</span> RSS_unrest) <span class="op">/</span> q) <span class="op">/</span> (RSS_unrest <span class="op">/</span> df_unrest)</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>p_value_subset <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> stats.f.cdf(F_subset, q, df_unrest)</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>f_crit_subset <span class="op">=</span> stats.f.ppf(<span class="fl">0.95</span>, q, df_unrest)</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Subset F-test results:"</span>)</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Number of restrictions (q): </span><span class="sc">{</span>q<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  RSS (restricted): </span><span class="sc">{</span>RSS_rest<span class="sc">:,.2f}</span><span class="ss">"</span>)</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  RSS (unrestricted): </span><span class="sc">{</span>RSS_unrest<span class="sc">:,.2f}</span><span class="ss">"</span>)</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Increase in RSS: </span><span class="sc">{</span>RSS_rest <span class="op">-</span> RSS_unrest<span class="sc">:,.2f}</span><span class="ss">"</span>)</span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  F-statistic: </span><span class="sc">{</span>F_subset<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  p-value: </span><span class="sc">{</span>p_value_subset<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Critical value (α=0.05): </span><span class="sc">{</span>f_crit_subset<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> F_subset <span class="op">&gt;</span> f_crit_subset:</span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Result: Reject H₀ - The additional variables are jointly significant"</span>)</span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"  Keep the full model."</span>)</span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Result: Fail to reject H₀ - The additional variables are NOT jointly significant"</span>)</span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"  The simpler model (only size) is preferred."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Subset F-test results:
  Number of restrictions (q): 5
  RSS (restricted): 14,975,101,654.50
  RSS (unrestricted): 13,679,397,854.73
  Increase in RSS: 1,295,703,799.78
  F-statistic: 0.4168
  p-value: 0.8320
  Critical value (α=0.05): 2.6613

Result: Fail to reject H₀ - The additional variables are NOT jointly significant
  The simpler model (only size) is preferred.</code></pre>
</div>
</div>
</section>
<section id="anova-table-comparison" class="level2">
<h2 class="anchored" data-anchor-id="anova-table-comparison">ANOVA Table Comparison</h2>
<div id="cell-54" class="cell" data-execution_count="17">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Using ANOVA table for comparison</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"-"</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"ANOVA table comparison"</span>)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>anova_results <span class="op">=</span> anova_lm(model_restricted, model_full)</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(anova_results)</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">The ANOVA table confirms our manual F-test calculation."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
----------------------------------------------------------------------
ANOVA table comparison
----------------------------------------------------------------------
   df_resid           ssr  df_diff       ss_diff         F    Pr(&gt;F)
0      27.0  1.497510e+10      0.0           NaN       NaN       NaN
1      22.0  1.367940e+10      5.0  1.295704e+09  0.416765  0.831976

The ANOVA table confirms our manual F-test calculation.</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p><strong>Key Concept 11.7: Testing Subsets of Regressors</strong></p>
<p>To test whether a subset of regressors belongs in the model, compare the restricted model (without those variables) to the unrestricted model (with them) using an F-test. If the F-statistic is small (large <span class="math inline">\(p\)</span>-value), the additional regressors don’t significantly improve fit and the simpler model is preferred.</p>
</blockquote>
<p>Now that we can compute and interpret F-statistics, let’s learn how to present regression results professionally.</p>
</section>
<section id="presentation-of-regression-results" class="level2">
<h2 class="anchored" data-anchor-id="presentation-of-regression-results">11.7: Presentation of Regression Results</h2>
<p>Professional presentation of regression results is important for communication. Different formats emphasize different aspects.</p>
<p><strong>Common presentation formats:</strong></p>
<ol type="1">
<li><strong>Coefficients with standard errors</strong> (in parentheses)</li>
<li><strong>Coefficients with t-statistics</strong> (in parentheses)</li>
<li><strong>Coefficients with p-values</strong> (in parentheses)</li>
<li><strong>Coefficients with 95% confidence intervals</strong></li>
<li><strong>Coefficients with significance stars</strong>:
<ul>
<li>*** for p &lt; 0.01 (1% level)</li>
<li>** for p &lt; 0.05 (5% level)</li>
<li><ul>
<li>for p &lt; 0.10 (10% level)</li>
</ul></li>
</ul></li>
</ol>
<p><strong>Model comparison tables</strong> typically show:</p>
<ul>
<li>Multiple model specifications side-by-side</li>
<li>Standard errors in parentheses below coefficients</li>
<li>Model fit statistics (R², N, F-stat) at bottom</li>
</ul>
<p>This allows readers to see how coefficient estimates change across specifications.</p>
<div id="cell-58" class="cell" data-execution_count="18">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"11.7 PRESENTATION OF REGRESSION RESULTS"</span>)</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparison of multiple models</span></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"-"</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Model Comparison: Three Specifications"</span>)</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Model 1: Simple regression</span></span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>model1 <span class="op">=</span> ols(<span class="st">'price ~ size'</span>, data<span class="op">=</span>data_house).fit()</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Model 2: Two regressors</span></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>model2 <span class="op">=</span> ols(<span class="st">'price ~ size + bedrooms'</span>, data<span class="op">=</span>data_house).fit()</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Model 3: Full model (already estimated as model_full)</span></span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>model3 <span class="op">=</span> model_full</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Create comparison table</span></span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> [model1, model2, model3]</span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>model_names <span class="op">=</span> [<span class="st">'Model 1'</span>, <span class="st">'Model 2'</span>, <span class="st">'Model 3'</span>]</span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>comparison_data <span class="op">=</span> []</span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> name, model <span class="kw">in</span> <span class="bu">zip</span>(model_names, models):</span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a>    model_stats <span class="op">=</span> {</span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Model'</span>: name,</span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a>        <span class="st">'N'</span>: <span class="bu">int</span>(model.nobs),</span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a>        <span class="st">'R²'</span>: <span class="ss">f"</span><span class="sc">{</span>model<span class="sc">.</span>rsquared<span class="sc">:.4f}</span><span class="ss">"</span>,</span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a>        <span class="st">'Adj. R²'</span>: <span class="ss">f"</span><span class="sc">{</span>model<span class="sc">.</span>rsquared_adj<span class="sc">:.4f}</span><span class="ss">"</span>,</span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a>        <span class="st">'RMSE'</span>: <span class="ss">f"</span><span class="sc">{</span>np<span class="sc">.</span>sqrt(model.mse_resid)<span class="sc">:.2f}</span><span class="ss">"</span>,</span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a>        <span class="st">'F-stat'</span>: <span class="ss">f"</span><span class="sc">{</span>model<span class="sc">.</span>fvalue<span class="sc">:.4f}</span><span class="ss">"</span>,</span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a>        <span class="st">'p-value'</span>: <span class="ss">f"</span><span class="sc">{</span>model<span class="sc">.</span>f_pvalue<span class="sc">:.6f}</span><span class="ss">"</span></span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a>    comparison_data.append(model_stats)</span>
<span id="cb35-35"><a href="#cb35-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-36"><a href="#cb35-36" aria-hidden="true" tabindex="-1"></a>comparison_df <span class="op">=</span> pd.DataFrame(comparison_data)</span>
<span id="cb35-37"><a href="#cb35-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(comparison_df.to_string(index<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb35-38"><a href="#cb35-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-39"><a href="#cb35-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Model specifications:"</span>)</span>
<span id="cb35-40"><a href="#cb35-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  Model 1: price ~ size"</span>)</span>
<span id="cb35-41"><a href="#cb35-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  Model 2: price ~ size + bedrooms"</span>)</span>
<span id="cb35-42"><a href="#cb35-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  Model 3: price ~ size + bedrooms + bathrooms + lotsize + age + monthsold"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>======================================================================
11.7 PRESENTATION OF REGRESSION RESULTS
======================================================================

----------------------------------------------------------------------
Model Comparison: Three Specifications
----------------------------------------------------------------------
  Model  N     R² Adj. R²     RMSE  F-stat  p-value
Model 1 29 0.6175  0.6033 23550.66 43.5796 0.000000
Model 2 29 0.6180  0.5886 23981.21 21.0340 0.000004
Model 3 29 0.6506  0.5552 24935.73  6.8261 0.000342

Model specifications:
  Model 1: price ~ size
  Model 2: price ~ size + bedrooms
  Model 3: price ~ size + bedrooms + bathrooms + lotsize + age + monthsold</code></pre>
</div>
</div>
</section>
<section id="detailed-coefficient-comparison-across-models" class="level2">
<h2 class="anchored" data-anchor-id="detailed-coefficient-comparison-across-models">Detailed Coefficient Comparison Across Models</h2>
<p>Now let’s see how coefficient estimates change as we add variables.</p>
<div id="cell-60" class="cell" data-execution_count="19">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Detailed coefficient comparison</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"-"</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Coefficient Comparison Across Models"</span>)</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Get all unique parameter names</span></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>all_params <span class="op">=</span> <span class="bu">set</span>()</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> model <span class="kw">in</span> models:</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>    all_params.update(model.params.index)</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>all_params <span class="op">=</span> <span class="bu">sorted</span>(all_params)</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Create coefficient table</span></span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>coef_comparison <span class="op">=</span> pd.DataFrame(index<span class="op">=</span>all_params)</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, (name, model) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">zip</span>(model_names, models), <span class="dv">1</span>):</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>    coef_col <span class="op">=</span> <span class="ss">f'</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss"> Coef'</span></span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a>    se_col <span class="op">=</span> <span class="ss">f'</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss"> SE'</span></span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a>    coef_comparison[coef_col] <span class="op">=</span> model.params.reindex(all_params)</span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a>    coef_comparison[se_col] <span class="op">=</span> model.bse.reindex(all_params)</span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(coef_comparison.fillna(<span class="st">'-'</span>))</span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Key observations:"</span>)</span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  - Size coefficient relatively stable across models"</span>)</span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  - Adding variables increases standard errors (multicollinearity)"</span>)</span>
<span id="cb37-26"><a href="#cb37-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  - Adjusted R² peaks at Model 1 (simplest model)"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
----------------------------------------------------------------------
Coefficient Comparison Across Models
----------------------------------------------------------------------
            Model 1 Coef    Model 1 SE   Model 2 Coef   Model 2 SE  \
Intercept  115017.282609  21489.359861  111690.856193  27589.07418   
age                    -             -              -            -   
bathrooms              -             -              -            -   
bedrooms               -             -    1553.458022  7846.866223   
lotsize                -             -              -            -   
monthsold              -             -              -            -   
size            73.77104     11.174911      72.408146    13.299618   

            Model 3 Coef    Model 3 SE  
Intercept  137791.065699  61464.951869  
age          -833.038602    719.334544  
bathrooms    6832.880015  15721.191544  
bedrooms     2685.315122   9192.525674  
lotsize      2303.221371   7226.535205  
monthsold   -2088.503625   3520.897859  
size           68.369419     15.389472  

Key observations:
  - Size coefficient relatively stable across models
  - Adding variables increases standard errors (multicollinearity)
  - Adjusted R² peaks at Model 1 (simplest model)</code></pre>
</div>
</div>
</section>
<section id="robust-standard-errors-heteroskedasticity-robust" class="level2">
<h2 class="anchored" data-anchor-id="robust-standard-errors-heteroskedasticity-robust">Robust Standard Errors (Heteroskedasticity-Robust)</h2>
<p>Classical OLS assumes constant error variance (homoskedasticity). When this fails, standard errors are incorrect.</p>
<p><strong>Heteroskedasticity-robust standard errors</strong> (HC1, White’s correction):</p>
<ul>
<li>Valid inference even when error variance is not constant</li>
<li>Typically larger than classical standard errors</li>
<li>Recommended for cross-sectional data</li>
</ul>
<p><strong>Effect on inference:</strong></p>
<ul>
<li>Coefficient estimates unchanged</li>
<li>Standard errors may increase</li>
<li>t-statistics may decrease</li>
<li>Some “significant” variables may become insignificant</li>
</ul>
<div id="cell-62" class="cell" data-execution_count="20">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"ROBUST STANDARD ERRORS (HC1)"</span>)</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Get robust results for full model</span></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>model_full_robust <span class="op">=</span> model_full.get_robustcov_results(cov_type<span class="op">=</span><span class="st">'HC1'</span>)</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Comparison of standard vs robust standard errors:"</span>)</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>robust_comparison <span class="op">=</span> pd.DataFrame({</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Coefficient'</span>: model_full.params,</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Std. Error'</span>: model_full.bse,</span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Robust SE'</span>: model_full_robust.bse,</span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">'t-stat (std)'</span>: model_full.tvalues,</span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">'t-stat (robust)'</span>: model_full_robust.tvalues,</span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">'p-value (std)'</span>: model_full.pvalues,</span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">'p-value (robust)'</span>: model_full_robust.pvalues</span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(robust_comparison)</span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Interpretation:"</span>)</span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  - Robust SEs are often larger (more conservative inference)"</span>)</span>
<span id="cb39-22"><a href="#cb39-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  - t-statistics are correspondingly smaller"</span>)</span>
<span id="cb39-23"><a href="#cb39-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  - Recommended to report robust SEs for cross-sectional data"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>======================================================================
ROBUST STANDARD ERRORS (HC1)
======================================================================

Comparison of standard vs robust standard errors:
             Coefficient    Std. Error     Robust SE  t-stat (std)  \
Intercept  137791.065699  61464.951869  65545.225391      2.241783   
size           68.369419     15.389472     15.359192      4.442610   
bedrooms     2685.315122   9192.525674   8285.528329      0.292119   
bathrooms    6832.880015  15721.191544  19283.790798      0.434629   
lotsize      2303.221371   7226.535205   5328.859590      0.318717   
age          -833.038602    719.334544    762.929519     -1.158068   
monthsold   -2088.503625   3520.897859   3738.270456     -0.593174   

           t-stat (robust)  p-value (std)  p-value (robust)  
Intercept         2.102229       0.035387          0.047203  
size              4.451368       0.000205          0.000200  
bedrooms          0.324097       0.772932          0.748926  
bathrooms         0.354333       0.668065          0.726463  
lotsize           0.432217       0.752947          0.669791  
age              -1.091895       0.259254          0.286693  
monthsold        -0.558682       0.559114          0.582021  

Interpretation:
  - Robust SEs are often larger (more conservative inference)
  - t-statistics are correspondingly smaller
  - Recommended to report robust SEs for cross-sectional data</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p><strong>Key Concept 11.8: Robust Standard Errors and Heteroskedasticity</strong></p>
<p>When errors may not have constant variance, heteroskedasticity-robust (HC1) standard errors provide valid inference without assuming homoskedasticity. Coefficient estimates remain unchanged, but standard errors — and thus t-statistics and p-values — may differ. For cross-sectional data, reporting robust SEs is considered best practice.</p>
</blockquote>
</section>
<section id="visualization-confidence-intervals-for-all-coefficients" class="level2">
<h2 class="anchored" data-anchor-id="visualization-confidence-intervals-for-all-coefficients">Visualization: Confidence Intervals for All Coefficients</h2>
<p>A coefficient plot provides a visual summary of estimation results.</p>
<div id="cell-65" class="cell" data-execution_count="21">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Figure 11.1: Confidence intervals for all coefficients</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">8</span>))</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>params_no_int <span class="op">=</span> model_full.params[<span class="dv">1</span>:]</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>ci_no_int <span class="op">=</span> conf_int.iloc[<span class="dv">1</span>:, :]</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>y_pos <span class="op">=</span> np.arange(<span class="bu">len</span>(params_no_int))</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>ax.errorbar(params_no_int.values, y_pos,</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>            xerr<span class="op">=</span>[params_no_int.values <span class="op">-</span> ci_no_int.iloc[:, <span class="dv">0</span>].values,</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>                  ci_no_int.iloc[:, <span class="dv">1</span>].values <span class="op">-</span> params_no_int.values],</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>            fmt<span class="op">=</span><span class="st">'o'</span>, markersize<span class="op">=</span><span class="dv">8</span>, capsize<span class="op">=</span><span class="dv">5</span>, capthick<span class="op">=</span><span class="dv">2</span>, linewidth<span class="op">=</span><span class="dv">2</span>, color<span class="op">=</span><span class="st">'blue'</span>)</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>ax.set_yticks(y_pos)</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a>ax.set_yticklabels(params_no_int.index)</span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a>ax.axvline(x<span class="op">=</span><span class="dv">0</span>, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, linewidth<span class="op">=</span><span class="fl">1.5</span>, alpha<span class="op">=</span><span class="fl">0.7</span>,</span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a>           label<span class="op">=</span><span class="st">'H₀: β = 0'</span>)</span>
<span id="cb41-16"><a href="#cb41-16" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Coefficient Value'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb41-17"><a href="#cb41-17" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Figure 11.1: Coefficient Estimates with 95% Confidence Intervals'</span>,</span>
<span id="cb41-18"><a href="#cb41-18" aria-hidden="true" tabindex="-1"></a>             fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb41-19"><a href="#cb41-19" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb41-20"><a href="#cb41-20" aria-hidden="true" tabindex="-1"></a>ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>, axis<span class="op">=</span><span class="st">'x'</span>)</span>
<span id="cb41-21"><a href="#cb41-21" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb41-22"><a href="#cb41-22" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb41-23"><a href="#cb41-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-24"><a href="#cb41-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Coefficients whose CI crosses zero are not statistically significant at 5%."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stderr">
<pre><code>/var/folders/tq/t98kb27n6djgrh085g476yhc0000gn/T/ipykernel_56083/677075515.py:21: UserWarning: Glyph 8320 (\N{SUBSCRIPT ZERO}) missing from current font.
  plt.tight_layout()
/Users/carlosmendez/miniforge3/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 8320 (\N{SUBSCRIPT ZERO}) missing from current font.
  fig.canvas.print_figure(bytes_io, **kw)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ch11_Statistical_Inference_for_Multiple_Regression_files/figure-html/cell-22-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Coefficients whose CI crosses zero are not statistically significant at 5%.</code></pre>
</div>
</div>
</section>
<section id="visualization-f-distribution" class="level2">
<h2 class="anchored" data-anchor-id="visualization-f-distribution">Visualization: F-Distribution</h2>
<p>Visualize the F-distribution and show where our test statistic falls.</p>
<div id="cell-67" class="cell" data-execution_count="22">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Figure: F-distribution visualization</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>x_range <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">1000</span>)</span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>f_pdf <span class="op">=</span> stats.f.pdf(x_range, dfn, dfd)</span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>ax.plot(x_range, f_pdf, <span class="st">'b-'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span><span class="ss">f'F(</span><span class="sc">{</span>dfn<span class="sc">}</span><span class="ss">, </span><span class="sc">{</span>dfd<span class="sc">}</span><span class="ss">) distribution'</span>)</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>ax.axvline(x<span class="op">=</span>f_stat, color<span class="op">=</span><span class="st">'red'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, linestyle<span class="op">=</span><span class="st">'--'</span>,</span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>           label<span class="op">=</span><span class="ss">f'Observed F = </span><span class="sc">{</span>f_stat<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a>ax.axvline(x<span class="op">=</span>f_crit, color<span class="op">=</span><span class="st">'green'</span>, linewidth<span class="op">=</span><span class="dv">2</span>, linestyle<span class="op">=</span><span class="st">':'</span>,</span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a>           label<span class="op">=</span><span class="ss">f'Critical value = </span><span class="sc">{</span>f_crit<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-13"><a href="#cb44-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Shade rejection region</span></span>
<span id="cb44-14"><a href="#cb44-14" aria-hidden="true" tabindex="-1"></a>x_reject <span class="op">=</span> x_range[x_range <span class="op">&gt;=</span> f_crit]</span>
<span id="cb44-15"><a href="#cb44-15" aria-hidden="true" tabindex="-1"></a>f_reject <span class="op">=</span> stats.f.pdf(x_reject, dfn, dfd)</span>
<span id="cb44-16"><a href="#cb44-16" aria-hidden="true" tabindex="-1"></a>ax.fill_between(x_reject, <span class="dv">0</span>, f_reject, alpha<span class="op">=</span><span class="fl">0.3</span>, color<span class="op">=</span><span class="st">'red'</span>,</span>
<span id="cb44-17"><a href="#cb44-17" aria-hidden="true" tabindex="-1"></a>                label<span class="op">=</span><span class="st">'Rejection region (α=0.05)'</span>)</span>
<span id="cb44-18"><a href="#cb44-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-19"><a href="#cb44-19" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'F-statistic'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb44-20"><a href="#cb44-20" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Density'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb44-21"><a href="#cb44-21" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'F-Distribution for Overall Significance Test'</span>,</span>
<span id="cb44-22"><a href="#cb44-22" aria-hidden="true" tabindex="-1"></a>             fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb44-23"><a href="#cb44-23" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb44-24"><a href="#cb44-24" aria-hidden="true" tabindex="-1"></a>ax.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb44-25"><a href="#cb44-25" aria-hidden="true" tabindex="-1"></a>ax.set_xlim(<span class="dv">0</span>, <span class="bu">max</span>(<span class="dv">8</span>, f_stat <span class="op">+</span> <span class="dv">1</span>))</span>
<span id="cb44-26"><a href="#cb44-26" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb44-27"><a href="#cb44-27" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb44-28"><a href="#cb44-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-29"><a href="#cb44-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"The observed F-statistic (</span><span class="sc">{</span>f_stat<span class="sc">:.2f}</span><span class="ss">) exceeds the critical value (</span><span class="sc">{</span>f_crit<span class="sc">:.2f}</span><span class="ss">)."</span>)</span>
<span id="cb44-30"><a href="#cb44-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"This leads us to reject the null hypothesis of no relationship."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ch11_Statistical_Inference_for_Multiple_Regression_files/figure-html/cell-23-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>The observed F-statistic (6.83) exceeds the critical value (2.55).
This leads us to reject the null hypothesis of no relationship.</code></pre>
</div>
</div>
</section>
<section id="visualization-model-comparison-actual-vs-predicted" class="level2">
<h2 class="anchored" data-anchor-id="visualization-model-comparison-actual-vs-predicted">Visualization: Model Comparison (Actual vs Predicted)</h2>
<p>Compare the three models visually by plotting actual vs.&nbsp;predicted values.</p>
<div id="cell-69" class="cell" data-execution_count="23">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Figure: Model comparison visualization</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">18</span>, <span class="dv">5</span>))</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, (model, name) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="bu">zip</span>(models, model_names)):</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>    axes[i].scatter(data_house[<span class="st">'price'</span>], model.fittedvalues,</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>                   alpha<span class="op">=</span><span class="fl">0.6</span>, s<span class="op">=</span><span class="dv">50</span>, color<span class="op">=</span><span class="st">'black'</span>)</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>    axes[i].plot([data_house[<span class="st">'price'</span>].<span class="bu">min</span>(), data_house[<span class="st">'price'</span>].<span class="bu">max</span>()],</span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>                [data_house[<span class="st">'price'</span>].<span class="bu">min</span>(), data_house[<span class="st">'price'</span>].<span class="bu">max</span>()],</span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>                <span class="st">'r--'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>    axes[i].set_xlabel(<span class="st">'Actual Price ($)'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>    axes[i].set_ylabel(<span class="st">'Predicted Price ($)'</span>, fontsize<span class="op">=</span><span class="dv">11</span>)</span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a>    axes[i].set_title(<span class="ss">f'</span><span class="sc">{</span>name<span class="sc">}</span><span class="ch">\n</span><span class="ss">R² = </span><span class="sc">{</span>model<span class="sc">.</span>rsquared<span class="sc">:.4f}</span><span class="ss">'</span>,</span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a>                     fontsize<span class="op">=</span><span class="dv">11</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a>    axes[i].grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">'Model Comparison: Actual vs Predicted Prices'</span>,</span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a>             fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>, y<span class="op">=</span><span class="fl">1.00</span>)</span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-21"><a href="#cb46-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"All three models show similar predictive performance."</span>)</span>
<span id="cb46-22"><a href="#cb46-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The simplest model (Model 1) may be preferred for parsimony."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ch11_Statistical_Inference_for_Multiple_Regression_files/figure-html/cell-24-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>All three models show similar predictive performance.
The simplest model (Model 1) may be preferred for parsimony.</code></pre>
</div>
</div>
</section>
<section id="key-takeaways" class="level2">
<h2 class="anchored" data-anchor-id="key-takeaways">Key Takeaways</h2>
<p><strong>Classical Assumptions and OLS Properties:</strong> - Under assumptions 1-4 (linearity, random sampling, no perfect collinearity, zero conditional mean), OLS is unbiased, consistent, and efficient (BLUE) - The standard error <span class="math inline">\(se(b_j) = s_e / \sqrt{\sum \widetilde{x}_{ji}^2}\)</span> decreases with larger samples, more variation in <span class="math inline">\(x_j\)</span>, and lower multicollinearity - The <span class="math inline">\(t\)</span>-statistic <span class="math inline">\(t = b_j / se(b_j)\)</span> follows a <span class="math inline">\(T(n-k)\)</span> distribution</p>
<p><strong>Confidence Intervals:</strong> - 95% CI: <span class="math inline">\(b_j \pm t_{n-k, 0.025} \times se(b_j)\)</span> - If the CI excludes zero, the coefficient is statistically significant at 5% - Narrower CIs indicate more precise estimation</p>
<p><strong>Individual Hypothesis Tests:</strong> - Test <span class="math inline">\(H_0: \beta_j = \beta_j^*\)</span> using <span class="math inline">\(t = (b_j - \beta_j^*) / se(b_j)\)</span> - Most common: test of significance <span class="math inline">\(H_0: \beta_j = 0\)</span> — does variable <span class="math inline">\(x_j\)</span> matter after controlling for others? - Reject <span class="math inline">\(H_0\)</span> if <span class="math inline">\(|t| &gt; t_{\text{critical}}\)</span> or equivalently if <span class="math inline">\(p\)</span>-value <span class="math inline">\(&lt; \alpha\)</span></p>
<p><strong>Joint F-Tests:</strong> - F-test evaluates multiple restrictions simultaneously: <span class="math inline">\(F = \frac{(RSS_r - RSS_u)/q}{RSS_u/(n-k)} \sim F(q, n-k)\)</span> - Overall significance test: <span class="math inline">\(H_0: \beta_2 = \cdots = \beta_k = 0\)</span> (all slopes zero) - Subset tests: compare restricted vs.&nbsp;unrestricted models to decide if additional regressors are needed - Equivalently: <span class="math inline">\(F = \frac{(R_u^2 - R_r^2)/q}{(1 - R_u^2)/(n-k)}\)</span></p>
<p><strong>Model Comparison and Selection:</strong> - Use F-tests to formally compare nested models - Consider adjusted <span class="math inline">\(R^2\)</span>, AIC, BIC alongside F-tests - Prefer parsimony: if additional variables don’t significantly improve fit, use the simpler model - In our house price example, size alone was sufficient — five additional variables failed the joint F-test (<span class="math inline">\(p = 0.83\)</span>)</p>
<p><strong>Presenting Results and Robust Inference:</strong> - Five standard formats: coefficients with (SEs), (t-stats), (p-values), (CIs), or (asterisks) - Heteroskedasticity-robust (HC1) standard errors provide valid inference without assuming constant variance - Report robust SEs by default for cross-sectional data</p>
<p><strong>Python tools used:</strong> <code>statsmodels</code> (OLS, t_test, f_test, anova_lm, HC1), <code>scipy.stats</code> (t and F distributions), <code>matplotlib</code>/<code>seaborn</code> (coefficient plots, F-distribution)</p>
<p><strong>Next steps:</strong> Chapter 12 covers <strong>further inference and model specification</strong> — additional diagnostic tests and extensions to the multiple regression framework.</p>
<p>Congratulations on completing Chapter 11! You can now conduct rigorous statistical inference for multiple regression models.</p>
</section>
<section id="practice-exercises" class="level2">
<h2 class="anchored" data-anchor-id="practice-exercises">Practice Exercises</h2>
<p>Test your understanding of statistical inference for multiple regression.</p>
<hr>
<p><strong>Exercise 1: Confidence Interval Calculation</strong></p>
<p>A multiple regression with <span class="math inline">\(n = 200\)</span> observations and <span class="math inline">\(k = 4\)</span> parameters yields: - <span class="math inline">\(b_2 = 5.0\)</span>, <span class="math inline">\(se(b_2) = 2.0\)</span> - <span class="math inline">\(b_3 = 7.0\)</span>, <span class="math inline">\(se(b_3) = 2.0\)</span></p>
<ol type="a">
<li><p>Compute an approximate 95% confidence interval for <span class="math inline">\(\beta_2\)</span>.</p></li>
<li><p>Compute an approximate 95% confidence interval for <span class="math inline">\(\beta_3\)</span>.</p></li>
<li><p>Which coefficient is estimated more precisely? Explain.</p></li>
</ol>
<hr>
<p><strong>Exercise 2: Test of Statistical Significance</strong></p>
<p>Using the regression from Exercise 1:</p>
<ol type="a">
<li><p>Is <span class="math inline">\(x_2\)</span> statistically significant at the 5% level? Compute the <span class="math inline">\(t\)</span>-statistic and state your conclusion.</p></li>
<li><p>Is <span class="math inline">\(x_3\)</span> statistically significant at the 5% level?</p></li>
<li><p>What is the approximate <span class="math inline">\(p\)</span>-value for each coefficient?</p></li>
</ol>
<hr>
<p><strong>Exercise 3: Testing a Specific Value</strong></p>
<p>Using the same regression, test the claim that <span class="math inline">\(\beta_3 = 10.0\)</span> at significance level 0.05.</p>
<ol type="a">
<li><p>State the null and alternative hypotheses.</p></li>
<li><p>Compute the <span class="math inline">\(t\)</span>-statistic.</p></li>
<li><p>What is your decision? Can you reject <span class="math inline">\(H_0\)</span>?</p></li>
</ol>
<hr>
<p><strong>Exercise 4: Joint F-Test Setup</strong></p>
<p>Consider the model <span class="math inline">\(y = \beta_1 + \beta_2 x_2 + \beta_3 x_3 + \beta_4 x_4 + \beta_5 x_5 + \beta_6 x_6 + u\)</span>.</p>
<p>We wish to test whether only <span class="math inline">\(x_2\)</span> and <span class="math inline">\(x_3\)</span> should be included in the model.</p>
<ol type="a">
<li><p>State <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_a\)</span> for this test.</p></li>
<li><p>How many restrictions are being tested (<span class="math inline">\(q\)</span>)?</p></li>
<li><p>What are the degrees of freedom for the F-test if <span class="math inline">\(n = 100\)</span>?</p></li>
</ol>
<hr>
<p><strong>Exercise 5: F-Statistic Computation</strong></p>
<p>You estimate two models on <span class="math inline">\(n = 53\)</span> observations: - Restricted model (<span class="math inline">\(k_r = 3\)</span>): <span class="math inline">\(RSS_r = 40\)</span> - Unrestricted model (<span class="math inline">\(k_u = 6\)</span>): <span class="math inline">\(RSS_u = 30\)</span></p>
<ol type="a">
<li><p>Compute the F-statistic.</p></li>
<li><p>What are the degrees of freedom?</p></li>
<li><p>At <span class="math inline">\(\alpha = 0.05\)</span>, would you reject the restrictions?</p></li>
</ol>
<hr>
<p><strong>Exercise 6: Regression Presentation</strong></p>
<p>Given these regression results:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Variable</th>
<th>Coefficient</th>
<th>Std. Error</th>
<th>p-value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Intercept</td>
<td>3.0</td>
<td>1.5</td>
<td>0.047</td>
</tr>
<tr class="even">
<td><span class="math inline">\(x_2\)</span></td>
<td>5.0</td>
<td>2.0</td>
<td>0.013</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(x_3\)</span></td>
<td>7.0</td>
<td>2.0</td>
<td>0.001</td>
</tr>
</tbody>
</table>
<ol type="a">
<li><p>Present these results using the asterisk notation (*** for <span class="math inline">\(p &lt; 0.01\)</span>, ** for <span class="math inline">\(p &lt; 0.05\)</span>, * for <span class="math inline">\(p &lt; 0.10\)</span>).</p></li>
<li><p>Present using the coefficient (standard error) format.</p></li>
<li><p>Which variables are significant at the 1% level? At the 5% level?</p></li>
</ol>
</section>
<section id="case-studies" class="level2">
<h2 class="anchored" data-anchor-id="case-studies">Case Studies</h2>
<section id="case-study-1-statistical-inference-for-cross-country-productivity" class="level3">
<h3 class="anchored" data-anchor-id="case-study-1-statistical-inference-for-cross-country-productivity">Case Study 1: Statistical Inference for Cross-Country Productivity</h3>
<p>In this case study, you will apply confidence intervals, hypothesis tests, and F-tests to investigate whether physical capital and human capital are statistically significant determinants of cross-country labor productivity differences.</p>
<p><strong>Dataset:</strong> Mendez Convergence Clubs Data - <strong>Source:</strong> Mendez (2020), 108 countries, 1990-2014 - <strong>Key variables:</strong> - <code>lp</code> — Labor productivity (GDP per worker) - <code>rk</code> — Physical capital per worker - <code>hc</code> — Human capital index - <code>region</code> — Geographic region</p>
<p><strong>Research question:</strong> Are physical capital and human capital jointly significant in explaining cross-country labor productivity?</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the Mendez convergence clubs dataset</span></span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">"https://raw.githubusercontent.com/quarcs-lab/mendez2020-convergence-clubs-code-data/master/assets/dat.csv"</span></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>dat <span class="op">=</span> pd.read_csv(url)</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>dat_2014 <span class="op">=</span> dat[dat[<span class="st">'year'</span>] <span class="op">==</span> <span class="dv">2014</span>].dropna(subset<span class="op">=</span>[<span class="st">'lp'</span>, <span class="st">'rk'</span>, <span class="st">'hc'</span>]).copy()</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>dat_2014[<span class="st">'ln_lp'</span>] <span class="op">=</span> np.log(dat_2014[<span class="st">'lp'</span>])</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>dat_2014[<span class="st">'ln_rk'</span>] <span class="op">=</span> np.log(dat_2014[<span class="st">'rk'</span>])</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Cross-section sample: </span><span class="sc">{</span><span class="bu">len</span>(dat_2014)<span class="sc">}</span><span class="ss"> countries (year 2014)"</span>)</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>dat_2014.head()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<section id="task-1-estimate-productivity-model-guided" class="level4">
<h4 class="anchored" data-anchor-id="task-1-estimate-productivity-model-guided">Task 1: Estimate Productivity Model (Guided)</h4>
<p>Estimate the multiple regression model for labor productivity.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate: ln(lp) = beta_0 + beta_1 * ln(rk) + beta_2 * hc + u</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>model_prod <span class="op">=</span> ols(<span class="st">'ln_lp ~ ln_rk + hc'</span>, data<span class="op">=</span>dat_2014).fit()</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model_prod.summary())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Questions:</strong> - How many observations and parameters does the model have? - What is the <span class="math inline">\(R^2\)</span>? How much of productivity variation do capital and human capital explain?</p>
</section>
<section id="task-2-confidence-intervals-guided" class="level4">
<h4 class="anchored" data-anchor-id="task-2-confidence-intervals-guided">Task 2: Confidence Intervals (Guided)</h4>
<p>Compute and interpret 95% confidence intervals for the coefficients.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 95% confidence intervals</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"95% Confidence Intervals:"</span>)</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model_prod.conf_int(alpha<span class="op">=</span><span class="fl">0.05</span>))</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Manual calculation for ln_rk coefficient</span></span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>b_rk <span class="op">=</span> model_prod.params[<span class="st">'ln_rk'</span>]</span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>se_rk <span class="op">=</span> model_prod.bse[<span class="st">'ln_rk'</span>]</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> model_prod.df_resid</span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a>t_crit <span class="op">=</span> stats.t.ppf(<span class="fl">0.975</span>, df)</span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Manual CI for ln(rk): [</span><span class="sc">{</span>b_rk <span class="op">-</span> t_crit<span class="op">*</span>se_rk<span class="sc">:.4f}</span><span class="ss">, </span><span class="sc">{</span>b_rk <span class="op">+</span> t_crit<span class="op">*</span>se_rk<span class="sc">:.4f}</span><span class="ss">]"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Questions:</strong> - Does the CI for <span class="math inline">\(\ln(\text{rk})\)</span> exclude zero? What does this tell you? - Does the CI for hc exclude zero? Interpret in economic terms.</p>
<blockquote class="blockquote">
<p><strong>Key Concept 11.9: Statistical Significance in Cross-Country Regressions</strong></p>
<p>With over 100 countries, cross-country regressions have sufficient power to detect moderate effects. However, statistical significance does not imply causation — unobserved factors (institutions, geography, culture) may confound the relationship between capital inputs and productivity. Confidence intervals quantify estimation uncertainty but not omitted variable bias.</p>
</blockquote>
</section>
<section id="task-3-individual-hypothesis-tests-semi-guided" class="level4">
<h4 class="anchored" data-anchor-id="task-3-individual-hypothesis-tests-semi-guided">Task 3: Individual Hypothesis Tests (Semi-guided)</h4>
<p>Test the statistical significance of each coefficient.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Test significance of each coefficient</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"t-statistics and p-values:"</span>)</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> var <span class="kw">in</span> [<span class="st">'ln_rk'</span>, <span class="st">'hc'</span>]:</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>    t <span class="op">=</span> model_prod.tvalues[var]</span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> model_prod.pvalues[var]</span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>    sig <span class="op">=</span> <span class="st">'***'</span> <span class="cf">if</span> p <span class="op">&lt;</span> <span class="fl">0.01</span> <span class="cf">else</span> <span class="st">'**'</span> <span class="cf">if</span> p <span class="op">&lt;</span> <span class="fl">0.05</span> <span class="cf">else</span> <span class="st">'*'</span> <span class="cf">if</span> p <span class="op">&lt;</span> <span class="fl">0.10</span> <span class="cf">else</span> <span class="st">''</span></span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>var<span class="sc">}</span><span class="ss">: t = </span><span class="sc">{</span>t<span class="sc">:.3f}</span><span class="ss">, p = </span><span class="sc">{</span>p<span class="sc">:.4f}</span><span class="ss"> </span><span class="sc">{</span>sig<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Questions:</strong> - Which coefficients are significant at the 1% level? At the 5% level? - Interpret the economic meaning: what does significance of <span class="math inline">\(\ln(\text{rk})\)</span> tell us about physical capital?</p>
</section>
<section id="task-4-joint-f-test-semi-guided" class="level4">
<h4 class="anchored" data-anchor-id="task-4-joint-f-test-semi-guided">Task 4: Joint F-Test (Semi-guided)</h4>
<p>Test whether physical capital and human capital are jointly significant.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Overall F-test: H0: beta_1 = beta_2 = 0</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Overall F-statistic: </span><span class="sc">{</span>model_prod<span class="sc">.</span>fvalue<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"p-value: </span><span class="sc">{</span>model_prod<span class="sc">.</span>f_pvalue<span class="sc">:.6e}</span><span class="ss">"</span>)</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare to restricted model (intercept only)</span></span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>model_restricted <span class="op">=</span> ols(<span class="st">'ln_lp ~ 1'</span>, data<span class="op">=</span>dat_2014).fit()</span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a>anova_result <span class="op">=</span> anova_lm(model_restricted, model_prod)</span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">ANOVA comparison:"</span>)</span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(anova_result)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Questions:</strong> - Can you reject <span class="math inline">\(H_0: \beta_1 = \beta_2 = 0\)</span>? What does this mean economically? - How does the F-test relate to the individual <span class="math inline">\(t\)</span>-tests?</p>
</section>
<section id="task-5-model-comparison-independent" class="level4">
<h4 class="anchored" data-anchor-id="task-5-model-comparison-independent">Task 5: Model Comparison (Independent)</h4>
<p>Compare nested models to determine the best specification.</p>
<p><strong>Your tasks:</strong> 1. Estimate three models: (a) <span class="math inline">\(\ln(\text{lp}) \sim \ln(\text{rk})\)</span> only, (b) <span class="math inline">\(\ln(\text{lp}) \sim \text{hc}\)</span> only, (c) both regressors 2. Create a model comparison table with <span class="math inline">\(R^2\)</span>, adjusted <span class="math inline">\(R^2\)</span>, AIC, BIC 3. Conduct subset F-tests: does adding hc to the <span class="math inline">\(\ln(\text{rk})\)</span>-only model significantly improve fit? 4. Report robust standard errors for the preferred model</p>
<p><em>Hint: Use <code>anova_lm(model_restricted, model_unrestricted)</code> for the F-test and <code>model.get_robustcov_results(cov_type='HC1')</code> for robust SEs.</em></p>
</section>
<section id="task-6-inference-policy-brief-independent" class="level4">
<h4 class="anchored" data-anchor-id="task-6-inference-policy-brief-independent">Task 6: Inference Policy Brief (Independent)</h4>
<p>Write a 200-300 word policy brief summarizing your inference results.</p>
<p><strong>Your brief should address:</strong> 1. Which factors are statistically significant predictors of cross-country productivity? 2. What are the 95% confidence intervals for the effects of capital and human capital? 3. Are both factors jointly significant? What does the F-test tell us? 4. What policy implications follow from these findings? 5. What caveats should policymakers consider (association vs.&nbsp;causation, omitted variables)?</p>
<blockquote class="blockquote">
<p><strong>Key Concept 11.10: From Statistical Significance to Policy Relevance</strong></p>
<p>Finding that both physical and human capital are statistically significant predictors of productivity suggests that investments in both areas may boost economic output. However, the magnitudes matter for policy: confidence intervals tell us the plausible range of effects, while F-tests confirm that both factors jointly matter beyond what each contributes alone. Policy decisions should weigh statistical evidence alongside practical considerations like cost-effectiveness and implementation feasibility.</p>
</blockquote>
</section>
</section>
<section id="what-youve-learned" class="level3">
<h3 class="anchored" data-anchor-id="what-youve-learned">What You’ve Learned</h3>
<p>In this case study, you applied the full statistical inference toolkit to cross-country productivity data:</p>
<ul>
<li>Estimated multiple regression models and examined coefficient properties</li>
<li>Constructed and interpreted confidence intervals for partial effects</li>
<li>Conducted individual <span class="math inline">\(t\)</span>-tests to assess each predictor’s significance</li>
<li>Performed joint F-tests to evaluate whether both capital types matter</li>
<li>Compared nested models and reported results with robust standard errors</li>
</ul>
<p>These inferential tools are essential for drawing reliable conclusions from empirical economic analysis.</p>
</section>
<section id="case-study-2-which-satellite-features-matter-joint-tests-for-predictive-power" class="level3">
<h3 class="anchored" data-anchor-id="case-study-2-which-satellite-features-matter-joint-tests-for-predictive-power">Case Study 2: Which Satellite Features Matter? Joint Tests for Predictive Power</h3>
<p>In Chapter 10, we estimated a multiple regression of municipal development on nighttime lights and satellite embeddings. Now we apply Chapter 11’s inference tools—t-tests for individual coefficients and F-tests for joint significance—to determine which satellite features add statistically significant predictive power.</p>
<p><strong>Dataset:</strong> DS4Bolivia — Satellite Data for Sustainable Development</p>
<ul>
<li><strong>Source:</strong> <a href="https://github.com/quarcs-lab/ds4bolivia">DS4Bolivia Project</a>, 339 municipalities</li>
<li><strong>Key variables:</strong>
<ul>
<li><code>imds</code> — Municipal Sustainable Development Index (0-100 composite)</li>
<li><code>ln_NTLpc2017</code> — Log nighttime lights per capita (2017)</li>
<li><code>A00</code>, <code>A10</code>, <code>A20</code>, <code>A30</code>, <code>A40</code> — Selected satellite image embedding dimensions</li>
</ul></li>
</ul>
<p><strong>Research question:</strong> Do satellite image embeddings add statistically significant predictive power for municipal development beyond nighttime lights alone?</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the DS4Bolivia dataset</span></span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>url_bol <span class="op">=</span> <span class="st">"https://raw.githubusercontent.com/quarcs-lab/ds4bolivia/master/ds4bolivia_v20250523.csv"</span></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>bol <span class="op">=</span> pd.read_csv(url_bol)</span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Select variables and prepare analysis sample</span></span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a>embed_vars <span class="op">=</span> [<span class="st">'A00'</span>, <span class="st">'A10'</span>, <span class="st">'A20'</span>, <span class="st">'A30'</span>, <span class="st">'A40'</span>]</span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a>analysis_vars <span class="op">=</span> [<span class="st">'imds'</span>, <span class="st">'ln_NTLpc2017'</span>] <span class="op">+</span> embed_vars</span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a>bol_cs <span class="op">=</span> bol[[<span class="st">'mun'</span>, <span class="st">'dep'</span>] <span class="op">+</span> analysis_vars].dropna(subset<span class="op">=</span>analysis_vars).copy()</span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Analysis sample: </span><span class="sc">{</span><span class="bu">len</span>(bol_cs)<span class="sc">}</span><span class="ss"> municipalities with complete data"</span>)</span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a>bol_cs[analysis_vars].describe().<span class="bu">round</span>(<span class="dv">3</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<section id="task-1-estimate-full-model-guided" class="level4">
<h4 class="anchored" data-anchor-id="task-1-estimate-full-model-guided">Task 1: Estimate Full Model (Guided)</h4>
<p>Estimate the full multiple regression model with nighttime lights and all five satellite embedding dimensions as predictors of municipal development.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate: imds = beta_0 + beta_1*ln_NTLpc2017 + beta_2*A00 + ... + beta_6*A40 + u</span></span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>model_full <span class="op">=</span> ols(<span class="st">'imds ~ ln_NTLpc2017 + A00 + A10 + A20 + A30 + A40'</span>, data<span class="op">=</span>bol_cs).fit()</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model_full.summary())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Questions:</strong></p>
<ul>
<li>How many coefficients are estimated (including the intercept)?</li>
<li>Which coefficients have p-values below 0.05? Below 0.10?</li>
<li>What is the overall <span class="math inline">\(R^2\)</span>? How much variation in development does this model explain?</li>
<li>Compare this <span class="math inline">\(R^2\)</span> to a model with NTL alone—how much do the embeddings add?</li>
</ul>
<div id="cell-84" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Your code here: Estimate the full model</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Steps:</span></span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Estimate the full model with NTL and all 5 embeddings</span></span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Print the full summary</span></span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Identify significant coefficients (p &lt; 0.05 and p &lt; 0.10)</span></span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Example structure:</span></span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a><span class="co"># model_full = ols('imds ~ ln_NTLpc2017 + A00 + A10 + A20 + A30 + A40', data=bol_cs).fit()</span></span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a><span class="co"># print(model_full.summary())</span></span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb55-12"><a href="#cb55-12" aria-hidden="true" tabindex="-1"></a><span class="co"># # Identify significant predictors</span></span>
<span id="cb55-13"><a href="#cb55-13" aria-hidden="true" tabindex="-1"></a><span class="co"># print("\nSignificance at 5% level:")</span></span>
<span id="cb55-14"><a href="#cb55-14" aria-hidden="true" tabindex="-1"></a><span class="co"># for var in model_full.params.index:</span></span>
<span id="cb55-15"><a href="#cb55-15" aria-hidden="true" tabindex="-1"></a><span class="co">#     p = model_full.pvalues[var]</span></span>
<span id="cb55-16"><a href="#cb55-16" aria-hidden="true" tabindex="-1"></a><span class="co">#     sig = "***" if p &lt; 0.01 else "**" if p &lt; 0.05 else "*" if p &lt; 0.10 else ""</span></span>
<span id="cb55-17"><a href="#cb55-17" aria-hidden="true" tabindex="-1"></a><span class="co">#     print(f"  {var:18s}  p = {p:.4f}  {sig}")</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="task-2-confidence-intervals-guided-1" class="level4">
<h4 class="anchored" data-anchor-id="task-2-confidence-intervals-guided-1">Task 2: Confidence Intervals (Guided)</h4>
<p>Compute 95% confidence intervals for all coefficients and create a coefficient plot (forest plot) to visualize the estimates and their uncertainty.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 95% confidence intervals</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>ci <span class="op">=</span> model_full.conf_int(alpha<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>ci.columns <span class="op">=</span> [<span class="st">'Lower 2.5%'</span>, <span class="st">'Upper 97.5%'</span>]</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>ci[<span class="st">'Estimate'</span>] <span class="op">=</span> model_full.params</span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ci[[<span class="st">'Estimate'</span>, <span class="st">'Lower 2.5%'</span>, <span class="st">'Upper 97.5%'</span>]].<span class="bu">round</span>(<span class="dv">4</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Questions:</strong></p>
<ul>
<li>Which confidence intervals include zero? What does this imply about significance?</li>
<li>Which coefficient has the widest confidence interval? The narrowest (excluding intercept)?</li>
<li>Create a forest plot showing point estimates and 95% CIs for the embedding coefficients</li>
<li>How do the confidence intervals for embeddings compare in width to the NTL coefficient?</li>
</ul>
<div id="cell-86" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Your code here: Confidence intervals and coefficient plot</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Steps:</span></span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Compute confidence intervals with model_full.conf_int()</span></span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Print the table of estimates and CIs</span></span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Create a coefficient plot (forest plot) for embedding variables</span></span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Identify which CIs include zero</span></span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Example structure:</span></span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a><span class="co"># ci = model_full.conf_int(alpha=0.05)</span></span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a><span class="co"># ci.columns = ['Lower', 'Upper']</span></span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a><span class="co"># ci['Estimate'] = model_full.params</span></span>
<span id="cb57-13"><a href="#cb57-13" aria-hidden="true" tabindex="-1"></a><span class="co"># print(ci[['Estimate', 'Lower', 'Upper']].round(4))</span></span>
<span id="cb57-14"><a href="#cb57-14" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb57-15"><a href="#cb57-15" aria-hidden="true" tabindex="-1"></a><span class="co"># # Forest plot for embedding coefficients</span></span>
<span id="cb57-16"><a href="#cb57-16" aria-hidden="true" tabindex="-1"></a><span class="co"># embed_vars = ['A00', 'A10', 'A20', 'A30', 'A40']</span></span>
<span id="cb57-17"><a href="#cb57-17" aria-hidden="true" tabindex="-1"></a><span class="co"># fig, ax = plt.subplots(figsize=(8, 5))</span></span>
<span id="cb57-18"><a href="#cb57-18" aria-hidden="true" tabindex="-1"></a><span class="co"># y_pos = range(len(embed_vars))</span></span>
<span id="cb57-19"><a href="#cb57-19" aria-hidden="true" tabindex="-1"></a><span class="co"># estimates = [model_full.params[v] for v in embed_vars]</span></span>
<span id="cb57-20"><a href="#cb57-20" aria-hidden="true" tabindex="-1"></a><span class="co"># errors = [(model_full.params[v] - ci.loc[v, 'Lower'],</span></span>
<span id="cb57-21"><a href="#cb57-21" aria-hidden="true" tabindex="-1"></a><span class="co">#            ci.loc[v, 'Upper'] - model_full.params[v]) for v in embed_vars]</span></span>
<span id="cb57-22"><a href="#cb57-22" aria-hidden="true" tabindex="-1"></a><span class="co"># errors_T = list(zip(*errors))</span></span>
<span id="cb57-23"><a href="#cb57-23" aria-hidden="true" tabindex="-1"></a><span class="co"># ax.errorbar(estimates, y_pos, xerr=errors_T, fmt='o', color='navy',</span></span>
<span id="cb57-24"><a href="#cb57-24" aria-hidden="true" tabindex="-1"></a><span class="co">#             capsize=5, markersize=8)</span></span>
<span id="cb57-25"><a href="#cb57-25" aria-hidden="true" tabindex="-1"></a><span class="co"># ax.axvline(x=0, color='red', linestyle='--', alpha=0.7, label='Zero (no effect)')</span></span>
<span id="cb57-26"><a href="#cb57-26" aria-hidden="true" tabindex="-1"></a><span class="co"># ax.set_yticks(y_pos)</span></span>
<span id="cb57-27"><a href="#cb57-27" aria-hidden="true" tabindex="-1"></a><span class="co"># ax.set_yticklabels(embed_vars)</span></span>
<span id="cb57-28"><a href="#cb57-28" aria-hidden="true" tabindex="-1"></a><span class="co"># ax.set_xlabel('Coefficient Estimate with 95% CI')</span></span>
<span id="cb57-29"><a href="#cb57-29" aria-hidden="true" tabindex="-1"></a><span class="co"># ax.set_title('Coefficient Plot: Satellite Embedding Effects on IMDS')</span></span>
<span id="cb57-30"><a href="#cb57-30" aria-hidden="true" tabindex="-1"></a><span class="co"># ax.legend()</span></span>
<span id="cb57-31"><a href="#cb57-31" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.tight_layout()</span></span>
<span id="cb57-32"><a href="#cb57-32" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.show()</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="task-3-individual-t-tests-semi-guided" class="level4">
<h4 class="anchored" data-anchor-id="task-3-individual-t-tests-semi-guided">Task 3: Individual t-Tests (Semi-guided)</h4>
<p>Examine the t-statistics and p-values for each satellite embedding coefficient individually.</p>
<p><strong>Your tasks:</strong></p>
<ol type="1">
<li>Extract and display the t-statistic and p-value for each embedding variable (<code>A00</code>-<code>A40</code>)</li>
<li>Classify each as significant at 5%, significant at 10%, or not significant</li>
<li>Count how many of the 5 embeddings are individually significant at each level</li>
<li>Discuss: If some embeddings are individually insignificant, can we conclude they are “useless”? Why or why not?</li>
</ol>
<p><strong>Hint:</strong> Individual insignificance may reflect multicollinearity among embeddings rather than lack of predictive power. The joint F-test in Task 4 will help resolve this.</p>
<div id="cell-88" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Your code here: Individual t-tests for embedding coefficients</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Steps:</span></span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Extract t-statistics and p-values for each embedding</span></span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Classify significance levels</span></span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Discuss the implications</span></span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Example structure:</span></span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a><span class="co"># print("Individual t-Tests for Satellite Embeddings")</span></span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a><span class="co"># print("=" * 60)</span></span>
<span id="cb58-11"><a href="#cb58-11" aria-hidden="true" tabindex="-1"></a><span class="co"># embed_vars = ['A00', 'A10', 'A20', 'A30', 'A40']</span></span>
<span id="cb58-12"><a href="#cb58-12" aria-hidden="true" tabindex="-1"></a><span class="co"># sig_5 = 0</span></span>
<span id="cb58-13"><a href="#cb58-13" aria-hidden="true" tabindex="-1"></a><span class="co"># sig_10 = 0</span></span>
<span id="cb58-14"><a href="#cb58-14" aria-hidden="true" tabindex="-1"></a><span class="co"># for var in embed_vars:</span></span>
<span id="cb58-15"><a href="#cb58-15" aria-hidden="true" tabindex="-1"></a><span class="co">#     t = model_full.tvalues[var]</span></span>
<span id="cb58-16"><a href="#cb58-16" aria-hidden="true" tabindex="-1"></a><span class="co">#     p = model_full.pvalues[var]</span></span>
<span id="cb58-17"><a href="#cb58-17" aria-hidden="true" tabindex="-1"></a><span class="co">#     if p &lt; 0.05:</span></span>
<span id="cb58-18"><a href="#cb58-18" aria-hidden="true" tabindex="-1"></a><span class="co">#         level = "Significant at 5%  ***"</span></span>
<span id="cb58-19"><a href="#cb58-19" aria-hidden="true" tabindex="-1"></a><span class="co">#         sig_5 += 1</span></span>
<span id="cb58-20"><a href="#cb58-20" aria-hidden="true" tabindex="-1"></a><span class="co">#         sig_10 += 1</span></span>
<span id="cb58-21"><a href="#cb58-21" aria-hidden="true" tabindex="-1"></a><span class="co">#     elif p &lt; 0.10:</span></span>
<span id="cb58-22"><a href="#cb58-22" aria-hidden="true" tabindex="-1"></a><span class="co">#         level = "Significant at 10% *"</span></span>
<span id="cb58-23"><a href="#cb58-23" aria-hidden="true" tabindex="-1"></a><span class="co">#         sig_10 += 1</span></span>
<span id="cb58-24"><a href="#cb58-24" aria-hidden="true" tabindex="-1"></a><span class="co">#     else:</span></span>
<span id="cb58-25"><a href="#cb58-25" aria-hidden="true" tabindex="-1"></a><span class="co">#         level = "Not significant"</span></span>
<span id="cb58-26"><a href="#cb58-26" aria-hidden="true" tabindex="-1"></a><span class="co">#     print(f"  {var}: t = {t:7.3f}, p = {p:.4f}  --&gt; {level}")</span></span>
<span id="cb58-27"><a href="#cb58-27" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"\nSignificant at 5%:  {sig_5}/5 embeddings")</span></span>
<span id="cb58-28"><a href="#cb58-28" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"Significant at 10%: {sig_10}/5 embeddings")</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="task-4-joint-f-test-semi-guided-1" class="level4">
<h4 class="anchored" data-anchor-id="task-4-joint-f-test-semi-guided-1">Task 4: Joint F-Test (Semi-guided)</h4>
<p>Test whether all five satellite embedding coefficients are jointly equal to zero.</p>
<p><span class="math display">\[H_0: \beta_{A00} = \beta_{A10} = \beta_{A20} = \beta_{A30} = \beta_{A40} = 0\]</span></p>
<p><strong>Your tasks:</strong></p>
<ol type="1">
<li>Construct a restriction matrix <span class="math inline">\(R\)</span> where each row sets one embedding coefficient to zero</li>
<li>Use <code>model_full.f_test()</code> with the restriction matrix to compute the joint F-statistic</li>
<li>Report the F-statistic, degrees of freedom, and p-value</li>
<li>Compare the joint test result with the individual t-test results from Task 3</li>
<li>Are embeddings <em>jointly</em> significant even if some are individually insignificant?</li>
</ol>
<p><strong>Hint:</strong> The restriction matrix has 5 rows (one per restriction) and 7 columns (one per coefficient including intercept). Each row has a 1 in the position of the embedding coefficient being tested and 0s elsewhere.</p>
<div id="cell-90" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Your code here: Joint F-test for all embedding coefficients</span></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Steps:</span></span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Construct the restriction matrix R</span></span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Perform the joint F-test with model_full.f_test(R)</span></span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Report F-statistic and p-value</span></span>
<span id="cb59-7"><a href="#cb59-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Compare with individual t-test results</span></span>
<span id="cb59-8"><a href="#cb59-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb59-9"><a href="#cb59-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Example structure:</span></span>
<span id="cb59-10"><a href="#cb59-10" aria-hidden="true" tabindex="-1"></a><span class="co"># import numpy as np</span></span>
<span id="cb59-11"><a href="#cb59-11" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb59-12"><a href="#cb59-12" aria-hidden="true" tabindex="-1"></a><span class="co"># # Restriction matrix: 5 restrictions (A00=A10=A20=A30=A40=0)</span></span>
<span id="cb59-13"><a href="#cb59-13" aria-hidden="true" tabindex="-1"></a><span class="co"># # Coefficients order: Intercept, ln_NTLpc2017, A00, A10, A20, A30, A40</span></span>
<span id="cb59-14"><a href="#cb59-14" aria-hidden="true" tabindex="-1"></a><span class="co"># R = np.zeros((5, 7))</span></span>
<span id="cb59-15"><a href="#cb59-15" aria-hidden="true" tabindex="-1"></a><span class="co"># R[0, 2] = 1  # A00 = 0</span></span>
<span id="cb59-16"><a href="#cb59-16" aria-hidden="true" tabindex="-1"></a><span class="co"># R[1, 3] = 1  # A10 = 0</span></span>
<span id="cb59-17"><a href="#cb59-17" aria-hidden="true" tabindex="-1"></a><span class="co"># R[2, 4] = 1  # A20 = 0</span></span>
<span id="cb59-18"><a href="#cb59-18" aria-hidden="true" tabindex="-1"></a><span class="co"># R[3, 5] = 1  # A30 = 0</span></span>
<span id="cb59-19"><a href="#cb59-19" aria-hidden="true" tabindex="-1"></a><span class="co"># R[4, 6] = 1  # A40 = 0</span></span>
<span id="cb59-20"><a href="#cb59-20" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb59-21"><a href="#cb59-21" aria-hidden="true" tabindex="-1"></a><span class="co"># f_test = model_full.f_test(R)</span></span>
<span id="cb59-22"><a href="#cb59-22" aria-hidden="true" tabindex="-1"></a><span class="co"># print("Joint F-Test: All Embedding Coefficients = 0")</span></span>
<span id="cb59-23"><a href="#cb59-23" aria-hidden="true" tabindex="-1"></a><span class="co"># print("=" * 50)</span></span>
<span id="cb59-24"><a href="#cb59-24" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"F-statistic: {f_test.fvalue[0][0]:.4f}")</span></span>
<span id="cb59-25"><a href="#cb59-25" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"p-value:     {f_test.pvalue:.6f}")</span></span>
<span id="cb59-26"><a href="#cb59-26" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"df:          ({int(f_test.df_num)}, {int(f_test.df_denom)})")</span></span>
<span id="cb59-27"><a href="#cb59-27" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"\nConclusion: {'Reject H0' if f_test.pvalue &lt; 0.05 else 'Fail to reject H0'} at 5% level")</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<blockquote class="blockquote">
<p><strong>Key Concept 11.12: Joint Significance of Satellite Features</strong></p>
<p>Individual satellite embedding coefficients may appear <strong>statistically insignificant</strong> (p &gt; 0.05) in a multiple regression, yet the group of embeddings may be <strong>jointly significant</strong> (F-test p &lt; 0.05). This paradox arises when embeddings are correlated with each other: the individual t-tests cannot distinguish each embedding’s unique contribution, but the F-test captures their collective explanatory power. Joint F-tests are essential when evaluating groups of related predictors.</p>
</blockquote>
</section>
<section id="task-5-restricted-vs-unrestricted-model-comparison-independent" class="level4">
<h4 class="anchored" data-anchor-id="task-5-restricted-vs-unrestricted-model-comparison-independent">Task 5: Restricted vs Unrestricted Model Comparison (Independent)</h4>
<p>Compare the restricted model (NTL only) with the unrestricted model (NTL + embeddings) to quantify the contribution of satellite embeddings.</p>
<p><strong>Your tasks:</strong></p>
<ol type="1">
<li>Estimate Model 1 (restricted): <code>imds ~ ln_NTLpc2017</code> (NTL only)</li>
<li>Estimate Model 2 (unrestricted): <code>imds ~ ln_NTLpc2017 + A00 + A10 + A20 + A30 + A40</code></li>
<li>Compute the F-statistic manually using the formula:</li>
</ol>
<p><span class="math display">\[F = \frac{(R^2_u - R^2_r) / q}{(1 - R^2_u) / (n - k - 1)}\]</span></p>
<p>where <span class="math inline">\(q = 5\)</span> (number of restrictions), <span class="math inline">\(n\)</span> = sample size, <span class="math inline">\(k\)</span> = number of regressors in unrestricted model</p>
<ol start="4" type="1">
<li>Compare your manual calculation with <code>model_full.compare_f_test(model_restricted)</code></li>
<li>Interpret: How much do the embeddings improve the model’s explanatory power?</li>
</ol>
<div id="cell-93" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Your code here: Restricted vs unrestricted model comparison</span></span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Steps:</span></span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Estimate restricted model (NTL only)</span></span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Compare R-squared values</span></span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Compute F-statistic manually</span></span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Verify with compare_f_test()</span></span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-9"><a href="#cb60-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Example structure:</span></span>
<span id="cb60-10"><a href="#cb60-10" aria-hidden="true" tabindex="-1"></a><span class="co"># # Restricted model: NTL only</span></span>
<span id="cb60-11"><a href="#cb60-11" aria-hidden="true" tabindex="-1"></a><span class="co"># model_restricted = ols('imds ~ ln_NTLpc2017', data=bol_cs).fit()</span></span>
<span id="cb60-12"><a href="#cb60-12" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb60-13"><a href="#cb60-13" aria-hidden="true" tabindex="-1"></a><span class="co"># # Compare R-squared</span></span>
<span id="cb60-14"><a href="#cb60-14" aria-hidden="true" tabindex="-1"></a><span class="co"># R2_r = model_restricted.rsquared</span></span>
<span id="cb60-15"><a href="#cb60-15" aria-hidden="true" tabindex="-1"></a><span class="co"># R2_u = model_full.rsquared</span></span>
<span id="cb60-16"><a href="#cb60-16" aria-hidden="true" tabindex="-1"></a><span class="co"># n = model_full.nobs</span></span>
<span id="cb60-17"><a href="#cb60-17" aria-hidden="true" tabindex="-1"></a><span class="co"># k = len(model_full.params) - 1  # number of regressors (excluding intercept)</span></span>
<span id="cb60-18"><a href="#cb60-18" aria-hidden="true" tabindex="-1"></a><span class="co"># q = 5  # number of restrictions (embedding coefficients)</span></span>
<span id="cb60-19"><a href="#cb60-19" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb60-20"><a href="#cb60-20" aria-hidden="true" tabindex="-1"></a><span class="co"># print("Model Comparison")</span></span>
<span id="cb60-21"><a href="#cb60-21" aria-hidden="true" tabindex="-1"></a><span class="co"># print("=" * 50)</span></span>
<span id="cb60-22"><a href="#cb60-22" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"Restricted (NTL only):      R² = {R2_r:.4f}")</span></span>
<span id="cb60-23"><a href="#cb60-23" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"Unrestricted (NTL + embed): R² = {R2_u:.4f}")</span></span>
<span id="cb60-24"><a href="#cb60-24" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"Improvement in R²:          ΔR² = {R2_u - R2_r:.4f}")</span></span>
<span id="cb60-25"><a href="#cb60-25" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb60-26"><a href="#cb60-26" aria-hidden="true" tabindex="-1"></a><span class="co"># # Manual F-statistic</span></span>
<span id="cb60-27"><a href="#cb60-27" aria-hidden="true" tabindex="-1"></a><span class="co"># F_manual = ((R2_u - R2_r) / q) / ((1 - R2_u) / (n - k - 1))</span></span>
<span id="cb60-28"><a href="#cb60-28" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"\nManual F-statistic: {F_manual:.4f}")</span></span>
<span id="cb60-29"><a href="#cb60-29" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb60-30"><a href="#cb60-30" aria-hidden="true" tabindex="-1"></a><span class="co"># # Verify with statsmodels</span></span>
<span id="cb60-31"><a href="#cb60-31" aria-hidden="true" tabindex="-1"></a><span class="co"># f_compare = model_full.compare_f_test(model_restricted)</span></span>
<span id="cb60-32"><a href="#cb60-32" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"compare_f_test:     F = {f_compare[0]:.4f}, p = {f_compare[1]:.6f}")</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="task-6-inference-brief-independent" class="level4">
<h4 class="anchored" data-anchor-id="task-6-inference-brief-independent">Task 6: Inference Brief (Independent)</h4>
<p>Write a 200-300 word inference brief summarizing your statistical findings.</p>
<p><strong>Your brief should address:</strong></p>
<ol type="1">
<li>Which satellite features add significant predictive power for municipal development?</li>
<li>Does the joint F-test tell a different story than the individual t-tests? Why?</li>
<li>How much do satellite embeddings improve explanatory power beyond nighttime lights alone?</li>
<li>What are the implications for feature selection in satellite-based prediction models?</li>
<li>How should researchers decide which satellite features to include in SDG prediction models?</li>
</ol>
<p><strong>Connection to methods:</strong> This analysis demonstrates a core tension in applied econometrics: individual insignificance vs.&nbsp;joint significance. When predictors are correlated (as satellite embeddings often are), individual t-tests may lack power while joint F-tests reveal collective importance.</p>
<div id="cell-95" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Your code here: Additional analysis for the inference brief</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a><span class="co"># You might want to:</span></span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Create a summary table comparing individual and joint test results</span></span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Visualize the R-squared improvement from adding embeddings</span></span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Calculate specific statistics to cite in your brief</span></span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Summary of key inference results</span></span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a><span class="co"># print("KEY INFERENCE RESULTS")</span></span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a><span class="co"># print("=" * 60)</span></span>
<span id="cb61-11"><a href="#cb61-11" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"Sample size: {int(model_full.nobs)} municipalities")</span></span>
<span id="cb61-12"><a href="#cb61-12" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"R² (NTL only):          {model_restricted.rsquared:.4f}")</span></span>
<span id="cb61-13"><a href="#cb61-13" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"R² (NTL + embeddings):  {model_full.rsquared:.4f}")</span></span>
<span id="cb61-14"><a href="#cb61-14" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"R² improvement:         {model_full.rsquared - model_restricted.rsquared:.4f}")</span></span>
<span id="cb61-15"><a href="#cb61-15" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"\nJoint F-test p-value:   {f_test.pvalue:.6f}")</span></span>
<span id="cb61-16"><a href="#cb61-16" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"Individually significant at 5%: {sig_5}/5 embeddings")</span></span>
<span id="cb61-17"><a href="#cb61-17" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"Individually significant at 10%: {sig_10}/5 embeddings")</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<blockquote class="blockquote">
<p><strong>Key Concept 11.13: Feature Selection in Prediction Models</strong></p>
<p>When many potential predictors are available (e.g., 64 satellite embedding dimensions), selecting which to include requires balancing <strong>explanatory power</strong> against <strong>model parsimony</strong>. Joint F-tests help determine whether <em>subsets</em> of features add genuine predictive value beyond what simpler models provide. In the DS4Bolivia context, testing whether 5 selected embeddings improve upon NTL alone informs practical decisions about data collection and model complexity for SDG monitoring.</p>
</blockquote>
</section>
<section id="what-youve-learned-from-this-case-study" class="level4">
<h4 class="anchored" data-anchor-id="what-youve-learned-from-this-case-study">What You’ve Learned from This Case Study</h4>
<p>Through this analysis of satellite features and municipal development in Bolivia, you applied Chapter 11’s full inference toolkit to a remote sensing application:</p>
<ul>
<li><strong>Full model estimation</strong>: Estimated a multiple regression with nighttime lights and satellite embeddings as predictors of development</li>
<li><strong>Confidence intervals</strong>: Constructed and visualized 95% CIs for all coefficients using a forest plot</li>
<li><strong>Individual t-tests</strong>: Assessed the statistical significance of each satellite embedding individually</li>
<li><strong>Joint F-tests</strong>: Tested whether all embeddings are jointly significant using restriction matrices</li>
<li><strong>Restricted vs unrestricted comparison</strong>: Computed F-statistics manually and verified with <code>compare_f_test()</code></li>
<li><strong>Inference interpretation</strong>: Distinguished between individual insignificance and joint significance</li>
</ul>
<p><strong>Connection to the next chapter</strong>: In Chapter 12, we address robust standard errors and prediction intervals—crucial for making reliable predictions about individual municipalities.</p>
<hr>
<p><strong>Well done!</strong> You’ve now applied the full statistical inference toolkit to two datasets—cross-country productivity and Bolivian satellite data—discovering that joint tests can reveal predictive power hidden from individual tests.</p>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../notebooks_colab/ch10_Data_Summary_for_Multiple_Regression.html" class="pagination-link" aria-label="Chapter 10: Data Summary for Multiple Regression">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">Chapter 10: Data Summary for Multiple Regression</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../notebooks_colab/ch12_Further_Topics_in_Multiple_Regression.html" class="pagination-link" aria-label="Chapter 12: Further Topics in Multiple Regression">
        <span class="nav-page-text"><span class="chapter-title">Chapter 12: Further Topics in Multiple Regression</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>