<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>12. Further Topics in Multiple Regression ‚Äì Econometrics Powered by AI</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../notebooks_colab/ch13_Case_Studies_for_Multiple_Regression.html" rel="next">
<link href="../notebooks_colab/ch11_Statistical_Inference_for_Multiple_Regression.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-8b4baf804e461d9b72633f0de59a0cac.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-0da87e08732b0aad79cc276a1be62fe2.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../custom.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../notebooks_colab/ch10_Data_Summary_for_Multiple_Regression.html">Multiple Regression</a></li><li class="breadcrumb-item"><a href="../notebooks_colab/ch12_Further_Topics_in_Multiple_Regression.html"><span class="chapter-title">12. Further Topics in Multiple Regression</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Econometrics Powered by AI</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch00_Preface.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Statistical Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch01_Analysis_of_Economics_Data.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">1. Analysis of Economics Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch02_Univariate_Data_Summary.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">2. Univariate Data Summary</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch03_The_Sample_Mean.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">3. The Sample Mean</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch04_Statistical_Inference_for_the_Mean.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">4. Statistical Inference for the Mean</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Bivariate Regression</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch05_Bivariate_Data_Summary.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">5. Bivariate Data Summary</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch06_The_Least_Squares_Estimator.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">6. The Least Squares Estimator</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch07_Statistical_Inference_for_Bivariate_Regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">7. Statistical Inference for Bivariate Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch08_Case_Studies_for_Bivariate_Regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">8. Case Studies for Bivariate Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch09_Models_with_Natural_Logarithms.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">9. Models with Natural Logarithms</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Multiple Regression</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch10_Data_Summary_for_Multiple_Regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">10. Data Summary for Multiple Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch11_Statistical_Inference_for_Multiple_Regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">11. Statistical Inference for Multiple Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch12_Further_Topics_in_Multiple_Regression.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">12. Further Topics in Multiple Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch13_Case_Studies_for_Multiple_Regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">13. Case Studies for Multiple Regression</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Advanced Topics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch14_Regression_with_Indicator_Variables.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">14. Regression with Indicator Variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch15_Regression_with_Transformed_Variables.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">15. Regression with Transformed Variables</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch16_Checking_the_Model_and_Data.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">16. Checking the Model and Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notebooks_colab/ch17_Panel_Data_Time_Series_Data_Causation.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">17. Panel Data, Time Series Data, Causation</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul class="collapse">
  <li><a href="#chapter-overview" id="toc-chapter-overview" class="nav-link active" data-scroll-target="#chapter-overview">Chapter Overview</a></li>
  <li><a href="#setup" id="toc-setup" class="nav-link" data-scroll-target="#setup">Setup</a></li>
  <li><a href="#example---house-price-prediction" id="toc-example---house-price-prediction" class="nav-link" data-scroll-target="#example---house-price-prediction">12.1: Example - House Price Prediction</a></li>
  <li><a href="#inference-with-robust-standard-errors" id="toc-inference-with-robust-standard-errors" class="nav-link" data-scroll-target="#inference-with-robust-standard-errors">12.2: Inference with Robust Standard Errors</a></li>
  <li><a href="#prediction" id="toc-prediction" class="nav-link" data-scroll-target="#prediction">12.3: Prediction</a></li>
  <li><a href="#nonrepresentative-samples" id="toc-nonrepresentative-samples" class="nav-link" data-scroll-target="#nonrepresentative-samples">12.4: Nonrepresentative Samples</a></li>
  <li><a href="#best-estimation-methods" id="toc-best-estimation-methods" class="nav-link" data-scroll-target="#best-estimation-methods">12.5: Best Estimation Methods</a></li>
  <li><a href="#best-confidence-intervals" id="toc-best-confidence-intervals" class="nav-link" data-scroll-target="#best-confidence-intervals">12.6: Best Confidence Intervals</a></li>
  <li><a href="#best-tests" id="toc-best-tests" class="nav-link" data-scroll-target="#best-tests">12.7: Best Tests</a></li>
  <li><a href="#key-takeaways" id="toc-key-takeaways" class="nav-link" data-scroll-target="#key-takeaways">Key Takeaways</a></li>
  <li><a href="#practice-exercises" id="toc-practice-exercises" class="nav-link" data-scroll-target="#practice-exercises">Practice Exercises</a></li>
  <li><a href="#case-studies" id="toc-case-studies" class="nav-link" data-scroll-target="#case-studies">Case Studies</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">
<div id="google_translate_element" style="padding: 8px 0;"></div>
<script type="text/javascript">
function googleTranslateElementInit() {
  new google.translate.TranslateElement({
    pageLanguage: 'en',
    layout: google.translate.TranslateElement.InlineLayout.HORIZONTAL
  }, 'google_translate_element');
}
</script>
<script type="text/javascript" src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script>

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../notebooks_colab/ch10_Data_Summary_for_Multiple_Regression.html">Multiple Regression</a></li><li class="breadcrumb-item"><a href="../notebooks_colab/ch12_Further_Topics_in_Multiple_Regression.html"><span class="chapter-title">12. Further Topics in Multiple Regression</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-title">12. Further Topics in Multiple Regression</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><strong>metricsAI: An Introduction to Econometrics with Python and AI in the Cloud</strong></p>
<p><em><a href="https://carlos-mendez.org">Carlos Mendez</a></em></p>
<p><img src="https://raw.githubusercontent.com/quarcs-lab/metricsai/main/images/ch12_visual_summary.jpg" alt="Chapter 12 Visual Summary" width="65%"></p>
<p>This notebook provides an interactive introduction to advanced topics in regression inference and prediction. All code runs directly in Google Colab without any local setup.</p>
<a href="https://colab.research.google.com/github/quarcs-lab/metricsai/blob/main/notebooks_colab/ch12_Further_Topics_in_Multiple_Regression.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" class="img-fluid" alt="Open In Colab"></a>
<div class="chapter-resources">
<p><a href="https://www.youtube.com/watch?v=0rM5db2lTPo" target="_blank" class="resource-btn">üé¨ AI Video</a> <a href="https://carlos-mendez.my.canva.site/s12-further-topics-in-multiple-regression-pdf" target="_blank" class="resource-btn">‚ú® AI Slides</a> <a href="https://cameron.econ.ucdavis.edu/aed/traedv1_12" target="_blank" class="resource-btn">üìä Cameron Slides</a> <a href="https://app.edcafe.ai/quizzes/6978693a2f5d08069e04bed3" target="_blank" class="resource-btn">‚úèÔ∏è Quiz</a> <a href="https://app.edcafe.ai/chatbots/6978a1a32f5d08069e0719da" target="_blank" class="resource-btn">ü§ñ AI Tutor</a></p>
</div>
<section id="chapter-overview" class="level2">
<h2 class="anchored" data-anchor-id="chapter-overview">Chapter Overview</h2>
<p>This chapter covers advanced topics that extend the multiple regression framework: robust standard errors for different data structures, prediction of outcomes, and deeper understanding of estimation and testing optimality.</p>
<p><strong>Learning Objectives:</strong></p>
<p>By the end of this chapter, you will be able to:</p>
<ol type="1">
<li>Understand when to use heteroskedastic-robust, cluster-robust, and HAC-robust standard errors</li>
<li>Distinguish between prediction of average outcomes and individual outcomes</li>
<li>Compute prediction intervals for conditional means and forecasts</li>
<li>Understand the impact of nonrepresentative samples on regression estimates</li>
<li>Recognize the difference between unbiased and best (most efficient) estimators</li>
<li>Understand Type I and Type II errors in hypothesis testing</li>
<li>Appreciate the role of bootstrap methods as an alternative to classical inference</li>
<li>Know when OLS with robust SEs is preferred over more efficient estimators like FGLS</li>
</ol>
<p><strong>Datasets used:</strong></p>
<ul>
<li><strong>AED_HOUSE.DTA</strong>: 29 houses sold in Davis, California (1999) ‚Äî for robust SEs and prediction</li>
<li><strong>AED_REALGDPPC.DTA</strong>: Real GDP per capita growth (241 observations) ‚Äî for HAC standard errors</li>
</ul>
<p><strong>Key economic questions:</strong></p>
<ul>
<li>Do conclusions about house prices change with robust standard errors?</li>
<li>How precisely can we predict an individual house‚Äôs price vs.&nbsp;the average price?</li>
<li>What happens to inference when our sample is not representative?</li>
</ul>
<p><strong>Chapter outline:</strong></p>
<ul>
<li>12.1 Example - House Price Prediction</li>
<li>12.2 Inference with Robust Standard Errors</li>
<li>12.3 Prediction</li>
<li>12.4 Nonrepresentative Samples</li>
<li>12.5 Best Estimation Methods</li>
<li>12.6 Best Confidence Intervals</li>
<li>12.7 Best Tests</li>
<li>Key Takeaways</li>
<li>Practice Exercises</li>
<li>Case Studies</li>
</ul>
<p><strong>Estimated time:</strong> 60-75 minutes</p>
</section>
<section id="setup" class="level2">
<h2 class="anchored" data-anchor-id="setup">Setup</h2>
<p>First, we import the necessary Python packages and configure the environment for reproducibility. All data will stream directly from GitHub.</p>
<div id="cell-3" class="cell" data-execution_count="1">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import required packages</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.formula.api <span class="im">import</span> ols</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.regression.linear_model <span class="im">import</span> OLS</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> stats</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.graphics.tsaplots <span class="im">import</span> plot_acf</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> statsmodels.tsa.stattools <span class="im">import</span> acf</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Set random seeds for reproducibility</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>RANDOM_SEED <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>random.seed(RANDOM_SEED)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>np.random.seed(RANDOM_SEED)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>os.environ[<span class="st">'PYTHONHASHSEED'</span>] <span class="op">=</span> <span class="bu">str</span>(RANDOM_SEED)</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co"># GitHub data URL</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>GITHUB_DATA_URL <span class="op">=</span> <span class="st">"https://raw.githubusercontent.com/quarcs-lab/data-open/master/AED/"</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Set plotting style</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>sns.set_style(<span class="st">"whitegrid"</span>)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>plt.rcParams[<span class="st">'figure.figsize'</span>] <span class="op">=</span> (<span class="dv">10</span>, <span class="dv">6</span>)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Setup complete! Ready to explore further topics in multiple regression."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>Setup complete! Ready to explore further topics in multiple regression.</code></pre>
</div>
</div>
</section>
<section id="example---house-price-prediction" class="level2">
<h2 class="anchored" data-anchor-id="example---house-price-prediction">12.1: Example - House Price Prediction</h2>
<p>We‚Äôll work with two datasets:</p>
<ol type="1">
<li><strong>House price data</strong> for cross-sectional robust inference</li>
<li><strong>GDP growth data</strong> for time series HAC inference</li>
</ol>
<div id="cell-5" class="cell" data-execution_count="2">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Read house data</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>data_house <span class="op">=</span> pd.read_stata(GITHUB_DATA_URL <span class="op">+</span> <span class="st">'AED_HOUSE.DTA'</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"House Data Summary:"</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data_house.describe())</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">First few observations:"</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data_house[[<span class="st">'price'</span>, <span class="st">'size'</span>, <span class="st">'bedrooms'</span>, <span class="st">'bathrooms'</span>, <span class="st">'lotsize'</span>, <span class="st">'age'</span>, <span class="st">'monthsold'</span>]].head())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>House Data Summary:
               price         size   bedrooms  bathrooms    lotsize        age  \
count      29.000000    29.000000  29.000000  29.000000  29.000000  29.000000   
mean   253910.344828  1882.758621   3.793103   2.206897   2.137931  36.413792   
std     37390.710695   398.272130   0.675030   0.341144   0.693034   7.118975   
min    204000.000000  1400.000000   3.000000   2.000000   1.000000  23.000000   
25%    233000.000000  1600.000000   3.000000   2.000000   2.000000  31.000000   
50%    244000.000000  1800.000000   4.000000   2.000000   2.000000  35.000000   
75%    270000.000000  2000.000000   4.000000   2.500000   3.000000  39.000000   
max    375000.000000  3300.000000   6.000000   3.000000   3.000000  51.000000   

       monthsold           list  
count  29.000000      29.000000  
mean    5.965517  257824.137931  
std     1.679344   40860.264099  
min     3.000000  199900.000000  
25%     5.000000  239000.000000  
50%     6.000000  245000.000000  
75%     7.000000  269000.000000  
max     8.000000  386000.000000  

First few observations:
    price  size  bedrooms  bathrooms  lotsize   age  monthsold
0  204000  1400         3        2.0        1  31.0          7
1  212000  1600         3        3.0        2  33.0          5
2  213000  1800         3        2.0        2  51.0          4
3  220000  1600         3        2.0        1  49.0          4
4  224500  2100         4        2.5        2  47.0          6</code></pre>
</div>
</div>
</section>
<section id="inference-with-robust-standard-errors" class="level2">
<h2 class="anchored" data-anchor-id="inference-with-robust-standard-errors">12.2: Inference with Robust Standard Errors</h2>
<p>In practice, the classical assumptions often fail. The most common violations are:</p>
<p><strong>1. Heteroskedasticity</strong>: Error variance varies across observations</p>
<ul>
<li>Common in cross-sectional data</li>
<li>Makes default standard errors incorrect</li>
<li>Solution: Use <strong>heteroskedasticity-robust standard errors</strong> (HC1, White‚Äôs correction)</li>
</ul>
<p><strong>2. Clustered errors</strong>: Errors correlated within groups</p>
<ul>
<li>Common in panel data, hierarchical data</li>
<li>Makes default and het-robust SEs too small</li>
<li>Solution: Use <strong>cluster-robust standard errors</strong></li>
</ul>
<p><strong>3. Autocorrelation</strong>: Errors correlated over time</p>
<ul>
<li>Common in time series</li>
<li>Makes default SEs incorrect</li>
<li>Solution: Use <strong>HAC (Newey-West) standard errors</strong></li>
</ul>
<p><strong>Key insight</strong>: OLS coefficients remain unbiased under these violations, but standard errors need adjustment.</p>
<p><strong>Heteroskedastic-robust standard error formula</strong>:</p>
<p><span class="math display">\[se_{het}(\hat{\beta}_j) = \sqrt{\frac{\sum_{i=1}^n \tilde{x}_{ji}^2 \hat{u}_i^2}{(\sum_{i=1}^n \tilde{x}_{ji}^2)^2}}\]</span></p>
<p>where <span class="math inline">\(\tilde{x}_{ji}\)</span> are residuals from regressing <span class="math inline">\(x_j\)</span> on other regressors, and <span class="math inline">\(\hat{u}_i\)</span> are OLS residuals.</p>
<div id="cell-7" class="cell" data-execution_count="3">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"12.2 INFERENCE WITH ROBUST STANDARD ERRORS"</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate with default standard errors</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>model_default <span class="op">=</span> ols(<span class="st">'price ~ size + bedrooms + bathrooms + lotsize + age + monthsold'</span>,</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>                    data<span class="op">=</span>data_house).fit()</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Regression with Default Standard Errors:"</span>)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model_default.summary())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>======================================================================
12.2 INFERENCE WITH ROBUST STANDARD ERRORS
======================================================================

Regression with Default Standard Errors:
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  price   R-squared:                       0.651
Model:                            OLS   Adj. R-squared:                  0.555
Method:                 Least Squares   F-statistic:                     6.826
Date:                Wed, 21 Jan 2026   Prob (F-statistic):           0.000342
Time:                        15:04:03   Log-Likelihood:                -330.74
No. Observations:                  29   AIC:                             675.5
Df Residuals:                      22   BIC:                             685.1
Df Model:                           6                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept   1.378e+05   6.15e+04      2.242      0.035    1.03e+04    2.65e+05
size          68.3694     15.389      4.443      0.000      36.454     100.285
bedrooms    2685.3151   9192.526      0.292      0.773   -1.64e+04    2.17e+04
bathrooms   6832.8800   1.57e+04      0.435      0.668   -2.58e+04    3.94e+04
lotsize     2303.2214   7226.535      0.319      0.753   -1.27e+04    1.73e+04
age         -833.0386    719.335     -1.158      0.259   -2324.847     658.770
monthsold  -2088.5036   3520.898     -0.593      0.559   -9390.399    5213.392
==============================================================================
Omnibus:                        1.317   Durbin-Watson:                   1.259
Prob(Omnibus):                  0.518   Jarque-Bera (JB):                0.980
Skew:                           0.151   Prob(JB):                        0.612
Kurtosis:                       2.152   Cond. No.                     2.59e+04
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 2.59e+04. This might indicate that there are
strong multicollinearity or other numerical problems.</code></pre>
</div>
</div>
<div id="cell-8" class="cell" data-execution_count="4">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate with heteroskedastic-robust standard errors (HC1)</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>model_robust <span class="op">=</span> ols(<span class="st">'price ~ size + bedrooms + bathrooms + lotsize + age + monthsold'</span>,</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>                   data<span class="op">=</span>data_house).fit(cov_type<span class="op">=</span><span class="st">'HC1'</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Regression with Heteroskedastic-Robust Standard Errors (HC1):"</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model_robust.summary())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Regression with Heteroskedastic-Robust Standard Errors (HC1):
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  price   R-squared:                       0.651
Model:                            OLS   Adj. R-squared:                  0.555
Method:                 Least Squares   F-statistic:                     6.410
Date:                Wed, 21 Jan 2026   Prob (F-statistic):           0.000514
Time:                        15:04:03   Log-Likelihood:                -330.74
No. Observations:                  29   AIC:                             675.5
Df Residuals:                      22   BIC:                             685.1
Df Model:                           6                                         
Covariance Type:                  HC1                                         
==============================================================================
                 coef    std err          z      P&gt;|z|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept   1.378e+05   6.55e+04      2.102      0.036    9324.785    2.66e+05
size          68.3694     15.359      4.451      0.000      38.266      98.473
bedrooms    2685.3151   8285.528      0.324      0.746   -1.36e+04    1.89e+04
bathrooms   6832.8800   1.93e+04      0.354      0.723    -3.1e+04    4.46e+04
lotsize     2303.2214   5328.860      0.432      0.666   -8141.152    1.27e+04
age         -833.0386    762.930     -1.092      0.275   -2328.353     662.276
monthsold  -2088.5036   3738.270     -0.559      0.576   -9415.379    5238.372
==============================================================================
Omnibus:                        1.317   Durbin-Watson:                   1.259
Prob(Omnibus):                  0.518   Jarque-Bera (JB):                0.980
Skew:                           0.151   Prob(JB):                        0.612
Kurtosis:                       2.152   Cond. No.                     2.59e+04
==============================================================================

Notes:
[1] Standard Errors are heteroscedasticity robust (HC1)
[2] The condition number is large, 2.59e+04. This might indicate that there are
strong multicollinearity or other numerical problems.</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p><strong>Key Concept 12.1: Heteroskedastic-Robust Standard Errors</strong></p>
<p>When error variance is not constant across observations, default OLS standard errors are invalid. Heteroskedastic-robust (HC1) SEs correct this problem without changing the coefficient estimates themselves. Only the standard errors, <span class="math inline">\(t\)</span>-statistics, and confidence intervals change. For cross-sectional data, reporting HC1 robust SEs is considered best practice.</p>
</blockquote>
<section id="comparison-default-vs.-robust-standard-errors" class="level3">
<h3 class="anchored" data-anchor-id="comparison-default-vs.-robust-standard-errors">Comparison: Default vs.&nbsp;Robust Standard Errors</h3>
<p>Let‚Äôs systematically compare the standard errors and see how inference changes.</p>
</section>
<section id="interpreting-the-comparison-what-changed" class="level3">
<h3 class="anchored" data-anchor-id="interpreting-the-comparison-what-changed">Interpreting the Comparison: What Changed?</h3>
<p><strong>Understanding the Results:</strong></p>
<p>Looking at the SE Ratio column, we can see how robust standard errors differ from default ones:</p>
<p><strong>When SE Ratio &gt; 1.0</strong>: Robust SE is larger than default SE</p>
<ul>
<li>Suggests heteroskedasticity is present</li>
<li>Default SEs were <strong>understating</strong> uncertainty</li>
<li>t-statistics decrease, p-values increase</li>
<li>We were <strong>too confident</strong> in rejecting null hypotheses</li>
</ul>
<p><strong>When SE Ratio ‚âà 1.0</strong>: Robust SE similar to default SE</p>
<ul>
<li>Little evidence of heteroskedasticity for this variable</li>
<li>Both methods give similar inference</li>
</ul>
<p><strong>When SE Ratio &lt; 1.0</strong>: Robust SE smaller than default SE</p>
<ul>
<li>Unusual but possible</li>
<li>Could indicate negative correlation between x¬≤ and residuals</li>
</ul>
<p><strong>Practical Implications:</strong></p>
<ol type="1">
<li><strong>Coefficient estimates unchanged</strong>: OLS point estimates are the same regardless of SE type</li>
<li><strong>Inference changes</strong>: Variables significant with default SEs might become insignificant with robust SEs</li>
<li><strong>Publication standard</strong>: Most journals now require robust SEs for cross-sectional data</li>
<li><strong>Conservative approach</strong>: When in doubt, report robust SEs (they‚Äôre generally more credible)</li>
</ol>
<p><strong>Rule of thumb</strong>: If robust SEs differ substantially (&gt;30% change), heteroskedasticity is likely present and you should use robust inference.</p>
</section>
<section id="hac-standard-errors-for-time-series" class="level3">
<h3 class="anchored" data-anchor-id="hac-standard-errors-for-time-series">HAC Standard Errors for Time Series</h3>
<p>Time series data often exhibit <strong>autocorrelation</strong>: current errors correlated with past errors.</p>
<p><strong>Example</strong>: GDP growth tends to persist</p>
<ul>
<li>Positive shock today ‚Üí likely positive next period</li>
<li>Creates correlation structure <span class="math inline">\(Corr(u_t, u_{t-s}) \neq 0\)</span></li>
</ul>
<p><strong>HAC (Newey-West) standard errors</strong>:</p>
<ul>
<li>Account for both heteroskedasticity AND autocorrelation</li>
<li>Require specifying maximum lag length <span class="math inline">\(m\)</span></li>
<li>Rule of thumb: <span class="math inline">\(m = 0.75 \times T^{1/3}\)</span></li>
</ul>
<p><strong>Autocorrelation function</strong>:</p>
<p><span class="math display">\[\rho_s = \frac{Cov(y_t, y_{t-s})}{\sqrt{Var(y_t) Var(y_{t-s})}}\]</span></p>
<p>We can visualize this with a <strong>correlogram</strong>.</p>
<div id="cell-13" class="cell" data-execution_count="5">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load GDP growth data</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>data_gdp <span class="op">=</span> pd.read_stata(GITHUB_DATA_URL <span class="op">+</span> <span class="st">'AED_REALGDPPC.DTA'</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"HAC Standard Errors for Time Series Data"</span>)</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">GDP Growth Data Summary:"</span>)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data_gdp[<span class="st">'growth'</span>].describe())</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Mean of growth</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>mean_growth <span class="op">=</span> data_gdp[<span class="st">'growth'</span>].mean()</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Mean growth rate: </span><span class="sc">{</span>mean_growth<span class="sc">:.6f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
======================================================================
HAC Standard Errors for Time Series Data
======================================================================

GDP Growth Data Summary:
count    241.000000
mean       1.990456
std        2.178097
min       -4.772172
25%        0.892417
50%        2.089633
75%        3.314238
max        7.630545
Name: growth, dtype: float64

Mean growth rate: 1.990456</code></pre>
</div>
</div>
<div id="cell-14" class="cell" data-execution_count="6">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Autocorrelation analysis</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Autocorrelations at multiple lags:"</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>acf_values <span class="op">=</span> acf(data_gdp[<span class="st">'growth'</span>], nlags<span class="op">=</span><span class="dv">5</span>, fft<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">6</span>):</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Lag </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>acf_values[i]<span class="sc">:.6f}</span><span class="ss">"</span>)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Interpretation:"</span>)</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  - Lag 0 correlation is always 1.0 (correlation with itself)"</span>)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  - Positive lag 1 correlation suggests persistence"</span>)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  - Autocorrelation decays with lag length"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Autocorrelations at multiple lags:
  Lag 0: nan
  Lag 1: nan
  Lag 2: nan
  Lag 3: nan
  Lag 4: nan
  Lag 5: nan

Interpretation:
  - Lag 0 correlation is always 1.0 (correlation with itself)
  - Positive lag 1 correlation suggests persistence
  - Autocorrelation decays with lag length</code></pre>
</div>
</div>
<div id="cell-15" class="cell" data-execution_count="7">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Correlogram</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>plot_acf(data_gdp[<span class="st">'growth'</span>], lags<span class="op">=</span><span class="dv">10</span>, ax<span class="op">=</span>ax, alpha<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">'Lag'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">'Autocorrelation'</span>, fontsize<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">'Figure 12.1: Correlogram of GDP Growth'</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The correlogram shows autocorrelation at various lags."</span>)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Blue shaded area = 95</span><span class="sc">% c</span><span class="st">onfidence bands under null of no autocorrelation."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ch12_Further_Topics_in_Multiple_Regression_files/figure-html/cell-8-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>The correlogram shows autocorrelation at various lags.
Blue shaded area = 95% confidence bands under null of no autocorrelation.</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p><strong>Key Concept 12.2: HAC Standard Errors for Time Series</strong></p>
<p>In time series data, errors are often autocorrelated ‚Äî today‚Äôs shock persists into tomorrow. HAC (heteroskedasticity and autocorrelation consistent) standard errors, also called Newey-West SEs, account for both heteroskedasticity and autocorrelation. The lag length <span class="math inline">\(m\)</span> must be specified; a common rule of thumb is <span class="math inline">\(m = 0.75 \times T^{1/3}\)</span>.</p>
</blockquote>
</section>
<section id="interpreting-hac-standard-errors" class="level3">
<h3 class="anchored" data-anchor-id="interpreting-hac-standard-errors">Interpreting HAC Standard Errors</h3>
<p><strong>What the Results Tell Us:</strong></p>
<p>Comparing the three standard error estimates for the mean growth rate:</p>
<ol type="1">
<li><strong>Default SE</strong> (assumes no autocorrelation):</li>
</ol>
<ul>
<li>Smallest standard error</li>
<li>Assumes errors are independent over time</li>
<li><strong>Underestimates</strong> uncertainty when autocorrelation exists</li>
</ul>
<ol start="2" type="1">
<li><strong>HAC with lag 0</strong> (het-robust only):</li>
</ol>
<ul>
<li>Accounts for heteroskedasticity but not autocorrelation</li>
<li>Often similar to default in time series</li>
<li>Still underestimates uncertainty if autocorrelation present</li>
</ul>
<ol start="3" type="1">
<li><strong>HAC with lag 5</strong> (Newey-West):</li>
</ol>
<ul>
<li>Accounts for both heteroskedasticity AND autocorrelation</li>
<li><strong>Larger SE</strong> reflects true uncertainty</li>
<li>More conservative but valid inference</li>
</ul>
<p><strong>Why is HAC SE larger?</strong></p>
<p>Autocorrelation creates <strong>information overlap</strong> between observations:</p>
<ul>
<li>If growth today predicts growth tomorrow, consecutive observations aren‚Äôt fully independent</li>
<li>We have <strong>less effective information</strong> than the sample size suggests</li>
<li>Standard errors must increase to reflect this</li>
</ul>
<p><strong>Practical guidance:</strong></p>
<ul>
<li>For time series data, <strong>always use HAC SEs</strong></li>
<li>Lag length choice: Rule of thumb = 0.75 √ó T^(1/3)</li>
<li>For T=100: m ‚âà 3-4 lags</li>
<li>For T=200: m ‚âà 4-5 lags</li>
<li>Err on the side of more lags (inference remains valid)</li>
<li>Check sensitivity to lag length</li>
</ul>
<p><strong>The cost of ignoring autocorrelation:</strong></p>
<ul>
<li>Overconfident inference (SEs too small)</li>
<li>Spurious significance (false discoveries)</li>
<li>Invalid hypothesis tests</li>
</ul>
<p>Having established how to conduct valid inference with robust standard errors, we now turn to prediction ‚Äî estimating outcomes for specific values.</p>
</section>
</section>
<section id="prediction" class="level2">
<h2 class="anchored" data-anchor-id="prediction">12.3: Prediction</h2>
<p>Prediction is a core application of regression, but there‚Äôs a crucial distinction:</p>
<p><strong>1. Predicting the conditional mean</strong> <span class="math inline">\(E[y | x^*]\)</span></p>
<ul>
<li>Average outcome for given <span class="math inline">\(x^*\)</span></li>
<li>More precise (smaller standard error)</li>
<li>Used for policy analysis, average effects</li>
</ul>
<p><strong>2. Predicting an actual value</strong> <span class="math inline">\(y | x^*\)</span></p>
<ul>
<li>Individual outcome including random error</li>
<li>Less precise (larger standard error)</li>
<li>Used for forecasting individual cases</li>
</ul>
<p><strong>Key formulas</strong>:</p>
<p>Conditional mean: <span class="math display">\[E[y | x^*] = \beta_1 + \beta_2 x_2^* + \cdots + \beta_k x_k^*\]</span></p>
<p>Actual value: <span class="math display">\[y | x^* = \beta_1 + \beta_2 x_2^* + \cdots + \beta_k x_k^* + u^*\]</span></p>
<p><strong>Standard errors</strong>:</p>
<p>For conditional mean (bivariate case): <span class="math display">\[se(\hat{y}_{cm}) = s_e \sqrt{\frac{1}{n} + \frac{(x^* - \bar{x})^2}{\sum(x_i - \bar{x})^2}}\]</span></p>
<p>For actual value (bivariate case): <span class="math display">\[se(\hat{y}_f) = s_e \sqrt{1 + \frac{1}{n} + \frac{(x^* - \bar{x})^2}{\sum(x_i - \bar{x})^2}}\]</span></p>
<p>Note the ‚Äú1 +‚Äù term for actual values - this reflects the irreducible uncertainty from <span class="math inline">\(u^*\)</span>.</p>
<div id="cell-20" class="cell" data-execution_count="8">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"12.3 PREDICTION"</span>)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple regression: price on size</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>model_simple <span class="op">=</span> ols(<span class="st">'price ~ size'</span>, data<span class="op">=</span>data_house).fit()</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Simple regression: price = Œ≤‚ÇÄ + Œ≤‚ÇÅ¬∑size + u"</span>)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Œ≤‚ÇÄ (Intercept): $</span><span class="sc">{</span>model_simple<span class="sc">.</span>params[<span class="st">'Intercept'</span>]<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Œ≤‚ÇÅ (Size): $</span><span class="sc">{</span>model_simple<span class="sc">.</span>params[<span class="st">'size'</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  R¬≤: </span><span class="sc">{</span>model_simple<span class="sc">.</span>rsquared<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Root MSE (œÉÃÇ): $</span><span class="sc">{</span>np<span class="sc">.</span>sqrt(model_simple.mse_resid)<span class="sc">:.2f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>======================================================================
12.3 PREDICTION
======================================================================

Simple regression: price = Œ≤‚ÇÄ + Œ≤‚ÇÅ¬∑size + u
  Œ≤‚ÇÄ (Intercept): $115017.28
  Œ≤‚ÇÅ (Size): $73.7710
  R¬≤: 0.6175
  Root MSE (œÉÃÇ): $23550.66</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p><strong>Key Concept 12.3: Predicting Conditional Means vs.&nbsp;Individual Outcomes</strong></p>
<p>Predicting the average outcome <span class="math inline">\(E[y|x^*]\)</span> is more precise than predicting an individual <span class="math inline">\(y|x^*\)</span>. The forecast variance equals the conditional mean variance plus <span class="math inline">\(\text{Var}(u^*)\)</span>: <span class="math inline">\(\text{Var}(\hat{y}_f) = \text{Var}(\hat{y}_{cm}) + \sigma^2\)</span>. As <span class="math inline">\(n \to \infty\)</span>, the conditional mean SE shrinks to zero, but the forecast SE remains at least <span class="math inline">\(s_e\)</span> ‚Äî a fundamental limit on individual predictions.</p>
</blockquote>
<section id="why-are-prediction-intervals-so-much-wider" class="level3">
<h3 class="anchored" data-anchor-id="why-are-prediction-intervals-so-much-wider">Why Are Prediction Intervals So Much Wider?</h3>
<p><strong>The Fundamental Difference:</strong></p>
<p>Looking at the two panels, you‚Äôll notice the <strong>prediction interval (blue) is dramatically wider</strong> than the confidence interval (red). This isn‚Äôt a mistake‚Äîit reflects a fundamental distinction in what we‚Äôre predicting.</p>
<p><strong>Confidence Interval for E[Y|X] (Red):</strong></p>
<ul>
<li>Predicts the <strong>average</strong> price for all 2000 sq ft houses</li>
<li>Uncertainty comes only from <strong>estimation error</strong> in Œ≤ÃÇ</li>
<li>As sample size increases (n ‚Üí ‚àû), this interval <strong>shrinks to zero</strong></li>
<li>Formula includes: 1/n term (goes to 0 as n grows)</li>
</ul>
<p><strong>Prediction Interval for Y (Blue):</strong></p>
<ul>
<li>Predicts an <strong>individual</strong> house price</li>
<li>Uncertainty comes from:</li>
</ul>
<ol type="1">
<li><strong>Estimation error</strong> in Œ≤ÃÇ (same as CI)</li>
<li><strong>Irreducible randomness</strong> in the individual outcome (u*)</li>
</ol>
<ul>
<li>Even with perfect knowledge of Œ≤, individual predictions remain uncertain</li>
<li>Formula includes: <strong>‚Äú1 +‚Äù</strong> term (never goes away)</li>
</ul>
<p><strong>Intuitive Example:</strong></p>
<p>Imagine predicting height from age:</p>
<ul>
<li><strong>Conditional mean</strong>: Average height of all 10-year-olds = 140 cm</li>
<li>We can estimate this average very precisely</li>
<li>CI might be [139, 141] cm</li>
<li><strong>Actual value</strong>: A specific 10-year-old‚Äôs height</li>
<li>Could be anywhere from 120 to 160 cm</li>
<li>PI might be [125, 155] cm</li>
<li>Even knowing the average perfectly doesn‚Äôt eliminate individual variation</li>
</ul>
<p><strong>Mathematical Insight:</strong></p>
<p><span class="math display">\[se(\hat{y}_f) = \sqrt{s_e^2 + se(\hat{y}_{cm})^2}\]</span></p>
<ul>
<li>First term (s_e¬≤): Irreducible error variance‚Äîdominates the formula</li>
<li>Second term: Estimation uncertainty‚Äîbecomes negligible with large samples</li>
<li>Result: PI width ‚âà 2 √ó 1.96 √ó s_e ‚âà 4 √ó RMSE</li>
</ul>
<p><strong>Practical Implications:</strong></p>
<ol type="1">
<li><strong>Don‚Äôt confuse the two</strong>: Predicting averages is much more precise than predicting individuals</li>
<li><strong>Policy vs.&nbsp;forecasting</strong>:</li>
</ol>
<ul>
<li>Policy analysis (average effects) ‚Üí Use confidence intervals</li>
<li>Individual forecasting (who will default?) ‚Üí Use prediction intervals</li>
</ul>
<ol start="3" type="1">
<li><strong>Communicating uncertainty</strong>: Always show prediction intervals for individual forecasts</li>
<li><strong>Limits of prediction</strong>: No amount of data eliminates individual-level uncertainty</li>
</ol>
</section>
<section id="visualization-confidence-vs.-prediction-intervals" class="level3">
<h3 class="anchored" data-anchor-id="visualization-confidence-vs.-prediction-intervals">Visualization: Confidence vs.&nbsp;Prediction Intervals</h3>
<p>This figure illustrates the fundamental difference between:</p>
<ul>
<li><strong>Confidence interval for conditional mean</strong> (narrower, red)</li>
<li><strong>Prediction interval for actual value</strong> (wider, blue)</li>
</ul>
</section>
<section id="understanding-the-numbers-a-concrete-example" class="level3">
<h3 class="anchored" data-anchor-id="understanding-the-numbers-a-concrete-example">Understanding the Numbers: A Concrete Example</h3>
<p><strong>Interpreting the Results for a 2000 sq ft House:</strong></p>
<p>Looking at our predictions, several patterns emerge:</p>
<p><strong>1. Point Prediction:</strong></p>
<ul>
<li>Predicted price ‚âà $280,000 (approximately)</li>
<li>This is our best single guess</li>
<li>Same for both conditional mean and actual value</li>
</ul>
<p><strong>2. Confidence Interval for E[Y|X=2000]:</strong></p>
<ul>
<li>Relatively narrow (e.g., $250k - $310k)</li>
<li>Tells us: ‚ÄúWe‚Äôre 95% confident the <strong>average price</strong> of all 2000 sq ft houses is in this range‚Äù</li>
<li>Precise because we‚Äôre estimating a population average</li>
<li>Useful for: Understanding market valuations, setting pricing policies</li>
</ul>
<p><strong>3. Prediction Interval for Y:</strong></p>
<ul>
<li>Much wider (e.g., $180k - $380k)</li>
<li>Tells us: ‚ÄúWe‚Äôre 95% confident <strong>this specific house</strong> will sell in this range‚Äù</li>
<li>Wide because individual houses vary considerably</li>
<li>Useful for: Setting listing ranges, individual appraisals</li>
</ul>
<p><strong>The Ratio is Revealing:</strong></p>
<p>Notice that the PI is approximately <strong>3-4 times wider</strong> than the CI. This ratio tells us:</p>
<ul>
<li>Most variation is <strong>between houses</strong> (individual heterogeneity)</li>
<li>Relatively little variation is <strong>estimation uncertainty</strong></li>
<li>Adding more data would shrink the CI but barely affect the PI</li>
</ul>
<p><strong>Statistical vs.&nbsp;Economic Significance:</strong></p>
<ul>
<li><strong>CI width</strong> = Statistical precision (how well we know Œ≤)</li>
<li><strong>PI width</strong> = Economic uncertainty (inherent market volatility)</li>
<li>In this example: Good statistical precision, but still substantial economic uncertainty</li>
</ul>
<p><strong>Practical Takeaway:</strong></p>
<p>If you‚Äôre a real estate agent:</p>
<ul>
<li>Don‚Äôt promise a precise price ($280k)</li>
<li>Do provide a realistic range ($180k - $380k)</li>
<li>Explain that individual houses vary, even controlling for size</li>
<li>Use the confidence interval to discuss average market values</li>
</ul>
</section>
<section id="deconstructing-the-standard-error-formulas" class="level3">
<h3 class="anchored" data-anchor-id="deconstructing-the-standard-error-formulas">Deconstructing the Standard Error Formulas</h3>
<p><strong>Understanding Where the ‚Äú1 +‚Äù Comes From:</strong></p>
<p>The manual calculations reveal the mathematical structure of prediction uncertainty:</p>
<p><strong>For Conditional Mean:</strong> <span class="math display">\[se(\hat{y}_{cm}) = \hat{\sigma} \sqrt{\frac{1}{n} + \frac{(x^* - \bar{x})^2}{\sum(x_i - \bar{x})^2}}\]</span></p>
<ul>
<li><strong>First term (1/n)</strong>: Decreases with sample size‚Äîmore data reduces uncertainty</li>
<li><strong>Second term</strong>: Distance from mean matters‚Äîextrapolation is risky</li>
<li>Prediction at <span class="math inline">\(x^* = \bar{x}\)</span> (sample mean) is most precise</li>
<li>Prediction far from <span class="math inline">\(\bar{x}\)</span> is less precise</li>
<li>Both terms ‚Üí 0 as n ‚Üí ‚àû (perfect knowledge of E[Y|X])</li>
</ul>
<p><strong>For Actual Value:</strong> <span class="math display">\[se(\hat{y}_f) = \hat{\sigma} \sqrt{1 + \frac{1}{n} + \frac{(x^* - \bar{x})^2}{\sum(x_i - \bar{x})^2}}\]</span></p>
<ul>
<li><strong>The critical ‚Äú1 +‚Äù</strong>: Represents <span class="math inline">\(Var[u^*]\)</span>, the future error term</li>
<li>This term <strong>never disappears</strong>, even with infinite data</li>
<li>Dominates the formula in moderate to large samples</li>
</ul>
<p><strong>Numerical Insight:</strong></p>
<p>In our example:</p>
<ul>
<li><span class="math inline">\(\hat{\sigma}\)</span> (RMSE) ‚âà $90k (this is the irreducible uncertainty)</li>
<li><span class="math inline">\((1/n)\)</span> term ‚âà 0.034 (small with n=29)</li>
<li>Distance term varies with prediction point</li>
</ul>
<p>For predictions near the mean:</p>
<ul>
<li><span class="math inline">\(se(\hat{y}_{cm})\)</span> ‚âà $90k √ó ‚àö0.034 ‚âà $17k (mainly from 1/n)</li>
<li><span class="math inline">\(se(\hat{y}_f)\)</span> ‚âà $90k √ó ‚àö1.034 ‚âà $92k (mainly from the ‚Äú1‚Äù)</li>
</ul>
<p><strong>The ‚Äú1 +‚Äù term is why:</strong></p>
<ul>
<li>Prediction intervals don‚Äôt shrink much with more data</li>
<li>Individual predictions remain uncertain even with perfect models</li>
<li><span class="math inline">\(se(\hat{y}_f) \approx \hat{\sigma}\)</span> in large samples</li>
</ul>
<p><strong>Geometric Interpretation:</strong></p>
<p>The funnel shape in prediction plots comes from the distance term:</p>
<ul>
<li>Narrow near <span class="math inline">\(\bar{x}\)</span> (center of data)</li>
<li>Wider at extremes (extrapolation region)</li>
<li>But even at the center, PI is wide due to the ‚Äú1‚Äù term</li>
</ul>
<p><strong>Practical Lesson:</strong></p>
<p>When presenting predictions:</p>
<ol type="1">
<li>Always acknowledge the ‚Äú1 +‚Äù uncertainty</li>
<li>Be most confident about predictions near the data center</li>
<li>Be especially cautious about extrapolation (predictions outside the data range)</li>
<li>Understand that better models reduce estimation error but not irreducible randomness</li>
</ol>
</section>
<section id="prediction-at-specific-values" class="level3">
<h3 class="anchored" data-anchor-id="prediction-at-specific-values">Prediction at Specific Values</h3>
<p>Let‚Äôs predict house price for a 2000 square foot house.</p>
</section>
<section id="manual-calculation-of-standard-errors" class="level3">
<h3 class="anchored" data-anchor-id="manual-calculation-of-standard-errors">Manual Calculation of Standard Errors</h3>
<p>Let‚Äôs manually calculate the standard errors to understand the formulas.</p>
</section>
<section id="prediction-with-multiple-regression" class="level3">
<h3 class="anchored" data-anchor-id="prediction-with-multiple-regression">Prediction with Multiple Regression</h3>
<p>Now let‚Äôs predict using the full multiple regression model.</p>
<div id="cell-29" class="cell" data-execution_count="9">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Prediction for Multiple Regression"</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>model_multi <span class="op">=</span> ols(<span class="st">'price ~ size + bedrooms + bathrooms + lotsize + age + monthsold'</span>,</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>                  data<span class="op">=</span>data_house).fit()</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict for specific values</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>new_house <span class="op">=</span> pd.DataFrame({</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'size'</span>: [<span class="dv">2000</span>],</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'bedrooms'</span>: [<span class="dv">4</span>],</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'bathrooms'</span>: [<span class="dv">2</span>],</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">'lotsize'</span>: [<span class="dv">2</span>],</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">'age'</span>: [<span class="dv">40</span>],</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">'monthsold'</span>: [<span class="dv">6</span>]</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>pred_multi <span class="op">=</span> model_multi.get_prediction(sm.add_constant(new_house))</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Prediction for:"</span>)</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  size=2000, bedrooms=4, bathrooms=2, lotsize=2, age=40, monthsold=6"</span>)</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Predicted price: $</span><span class="sc">{</span>pred_multi<span class="sc">.</span>predicted_mean[<span class="dv">0</span>]<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Confidence interval for conditional mean</span></span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>ci_mean_multi <span class="op">=</span> pred_multi.conf_int(alpha<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">95% CI for E[Y|X]:"</span>)</span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  [$</span><span class="sc">{</span>ci_mean_multi[<span class="dv">0</span>, <span class="dv">0</span>]<span class="sc">:.2f}</span><span class="ss">, $</span><span class="sc">{</span>ci_mean_multi[<span class="dv">0</span>, <span class="dv">1</span>]<span class="sc">:.2f}</span><span class="ss">]"</span>)</span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  SE: $</span><span class="sc">{</span>pred_multi<span class="sc">.</span>se_mean[<span class="dv">0</span>]<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Prediction interval for actual value</span></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>s_e_multi <span class="op">=</span> np.sqrt(model_multi.mse_resid)</span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>s_y_cm_multi <span class="op">=</span> pred_multi.se_mean[<span class="dv">0</span>]</span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>s_y_f_multi <span class="op">=</span> np.sqrt(s_e_multi<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> s_y_cm_multi<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a>n_multi <span class="op">=</span> <span class="bu">len</span>(data_house)</span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a>k_multi <span class="op">=</span> <span class="bu">len</span>(model_multi.params)</span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a>tcrit_multi <span class="op">=</span> stats.t.ppf(<span class="fl">0.975</span>, n_multi <span class="op">-</span> k_multi)</span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a>pi_lower <span class="op">=</span> pred_multi.predicted_mean[<span class="dv">0</span>] <span class="op">-</span> tcrit_multi <span class="op">*</span> s_y_f_multi</span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a>pi_upper <span class="op">=</span> pred_multi.predicted_mean[<span class="dv">0</span>] <span class="op">+</span> tcrit_multi <span class="op">*</span> s_y_f_multi</span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">95% PI for Y:"</span>)</span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  [$</span><span class="sc">{</span>pi_lower<span class="sc">:.2f}</span><span class="ss">, $</span><span class="sc">{</span>pi_upper<span class="sc">:.2f}</span><span class="ss">]"</span>)</span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  SE: $</span><span class="sc">{</span>s_y_f_multi<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-46"><a href="#cb17-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Multiple regression provides more precise conditional mean predictions."</span>)</span>
<span id="cb17-47"><a href="#cb17-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"But individual predictions still have large uncertainty."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
======================================================================
Prediction for Multiple Regression
======================================================================

Prediction for:
  size=2000, bedrooms=4, bathrooms=2, lotsize=2, age=40, monthsold=6

Predicted price: $257690.80

95% CI for E[Y|X]:
  [$244234.97, $271146.63]
  SE: $6488.26

95% PI for Y:
  [$204255.32, $311126.28]
  SE: $25766.03

Multiple regression provides more precise conditional mean predictions.
But individual predictions still have large uncertainty.</code></pre>
</div>
</div>
</section>
<section id="prediction-with-robust-standard-errors" class="level3">
<h3 class="anchored" data-anchor-id="prediction-with-robust-standard-errors">Prediction with Robust Standard Errors</h3>
<p>When heteroskedasticity is present, we should use robust standard errors for prediction intervals too.</p>
<div id="cell-31" class="cell" data-execution_count="10">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Prediction with Heteroskedastic-Robust SEs"</span>)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>model_multi_robust <span class="op">=</span> ols(<span class="st">'price ~ size + bedrooms + bathrooms + lotsize + age + monthsold'</span>,</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>                         data<span class="op">=</span>data_house).fit(cov_type<span class="op">=</span><span class="st">'HC1'</span>)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>pred_multi_robust <span class="op">=</span> model_multi_robust.get_prediction(sm.add_constant(new_house))</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Predicted price: $</span><span class="sc">{</span>pred_multi_robust<span class="sc">.</span>predicted_mean[<span class="dv">0</span>]<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Robust confidence interval for conditional mean</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>ci_mean_robust <span class="op">=</span> pred_multi_robust.conf_int(alpha<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Robust 95% CI for E[Y|X]:"</span>)</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  [$</span><span class="sc">{</span>ci_mean_robust[<span class="dv">0</span>, <span class="dv">0</span>]<span class="sc">:.2f}</span><span class="ss">, $</span><span class="sc">{</span>ci_mean_robust[<span class="dv">0</span>, <span class="dv">1</span>]<span class="sc">:.2f}</span><span class="ss">]"</span>)</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Robust SE: $</span><span class="sc">{</span>pred_multi_robust<span class="sc">.</span>se_mean[<span class="dv">0</span>]<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Robust prediction interval</span></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>s_y_cm_robust <span class="op">=</span> pred_multi_robust.se_mean[<span class="dv">0</span>]</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>s_y_f_robust <span class="op">=</span> np.sqrt(s_e_multi<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> s_y_cm_robust<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Robust 95% PI for Y:"</span>)</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Robust SE for actual value: $</span><span class="sc">{</span>s_y_f_robust<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Comparison of standard vs. robust:"</span>)</span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  SE (standard): $</span><span class="sc">{</span>s_y_cm_multi<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  SE (robust): $</span><span class="sc">{</span>s_y_cm_robust<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Ratio: </span><span class="sc">{</span>s_y_cm_robust <span class="op">/</span> s_y_cm_multi<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
======================================================================
Prediction with Heteroskedastic-Robust SEs
======================================================================

Predicted price: $257690.80

Robust 95% CI for E[Y|X]:
  [$244694.26, $270687.34]
  Robust SE: $6631.01

Robust 95% PI for Y:
  Robust SE for actual value: $25802.35

Comparison of standard vs. robust:
  SE (standard): $6488.26
  SE (robust): $6631.01
  Ratio: 1.022</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p><strong>Key Concept 12.4: Why Individual Forecasts Are Imprecise</strong></p>
<p>Even with precisely estimated coefficients, predicting an individual outcome is imprecise because the forecast must account for the unobservable error <span class="math inline">\(u^*\)</span>. The forecast standard error satisfies <span class="math inline">\(se(\hat{y}_f) \geq s_e\)</span> ‚Äî it is at least as large as the regression‚Äôs standard error. This means 95% prediction intervals are at least <span class="math inline">\(\pm 1.96 \times s_e\)</span> wide, regardless of how much data we have.</p>
</blockquote>
</section>
</section>
<section id="nonrepresentative-samples" class="level2">
<h2 class="anchored" data-anchor-id="nonrepresentative-samples">12.4: Nonrepresentative Samples</h2>
<p><strong>Sample selection</strong> can bias OLS estimates:</p>
<p><strong>Case 1: Selection on regressors</strong> (X)</p>
<ul>
<li>Example: Oversample high-income households</li>
<li>OLS remains unbiased if we include income as a control</li>
<li>Solution: Include selection variables as controls</li>
</ul>
<p><strong>Case 2: Selection on outcome</strong> (Y)</p>
<ul>
<li>Example: Survey excludes very high earners</li>
<li>OLS estimates are biased for population parameters</li>
<li>Solution: Sample weights, Heckman correction, or other selection models</li>
</ul>
<p><strong>Survey weights</strong>:</p>
<ul>
<li>Many surveys provide weights to adjust for nonrepresentativeness</li>
<li>Use <strong>weighted least squares (WLS)</strong> instead of OLS</li>
<li>Weight formula: <span class="math inline">\(w_i = 1 / P(\text{selected})\)</span></li>
</ul>
<p><strong>Key insight</strong>: Always check whether your sample is representative of your target population!</p>
<section id="bootstrap-confidence-intervals-an-alternative-approach" class="level3">
<h3 class="anchored" data-anchor-id="bootstrap-confidence-intervals-an-alternative-approach">Bootstrap Confidence Intervals: An Alternative Approach</h3>
<p><strong>What is Bootstrap?</strong></p>
<p>The bootstrap is a computational method that:</p>
<ol type="1">
<li><strong>Resamples</strong> your data many times (e.g., 1000 replications)</li>
<li><strong>Re-estimates</strong> the model for each resample</li>
<li>Uses the <strong>distribution of estimates</strong> to build confidence intervals</li>
</ol>
<p><strong>How it works:</strong></p>
<p>For each bootstrap replication b = 1, ‚Ä¶, B:</p>
<ol type="1">
<li>Draw n observations <strong>with replacement</strong> from original data</li>
<li>Estimate regression: <span class="math inline">\(\hat{\beta}_j^{(b)}\)</span></li>
<li>Store the coefficient estimate</li>
</ol>
<p>After B replications:</p>
<ul>
<li>You have B estimates: <span class="math inline">\(\{\hat{\beta}_j^{(1)}, \hat{\beta}_j^{(2)}, ..., \hat{\beta}_j^{(B)}\}\)</span></li>
<li>These form an empirical distribution</li>
</ul>
<p><strong>Percentile Method CI:</strong></p>
<ul>
<li>95% CI = [2.5th percentile, 97.5th percentile] of bootstrap distribution</li>
<li>Example: If you have 1000 estimates, use the 25th and 975th largest values</li>
</ul>
<p><strong>Advantages of Bootstrap:</strong></p>
<ol type="1">
<li><strong>No distributional assumptions</strong>: Don‚Äôt need to assume normality</li>
<li><strong>Works for complex statistics</strong>: Medians, ratios, quantiles, etc.</li>
<li><strong>Better small-sample coverage</strong>: Often more accurate than asymptotic formulas</li>
<li><strong>Flexibility</strong>: Can bootstrap residuals, observations, or both</li>
<li><strong>Visual understanding</strong>: See the actual sampling distribution</li>
</ol>
<p><strong>When to use Bootstrap:</strong></p>
<ul>
<li>Small samples (n &lt; 30-50)</li>
<li>Non-standard statistics (beyond means and coefficients)</li>
<li>Skewed or heavy-tailed distributions</li>
<li>Checking robustness of standard inference</li>
<li>When asymptotic formulas are complex or unavailable</li>
</ul>
<p><strong>Limitations:</strong></p>
<ul>
<li>Computationally intensive (need B = 1000+ replications)</li>
<li>Requires careful implementation (stratification, cluster bootstrap)</li>
<li>May fail with very small samples (n &lt; 10)</li>
<li>Assumes sample is representative of population</li>
</ul>
<p><strong>Bootstrap vs.&nbsp;Robust SEs:</strong></p>
<p>Both address uncertainty, but differently:</p>
<ul>
<li><strong>Robust SEs</strong>: Analytical correction for heteroskedasticity/autocorrelation</li>
<li><strong>Bootstrap</strong>: Computational approach using resampling</li>
</ul>
<p>Often used together: Bootstrap with robust methods!</p>
<p><strong>Practical Implementation Tips:</strong></p>
<ol type="1">
<li>Use B ‚â• 1000 for confidence intervals</li>
<li>Set random seed for reproducibility</li>
<li>For time series: Use block bootstrap (resample blocks, not individuals)</li>
<li>For panel data: Use cluster bootstrap (resample clusters)</li>
<li>Check convergence: Results shouldn‚Äôt change much with different seeds</li>
</ol>
<div id="cell-35" class="cell" data-execution_count="11">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"12.4 NONREPRESENTATIVE SAMPLES"</span>)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Conceptual discussion - no computation required"</span>)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Key points:"</span>)</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  1. Sample selection can lead to biased estimates"</span>)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  2. Selection on regressors: Include selection variables as controls"</span>)</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  3. Selection on outcome: Use sample weights or selection models"</span>)</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  4. Always verify sample representativeness"</span>)</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Example applications:"</span>)</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  - Wage surveys that exclude unemployed workers"</span>)</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  - Health studies with voluntary participation"</span>)</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  - Education data from selective schools"</span>)</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"  - Financial data excluding bankrupt firms"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>======================================================================
12.4 NONREPRESENTATIVE SAMPLES
======================================================================

Conceptual discussion - no computation required

Key points:
  1. Sample selection can lead to biased estimates
  2. Selection on regressors: Include selection variables as controls
  3. Selection on outcome: Use sample weights or selection models
  4. Always verify sample representativeness

Example applications:
  - Wage surveys that exclude unemployed workers
  - Health studies with voluntary participation
  - Education data from selective schools
  - Financial data excluding bankrupt firms</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p><strong>Key Concept 12.5: Sample Selection Bias</strong></p>
<p>If the sample is not representative of the population, OLS estimates may be biased. Selection on the dependent variable <span class="math inline">\(Y\)</span> (e.g., studying only high earners) is particularly problematic. Selection on the regressors <span class="math inline">\(X\)</span> (e.g., studying only college graduates) is less harmful because it reduces precision but doesn‚Äôt necessarily bias coefficient estimates.</p>
</blockquote>
</section>
<section id="the-type-i-vs.-type-ii-error-tradeoff" class="level3">
<h3 class="anchored" data-anchor-id="the-type-i-vs.-type-ii-error-tradeoff">The Type I vs.&nbsp;Type II Error Tradeoff</h3>
<p><strong>Understanding the Table:</strong></p>
<p>The 2√ó2 decision table reveals a fundamental tradeoff in hypothesis testing:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Decision</th>
<th>H‚ÇÄ True</th>
<th>H‚ÇÄ False</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Reject H‚ÇÄ</td>
<td><strong>Type I error (Œ±)</strong></td>
<td><strong>Correct (Power)</strong></td>
</tr>
<tr class="even">
<td>Don‚Äôt reject</td>
<td>Correct (1-Œ±)</td>
<td><strong>Type II error (Œ≤)</strong></td>
</tr>
</tbody>
</table>
<p><strong>Type I Error (False Positive):</strong></p>
<ul>
<li>Reject a true null hypothesis</li>
<li>Probability = significance level Œ± (we control this)</li>
<li>Example: Conclude a drug works when it doesn‚Äôt</li>
<li><strong>‚ÄúSeeing patterns in noise‚Äù</strong></li>
</ul>
<p><strong>Type II Error (False Negative):</strong></p>
<ul>
<li>Fail to reject a false null hypothesis</li>
<li>Probability = Œ≤ (harder to control)</li>
<li>Example: Miss a real drug effect</li>
<li><strong>‚ÄúMissing real signals‚Äù</strong></li>
</ul>
<p><strong>The Fundamental Tradeoff:</strong></p>
<p>If we make the test <strong>stricter</strong> (lower Œ±):</p>
<ul>
<li>Fewer false positives (Type I errors)</li>
<li>More false negatives (Type II errors)</li>
<li>Lower power (harder to detect real effects)</li>
</ul>
<p>If we make the test <strong>looser</strong> (higher Œ±):</p>
<ul>
<li>Higher power (easier to detect real effects)</li>
<li>More false positives (Type I errors)</li>
</ul>
<p><strong>Statistical Power = 1 - Œ≤:</strong></p>
<ul>
<li>Probability of correctly rejecting false H‚ÇÄ</li>
<li>‚ÄúSensitivity‚Äù of the test</li>
<li>Want power ‚â• 0.80 (80% chance of detecting real effect)</li>
</ul>
<p><strong>What Affects Power?</strong></p>
<ol type="1">
<li><strong>Sample size (n)</strong>: Larger n ‚Üí Higher power</li>
<li><strong>Effect size (Œ≤)</strong>: Larger true effect ‚Üí Higher power</li>
<li><strong>Significance level (Œ±)</strong>: Higher Œ± ‚Üí Higher power (but more Type I errors)</li>
<li><strong>Noise level (œÉ)</strong>: Lower œÉ ‚Üí Higher power</li>
</ol>
<p><strong>The Power Function:</strong></p>
<p>Power depends on the <strong>true parameter value</strong>:</p>
<ul>
<li>At Œ≤ = 0 (H‚ÇÄ true): Power = Œ± (just Type I error rate)</li>
<li>As |Œ≤| increases: Power increases</li>
<li>For very large |Œ≤|: Power ‚Üí 1 (almost certain detection)</li>
</ul>
<p><strong>Multiple Testing Problem:</strong></p>
<p>Testing k hypotheses at Œ± = 0.05:</p>
<ul>
<li>Expected false positives = 0.05 √ó k</li>
<li>Test 20 hypotheses ‚Üí expect 1 false positive even if all H‚ÇÄ are true!</li>
</ul>
<p><strong>Solutions:</strong></p>
<ol type="1">
<li><strong>Bonferroni correction</strong>: Use Œ±/k for each test (conservative)</li>
<li><strong>False Discovery Rate (FDR)</strong>: Control proportion of false positives</li>
<li><strong>Pre-registration</strong>: Specify primary hypotheses before seeing data</li>
<li><strong>Replication</strong>: Confirm findings in independent samples</li>
</ol>
<p>Now that we understand how sample selection affects estimates, let‚Äôs consider what happens when we seek the most efficient estimator.</p>
</section>
</section>
<section id="best-estimation-methods" class="level2">
<h2 class="anchored" data-anchor-id="best-estimation-methods">12.5: Best Estimation Methods</h2>
<p><strong>When are OLS estimators ‚Äúbest‚Äù?</strong></p>
<p>Under classical assumptions 1-4, OLS is <strong>BLUE</strong> (Best Linear Unbiased Estimator) by the Gauss-Markov Theorem.</p>
<p><strong>When assumptions fail:</strong></p>
<p><strong>1. Heteroskedasticity</strong>: <span class="math inline">\(Var[u_i | X] = \sigma_i^2\)</span> (varies)</p>
<ul>
<li>OLS remains unbiased but inefficient</li>
<li><strong>Feasible GLS (FGLS)</strong> or <strong>Weighted Least Squares (WLS)</strong> more efficient</li>
<li>Weight observations inversely to error variance: <span class="math inline">\(w_i = 1/\sigma_i\)</span></li>
</ul>
<p><strong>2. Autocorrelation</strong>: <span class="math inline">\(Cov[u_t, u_{t-s}] \neq 0\)</span></p>
<ul>
<li>OLS remains unbiased but inefficient</li>
<li><strong>FGLS with AR errors</strong> more efficient</li>
<li>Model error structure: <span class="math inline">\(u_t = \rho u_{t-1} + \epsilon_t\)</span></li>
</ul>
<p><strong>Practical advice</strong>:</p>
<ul>
<li>Most applied work uses OLS with robust SEs</li>
<li>Efficiency gains from GLS/FGLS often modest</li>
<li>Misspecifying error structure can make things worse</li>
<li>Exception: Panel data methods explicitly model error components</li>
</ul>
<section id="reading-the-power-curve-what-it-tells-us" class="level3">
<h3 class="anchored" data-anchor-id="reading-the-power-curve-what-it-tells-us">Reading the Power Curve: What It Tells Us</h3>
<p><strong>Interpreting Figure 12.3:</strong></p>
<p>The power function shows how test power varies with the true coefficient value. Here‚Äôs what each feature means:</p>
<p><strong>Key Features of the Curve:</strong></p>
<ol type="1">
<li><strong>At Œ≤ = 0 (vertical gray line)</strong>:</li>
</ol>
<ul>
<li>Power = Œ± = 0.05</li>
<li>This is the Type I error rate</li>
<li>When H‚ÇÄ is true, we reject 5% of the time (false positives)</li>
</ul>
<ol start="2" type="1">
<li><strong>As |Œ≤| increases (moving away from 0)</strong>:</li>
</ol>
<ul>
<li>Power increases rapidly</li>
<li>Larger effects are easier to detect</li>
<li>Curve approaches 1.0 (certain detection)</li>
</ul>
<ol start="3" type="1">
<li><strong>Symmetry around zero</strong>:</li>
</ol>
<ul>
<li>Power is same for Œ≤ = 30 and Œ≤ = -30</li>
<li>Two-sided test treats positive and negative effects equally</li>
<li>One-sided tests would have asymmetric power</li>
</ul>
<ol start="4" type="1">
<li><strong>The 0.80 threshold (green dashed line)</strong>:</li>
</ol>
<ul>
<li>Standard target: 80% power</li>
<li>Means 20% chance of Type II error (Œ≤ = 0.20)</li>
<li>In this example: Need |Œ≤| ‚âà 30 to achieve 80% power</li>
</ul>
<p><strong>What This Means for Study Design:</strong></p>
<p>Given the parameters (n=30, SE=15, Œ±=0.05):</p>
<ul>
<li><p><strong>Small effects</strong> (|Œ≤| &lt; 15):</p></li>
<li><p>Power &lt; 50%</p></li>
<li><p>More likely to <strong>miss</strong> the effect than detect it</p></li>
<li><p>Study is underpowered</p></li>
<li><p><strong>Medium effects</strong> (|Œ≤| ‚âà 30):</p></li>
<li><p>Power ‚âà 80%</p></li>
<li><p>Good chance of detection</p></li>
<li><p>Standard benchmark for adequate power</p></li>
<li><p><strong>Large effects</strong> (|Œ≤| &gt; 45):</p></li>
<li><p>Power &gt; 95%</p></li>
<li><p>Almost certain detection</p></li>
<li><p>Study is well-powered</p></li>
</ul>
<p><strong>Sample Size Implications:</strong></p>
<p>To detect smaller effects, you need larger samples:</p>
<ul>
<li><strong>Double the sample</strong> (n=60) ‚Üí Can detect smaller effects with same power</li>
<li>Power roughly proportional to ‚àön</li>
<li>To halve minimum detectable effect, need <strong>4√ó the sample size</strong></li>
</ul>
<p><strong>The Power-Sample Size Relationship:</strong></p>
<p>For a given effect size Œ≤:</p>
<ul>
<li>Power increases with ‚àön</li>
<li>To go from 50% to 80% power: Need ‚âà 2√ó the sample</li>
<li>To go from 80% to 95% power: Need ‚âà 2√ó the sample again</li>
</ul>
<p><strong>Practical Applications:</strong></p>
<ol type="1">
<li><strong>Pre-study planning</strong>:</li>
</ol>
<ul>
<li>Specify minimum effect of interest</li>
<li>Calculate required sample size for 80% power</li>
<li>Avoid underpowered studies</li>
</ul>
<ol start="2" type="1">
<li><strong>Post-study interpretation</strong>:</li>
</ol>
<ul>
<li>Non-significant result with low power: Inconclusive (not evidence of no effect)</li>
<li>Non-significant result with high power: Evidence against large effects</li>
<li>Significant result: Good, but consider magnitude and practical significance</li>
</ul>
<ol start="3" type="1">
<li><strong>Publication decisions</strong>:</li>
</ol>
<ul>
<li>Underpowered studies contribute to publication bias</li>
<li>Meta-analyses should weight by precision and power</li>
<li>Replication studies should be well-powered</li>
</ul>
<p><strong>Common Mistakes to Avoid:</strong></p>
<ol type="1">
<li>Treating non-significant results as ‚Äúproof of no effect‚Äù</li>
</ol>
<ul>
<li>Non-significance in underpowered study is uninformative</li>
</ul>
<ol start="2" type="1">
<li>Conducting multiple underpowered studies instead of one well-powered study</li>
</ol>
<ul>
<li>Wastes resources and leads to false negatives</li>
</ul>
<ol start="3" type="1">
<li>Post-hoc power analysis</li>
</ol>
<ul>
<li>Don‚Äôt calculate power after seeing results (circular reasoning)</li>
<li>Do it before data collection</li>
</ul>
<p><strong>The Bottom Line:</strong></p>
<p>This power curve illustrates a fundamental truth:</p>
<ul>
<li><strong>Smaller effects require larger samples to detect</strong></li>
<li>With n=30 and SE=15, we can reliably detect effects of |Œ≤| ‚â• 30</li>
<li>For smaller effects, we‚Äôd need more data or reduced noise (lower œÉ)</li>
</ul>
<div id="cell-41" class="cell" data-execution_count="12">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"12.5 BEST ESTIMATION METHODS"</span>)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Key concepts:"</span>)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">1. Gauss-Markov Theorem:"</span>)</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Under assumptions 1-4, OLS is BLUE"</span>)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - BLUE = Best Linear Unbiased Estimator"</span>)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - 'Best' = minimum variance among linear unbiased estimators"</span>)</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">2. When assumptions fail:"</span>)</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Heteroskedasticity ‚Üí Weighted Least Squares (WLS)"</span>)</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Autocorrelation ‚Üí GLS with AR errors"</span>)</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Both ‚Üí Feasible GLS (FGLS)"</span>)</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">3. Practical considerations:"</span>)</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Efficiency gains often modest in practice"</span>)</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Misspecification of error structure can worsen estimates"</span>)</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Most studies use OLS + robust SEs (simpler, more robust)"</span>)</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Exception: Panel data methods model error components explicitly"</span>)</span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">4. Maximum Likelihood:"</span>)</span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - If error distribution fully specified (e.g., normal)"</span>)</span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - MLE can be more efficient than OLS"</span>)</span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"   - Under normality, MLE = OLS for linear regression"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>======================================================================
12.5 BEST ESTIMATION METHODS
======================================================================

Key concepts:

1. Gauss-Markov Theorem:
   - Under assumptions 1-4, OLS is BLUE
   - BLUE = Best Linear Unbiased Estimator
   - 'Best' = minimum variance among linear unbiased estimators

2. When assumptions fail:
   - Heteroskedasticity ‚Üí Weighted Least Squares (WLS)
   - Autocorrelation ‚Üí GLS with AR errors
   - Both ‚Üí Feasible GLS (FGLS)

3. Practical considerations:
   - Efficiency gains often modest in practice
   - Misspecification of error structure can worsen estimates
   - Most studies use OLS + robust SEs (simpler, more robust)
   - Exception: Panel data methods model error components explicitly

4. Maximum Likelihood:
   - If error distribution fully specified (e.g., normal)
   - MLE can be more efficient than OLS
   - Under normality, MLE = OLS for linear regression</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p><strong>Key Concept 12.6: Feasible Generalized Least Squares</strong></p>
<p>When error variance is not constant (heteroskedasticity) or errors are correlated (autocorrelation), OLS remains unbiased but is no longer the most efficient estimator. Feasible GLS (FGLS) models the error structure and can achieve lower variance. However, FGLS requires correctly specifying the error structure ‚Äî in practice, OLS with robust SEs is preferred for its simplicity and robustness to misspecification.</p>
</blockquote>
</section>
</section>
<section id="best-confidence-intervals" class="level2">
<h2 class="anchored" data-anchor-id="best-confidence-intervals">12.6: Best Confidence Intervals</h2>
<p><strong>What makes a confidence interval ‚Äúbest‚Äù?</strong></p>
<p>A 95% CI is ‚Äúbest‚Äù if it:</p>
<ol type="1">
<li>Has correct coverage: Contains true parameter 95% of the time</li>
<li>Has minimum width among all CIs with correct coverage</li>
</ol>
<p><strong>Standard approach</strong>: <span class="math inline">\(\hat{\beta}_j \pm t_{n-k, \alpha/2} \times se(\hat{\beta}_j)\)</span></p>
<ul>
<li>Width determined by <span class="math inline">\(se(\hat{\beta}_j)\)</span></li>
<li>Shortest CI comes from most efficient estimator</li>
</ul>
<p><strong>Alternative approaches</strong>:</p>
<p><strong>1. Bootstrap confidence intervals</strong></p>
<ul>
<li>Resample data many times (e.g., 1000 replications)</li>
<li>Re-estimate model for each resample</li>
<li>Use distribution of bootstrap estimates</li>
<li>Percentile method: 2.5th and 97.5th percentiles</li>
<li>Advantages: No distributional assumptions, works for complex statistics</li>
</ul>
<p><strong>2. Bayesian credible intervals</strong></p>
<ul>
<li>Based on posterior distribution</li>
<li>Direct probability interpretation</li>
<li>Incorporates prior information</li>
</ul>
<p><strong>When assumptions fail</strong>:</p>
<ul>
<li>Use robust SEs ‚Üí wider but valid intervals</li>
<li>Bootstrap ‚Üí more accurate coverage in small samples</li>
<li>Asymptotic approximations may be poor in small samples</li>
</ul>
<blockquote class="blockquote">
<p><strong>Key Concept 12.7: Bootstrap Confidence Intervals</strong></p>
<p>The bootstrap resamples the original data (with replacement) many times to estimate the sampling distribution of a statistic. Bootstrap CIs don‚Äôt rely on normality or large-sample approximations, making them especially useful with small samples, skewed distributions, or non-standard estimators where analytical formulas aren‚Äôt available.</p>
</blockquote>
<p>Having discussed the best confidence intervals, we now examine what makes a hypothesis test optimal ‚Äî balancing Type I and Type II errors.</p>
</section>
<section id="best-tests" class="level2">
<h2 class="anchored" data-anchor-id="best-tests">12.7: Best Tests</h2>
<p><strong>Type I and Type II errors</strong>:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Decision</th>
<th><span class="math inline">\(H_0\)</span> True</th>
<th><span class="math inline">\(H_0\)</span> False</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Reject <span class="math inline">\(H_0\)</span></td>
<td>Type I error (Œ±)</td>
<td>Correct</td>
</tr>
<tr class="even">
<td>Don‚Äôt reject</td>
<td>Correct</td>
<td>Type II error (Œ≤)</td>
</tr>
</tbody>
</table>
<p><strong>Type I error</strong> (false positive):</p>
<ul>
<li>Reject <span class="math inline">\(H_0\)</span> when it‚Äôs true</li>
<li>Probability = significance level Œ± (e.g., 0.05)</li>
<li>We control this directly</li>
</ul>
<p><strong>Type II error</strong> (false negative):</p>
<ul>
<li>Fail to reject <span class="math inline">\(H_0\)</span> when it‚Äôs false</li>
<li>Probability = Œ≤</li>
<li>Harder to control</li>
</ul>
<p><strong>Test power</strong> = 1 - Œ≤</p>
<ul>
<li>Probability of correctly rejecting false <span class="math inline">\(H_0\)</span></li>
<li>Higher power is better</li>
</ul>
<p><strong>Trade-off</strong>:</p>
<ul>
<li>Decreasing Œ± (stricter test) ‚Üí increases Œ≤ (lower power)</li>
<li>Solution: Fix Œ±, maximize power</li>
</ul>
<p><strong>Most powerful test</strong>:</p>
<ul>
<li>Among all tests with size Œ±, has highest power</li>
<li>For linear regression: Use most efficient estimator</li>
</ul>
<p><strong>The Trinity of Tests</strong> (asymptotically equivalent):</p>
<ol type="1">
<li><strong>Wald test</strong>: Based on unrestricted estimates</li>
<li><strong>Likelihood Ratio (LR) test</strong>: Compares likelihoods</li>
<li><strong>Lagrange Multiplier (LM) test</strong>: Based on restricted estimates</li>
</ol>
<p><strong>Multiple testing</strong>:</p>
<ul>
<li>Testing many hypotheses inflates Type I error</li>
<li>Solutions: Bonferroni correction, FDR control</li>
</ul>
<section id="illustration-power-of-a-test" class="level3">
<h3 class="anchored" data-anchor-id="illustration-power-of-a-test">Illustration: Power of a Test</h3>
<p>Let‚Äôs visualize how test power depends on the true effect size.</p>
<blockquote class="blockquote">
<p><strong>Key Concept 12.8: Type I and Type II Errors</strong></p>
<p>Type I error (false positive) means rejecting a true <span class="math inline">\(H_0\)</span>; its probability equals the significance level <span class="math inline">\(\alpha\)</span>. Type II error (false negative) means failing to reject a false <span class="math inline">\(H_0\)</span>. Power = <span class="math inline">\(1 - P(\text{Type II})\)</span> measures the ability to detect true effects. The most powerful test for a given size uses the most precise estimator ‚Äî another reason efficient estimation matters beyond point estimates.</p>
</blockquote>
</section>
</section>
<section id="key-takeaways" class="level2">
<h2 class="anchored" data-anchor-id="key-takeaways">Key Takeaways</h2>
<p><strong>Robust Standard Errors:</strong></p>
<ul>
<li>When error variance is non-constant, default SEs are invalid ‚Äî use heteroskedastic-robust (HC1) SEs for cross-sectional data</li>
<li>With grouped observations, use cluster-robust SEs with <span class="math inline">\(G-1\)</span> degrees of freedom (not <span class="math inline">\(N-k\)</span>)</li>
<li>For time series with autocorrelated errors, use HAC (Newey-West) SEs with lag length <span class="math inline">\(m \approx 0.75 \times T^{1/3}\)</span></li>
<li>Coefficient estimates are unchanged; only SEs, <span class="math inline">\(t\)</span>-statistics, and CIs change</li>
</ul>
<p><strong>Prediction:</strong></p>
<ul>
<li>Predicting the conditional mean <span class="math inline">\(E[y|x^*]\)</span> is more precise than predicting an individual outcome <span class="math inline">\(y|x^*\)</span></li>
<li>Forecast variance = conditional mean variance + <span class="math inline">\(\text{Var}(u^*)\)</span>, so prediction intervals are always wider</li>
<li>Even with precise coefficients, individual forecasts are imprecise because we cannot predict <span class="math inline">\(u^*\)</span></li>
<li>Policy decisions should be based on average outcomes (precise) rather than individual predictions (imprecise)</li>
</ul>
<p><strong>Nonrepresentative Samples:</strong></p>
<ul>
<li>Sample selection on <span class="math inline">\(Y\)</span> can bias OLS estimates; selection on <span class="math inline">\(X\)</span> is less harmful</li>
<li>Survey weights can adjust for known selection, but unknown selection remains problematic</li>
</ul>
<p><strong>Best Estimation:</strong></p>
<ul>
<li>Under correct assumptions, OLS is BLUE (Gauss-Markov); when assumptions fail, FGLS is more efficient</li>
<li>In practice, most studies use OLS with robust SEs ‚Äî accepting a small efficiency loss for simplicity</li>
</ul>
<p><strong>Best Confidence Intervals:</strong></p>
<ul>
<li>Bootstrap methods resample the data to estimate the sampling distribution without relying on normality</li>
<li>Particularly useful with small samples or non-normal errors</li>
</ul>
<p><strong>Best Tests:</strong></p>
<ul>
<li>Type I error = false positive (rejecting true <span class="math inline">\(H_0\)</span>); Type II error = false negative</li>
<li>Power = <span class="math inline">\(1 - P(\text{Type II})\)</span>; the most powerful test uses the most precise estimator</li>
<li>Higher power comes from larger samples, more variation in regressors, and lower noise</li>
</ul>
<p><strong>Python tools used:</strong> <code>statsmodels</code> (OLS, HC1, <code>get_prediction()</code>), <code>scipy.stats</code> (distributions), <code>matplotlib</code>/<code>seaborn</code> (correlograms, prediction plots)</p>
<p><strong>Next steps:</strong> Chapter 13 introduces <strong>dummy variables</strong> and <strong>indicator variables</strong> ‚Äî extending regression to handle qualitative explanatory variables.</p>
<p>Congratulations on completing Chapter 12! You now understand advanced inference methods for handling real-world data challenges.</p>
</section>
<section id="practice-exercises" class="level2">
<h2 class="anchored" data-anchor-id="practice-exercises">Practice Exercises</h2>
<p>Test your understanding of advanced inference topics.</p>
<hr>
<p><strong>Exercise 1: Choosing Standard Errors</strong></p>
<p>For each scenario, identify the appropriate type of standard errors:</p>
<ol type="a">
<li><p>Cross-sectional survey of 500 households with varying income levels.</p></li>
<li><p>Panel data on 50 schools over 10 years, where student outcomes within a school are correlated.</p></li>
<li><p>Monthly GDP growth data for 20 years, where this quarter‚Äôs shock affects next quarter.</p></li>
<li><p>A randomized experiment with 200 independent observations and constant error variance.</p></li>
</ol>
<hr>
<p><strong>Exercise 2: Point Prediction</strong></p>
<p>A fitted regression model gives <span class="math inline">\(\widehat{y} = 10 + 2x_2 + 3x_3\)</span> with <span class="math inline">\(n = 200\)</span> and <span class="math inline">\(s_e = 2.0\)</span>.</p>
<ol type="a">
<li><p>Predict <span class="math inline">\(y\)</span> when <span class="math inline">\(x_2 = 5\)</span> and <span class="math inline">\(x_3 = 3\)</span>.</p></li>
<li><p>Is this a prediction of the conditional mean or an individual outcome?</p></li>
</ol>
<hr>
<p><strong>Exercise 3: Conditional Mean CI</strong></p>
<p>Using the model from Exercise 2, suppose <span class="math inline">\(se(\widehat{y}_{cm}) = 0.8\)</span> at <span class="math inline">\(x_2 = 5, x_3 = 3\)</span>.</p>
<ol type="a">
<li><p>Construct an approximate 95% confidence interval for <span class="math inline">\(E[y|x_2=5, x_3=3]\)</span>.</p></li>
<li><p>How would this interval change if the sample size doubled (assume SE shrinks by <span class="math inline">\(\sqrt{2}\)</span>)?</p></li>
</ol>
<hr>
<p><strong>Exercise 4: Individual Forecast CI</strong></p>
<p>Continuing from Exercise 3, construct a 95% prediction interval for an individual <span class="math inline">\(y\)</span> at <span class="math inline">\(x_2 = 5, x_3 = 3\)</span>.</p>
<ol type="a">
<li><p>Compute <span class="math inline">\(se(\widehat{y}_f) = \sqrt{se(\widehat{y}_{cm})^2 + s_e^2}\)</span>.</p></li>
<li><p>Construct the prediction interval.</p></li>
<li><p>Why is this interval so much wider than the confidence interval for the conditional mean?</p></li>
</ol>
<hr>
<p><strong>Exercise 5: Robust vs.&nbsp;Default Inference</strong></p>
<p>A regression yields the following results:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Variable</th>
<th>Coefficient</th>
<th>Default SE</th>
<th>Robust SE</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(x_2\)</span></td>
<td>5.0</td>
<td>2.0</td>
<td>3.5</td>
</tr>
<tr class="even">
<td><span class="math inline">\(x_3\)</span></td>
<td>7.0</td>
<td>2.0</td>
<td>1.8</td>
</tr>
</tbody>
</table>
<ol type="a">
<li><p>Compute the <span class="math inline">\(t\)</span>-statistic for each variable using default and robust SEs.</p></li>
<li><p>At <span class="math inline">\(\alpha = 0.05\)</span>, which variables are significant under each type of SE?</p></li>
<li><p>What does the change in SEs suggest about heteroskedasticity?</p></li>
</ol>
<hr>
<p><strong>Exercise 6: Type I/II Error Tradeoff</strong></p>
<p>A researcher tests <span class="math inline">\(H_0: \beta = 0\)</span> at three significance levels: <span class="math inline">\(\alpha = 0.01, 0.05, 0.10\)</span>.</p>
<ol type="a">
<li><p>As <span class="math inline">\(\alpha\)</span> decreases, what happens to the probability of Type I error?</p></li>
<li><p>As <span class="math inline">\(\alpha\)</span> decreases, what happens to the probability of Type II error?</p></li>
<li><p>If it‚Äôs very costly to miss a true effect (high cost of Type II error), should you use a smaller or larger <span class="math inline">\(\alpha\)</span>? Explain.</p></li>
</ol>
</section>
<section id="case-studies" class="level2">
<h2 class="anchored" data-anchor-id="case-studies">Case Studies</h2>
<section id="case-study-1-robust-inference-for-cross-country-productivity" class="level3">
<h3 class="anchored" data-anchor-id="case-study-1-robust-inference-for-cross-country-productivity">Case Study 1: Robust Inference for Cross-Country Productivity</h3>
<p>In this case study, you will apply robust inference methods to cross-country productivity data. You‚Äôll compare default and robust standard errors, make predictions for specific countries, and assess how methodological choices affect conclusions about productivity determinants.</p>
<p><strong>Dataset:</strong> Mendez Convergence Clubs Data</p>
<ul>
<li><strong>Source:</strong> Mendez (2020), 108 countries, 1990-2014</li>
<li><strong>Key variables:</strong>
<ul>
<li><code>lp</code> ‚Äî Labor productivity (GDP per worker)</li>
<li><code>rk</code> ‚Äî Physical capital per worker</li>
<li><code>hc</code> ‚Äî Human capital index</li>
<li><code>region</code> ‚Äî Geographic region (for clustering)</li>
</ul></li>
</ul>
<p><strong>Research question:</strong> Do conclusions about productivity determinants change when using robust standard errors? How precisely can we predict productivity for a specific country?</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the Mendez convergence clubs dataset</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">"https://raw.githubusercontent.com/quarcs-lab/mendez2020-convergence-clubs-code-data/master/assets/dat.csv"</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>dat <span class="op">=</span> pd.read_csv(url)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>dat_2014 <span class="op">=</span> dat[dat[<span class="st">'year'</span>] <span class="op">==</span> <span class="dv">2014</span>].dropna(subset<span class="op">=</span>[<span class="st">'lp'</span>, <span class="st">'rk'</span>, <span class="st">'hc'</span>]).copy()</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>dat_2014[<span class="st">'ln_lp'</span>] <span class="op">=</span> np.log(dat_2014[<span class="st">'lp'</span>])</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>dat_2014[<span class="st">'ln_rk'</span>] <span class="op">=</span> np.log(dat_2014[<span class="st">'rk'</span>])</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Cross-section sample: </span><span class="sc">{</span><span class="bu">len</span>(dat_2014)<span class="sc">}</span><span class="ss"> countries (year 2014)"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<section id="task-1-default-vs.-robust-standard-errors-guided" class="level4">
<h4 class="anchored" data-anchor-id="task-1-default-vs.-robust-standard-errors-guided">Task 1: Default vs.&nbsp;Robust Standard Errors (Guided)</h4>
<p>Compare default and heteroskedastic-robust standard errors.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate model with default SEs</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> ols(<span class="st">'ln_lp ~ ln_rk + hc'</span>, data<span class="op">=</span>dat_2014).fit()</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Default SEs:"</span>)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model.summary())</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate with HC1 robust SEs</span></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>model_robust <span class="op">=</span> model.get_robustcov_results(cov_type<span class="op">=</span><span class="st">'HC1'</span>)</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Robust SEs:"</span>)</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model_robust.summary())</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Questions:</strong></p>
<ul>
<li>How do the standard errors change? Which variables are affected most?</li>
<li>Do any significance conclusions change between default and robust SEs?</li>
</ul>
</section>
<section id="task-2-cluster-robust-ses-by-region-guided" class="level4">
<h4 class="anchored" data-anchor-id="task-2-cluster-robust-ses-by-region-guided">Task 2: Cluster-Robust SEs by Region (Guided)</h4>
<p>Estimate with cluster-robust standard errors grouped by geographic region.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Cluster-robust SEs by region</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>model_cluster <span class="op">=</span> model.get_robustcov_results(cov_type<span class="op">=</span><span class="st">'cluster'</span>, groups<span class="op">=</span>dat_2014[<span class="st">'region'</span>])</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Cluster-Robust SEs (by region):"</span>)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model_cluster.summary())</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare all three SE types</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">SE Comparison:"</span>)</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> var <span class="kw">in</span> [<span class="st">'Intercept'</span>, <span class="st">'ln_rk'</span>, <span class="st">'hc'</span>]:</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>var<span class="sc">}</span><span class="ss">: Default=</span><span class="sc">{</span>model<span class="sc">.</span>bse[var]<span class="sc">:.4f}</span><span class="ss">, HC1=</span><span class="sc">{</span>model_robust<span class="sc">.</span>bse[var]<span class="sc">:.4f}</span><span class="ss">, Cluster=</span><span class="sc">{</span>model_cluster<span class="sc">.</span>bse[var]<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Questions:</strong></p>
<ul>
<li>Are cluster-robust SEs larger or smaller than HC1 SEs? Why?</li>
<li>How many clusters (regions) are there? Is this enough for reliable cluster-robust inference?</li>
</ul>
<blockquote class="blockquote">
<p><strong>Key Concept 12.9: Choosing the Right Standard Errors</strong></p>
<p>The choice of standard errors depends on the data structure: HC1 for cross-sectional data with potential heteroskedasticity, cluster-robust when observations are grouped (e.g., countries within regions), and HAC for time series. With cross-country data, cluster-robust SEs by region account for the possibility that countries in the same region share unobserved shocks.</p>
</blockquote>
</section>
<section id="task-3-predict-conditional-mean-semi-guided" class="level4">
<h4 class="anchored" data-anchor-id="task-3-predict-conditional-mean-semi-guided">Task 3: Predict Conditional Mean (Semi-guided)</h4>
<p>Predict average productivity for a country with median capital and human capital values.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get median values</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>median_ln_rk <span class="op">=</span> dat_2014[<span class="st">'ln_rk'</span>].median()</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>median_hc <span class="op">=</span> dat_2014[<span class="st">'hc'</span>].median()</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Median ln(rk) = </span><span class="sc">{</span>median_ln_rk<span class="sc">:.3f}</span><span class="ss">, Median hc = </span><span class="sc">{</span>median_hc<span class="sc">:.3f}</span><span class="ss">"</span>)</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict conditional mean with CI</span></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>pred_data <span class="op">=</span> pd.DataFrame({<span class="st">'ln_rk'</span>: [median_ln_rk], <span class="st">'hc'</span>: [median_hc]})</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>pred <span class="op">=</span> model.get_prediction(pred_data)</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pred.summary_frame(alpha<span class="op">=</span><span class="fl">0.05</span>))</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Questions:</strong></p>
<ul>
<li>What is the predicted <span class="math inline">\(\ln(\text{lp})\)</span> for a median country? Convert back to levels.</li>
<li>How narrow is the 95% CI for the conditional mean?</li>
</ul>
</section>
<section id="task-4-forecast-individual-country-semi-guided" class="level4">
<h4 class="anchored" data-anchor-id="task-4-forecast-individual-country-semi-guided">Task 4: Forecast Individual Country (Semi-guided)</h4>
<p>Construct a prediction interval for an individual country‚Äôs productivity.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get prediction with observation-level interval</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>pred_frame <span class="op">=</span> pred.summary_frame(alpha<span class="op">=</span><span class="fl">0.05</span>)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Conditional mean CI vs. Prediction interval:"</span>)</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Mean CI:       [</span><span class="sc">{</span>pred_frame[<span class="st">'mean_ci_lower'</span>]<span class="sc">.</span>values[<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss">, </span><span class="sc">{</span>pred_frame[<span class="st">'mean_ci_upper'</span>]<span class="sc">.</span>values[<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss">]"</span>)</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"  Prediction PI: [</span><span class="sc">{</span>pred_frame[<span class="st">'obs_ci_lower'</span>]<span class="sc">.</span>values[<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss">, </span><span class="sc">{</span>pred_frame[<span class="st">'obs_ci_upper'</span>]<span class="sc">.</span>values[<span class="dv">0</span>]<span class="sc">:.3f}</span><span class="ss">]"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Questions:</strong></p>
<ul>
<li>How much wider is the prediction interval compared to the confidence interval?</li>
<li>Why can‚Äôt we predict an individual country‚Äôs productivity precisely even with good data?</li>
</ul>
</section>
<section id="task-5-model-comparison-with-robust-inference-independent" class="level4">
<h4 class="anchored" data-anchor-id="task-5-model-comparison-with-robust-inference-independent">Task 5: Model Comparison with Robust Inference (Independent)</h4>
<p>Compare nested models using robust inference.</p>
<p><strong>Your tasks:</strong></p>
<ol type="1">
<li>Estimate three models: (a) <span class="math inline">\(\ln(\text{lp}) \sim \ln(\text{rk})\)</span> only, (b) <span class="math inline">\(\ln(\text{lp}) \sim \text{hc}\)</span> only, (c) both regressors</li>
<li>For each model, report both default and HC1 robust standard errors</li>
<li>Do the significance conclusions change between default and robust SEs for any model?</li>
<li>Compare prediction interval widths across models ‚Äî does adding variables improve individual predictions?</li>
</ol>
<p><em>Hint: Use <code>model.get_robustcov_results(cov_type='HC1')</code> for robust SEs and <code>model.get_prediction()</code> for predictions.</em></p>
</section>
<section id="task-6-policy-brief-on-inference-robustness-independent" class="level4">
<h4 class="anchored" data-anchor-id="task-6-policy-brief-on-inference-robustness-independent">Task 6: Policy Brief on Inference Robustness (Independent)</h4>
<p>Write a 200-300 word policy brief summarizing your findings.</p>
<p><strong>Your brief should address:</strong></p>
<ol type="1">
<li>How do conclusions about productivity determinants change with robust standard errors?</li>
<li>What is the practical difference between cluster-robust and HC1 SEs in this context?</li>
<li>How precisely can we predict productivity for a specific country vs.&nbsp;a group of countries?</li>
<li>What recommendations would you make about standard error choices for cross-country studies?</li>
<li>What are the limitations of these inference methods (what don‚Äôt they fix)?</li>
</ol>
<blockquote class="blockquote">
<p><strong>Key Concept 12.10: Robust Methods Don‚Äôt Fix Everything</strong></p>
<p>Robust standard errors correct for heteroskedasticity and clustering, but they don‚Äôt address omitted variable bias, reverse causality, or measurement error. A coefficient estimate with a perfectly robust SE is still biased if the model is misspecified. Robust inference ensures valid <span class="math inline">\(p\)</span>-values and CIs <em>conditional on the model being correct</em> ‚Äî it‚Äôs a necessary but not sufficient condition for credible empirical work.</p>
</blockquote>
</section>
</section>
<section id="what-youve-learned" class="level3">
<h3 class="anchored" data-anchor-id="what-youve-learned">What You‚Äôve Learned</h3>
<p>In this case study, you applied advanced inference methods to cross-country productivity data:</p>
<ul>
<li>Compared default, heteroskedastic-robust, and cluster-robust standard errors</li>
<li>Observed how SE choices affect significance conclusions</li>
<li>Predicted conditional means with narrow CIs and individual outcomes with wide PIs</li>
<li>Connected robust inference methods to practical policy questions</li>
</ul>
<p>These tools ensure your empirical conclusions are reliable under realistic data conditions.</p>
</section>
<section id="case-study-2-robust-prediction-of-municipal-development" class="level3">
<h3 class="anchored" data-anchor-id="case-study-2-robust-prediction-of-municipal-development">Case Study 2: Robust Prediction of Municipal Development</h3>
<p>In Chapters 10-11, we estimated multiple regression models predicting municipal development from nighttime lights and satellite embeddings, and tested the statistical significance of these predictors. Now we apply Chapter 12‚Äôs tools for <strong>robust inference</strong> and <strong>prediction</strong>‚Äîcrucial for translating satellite models into practical SDG monitoring tools.</p>
<p><strong>The Data</strong>: The <a href="https://github.com/quarcs-lab/ds4bolivia">DS4Bolivia project</a> provides a comprehensive dataset covering 339 Bolivian municipalities with over 350 variables, including the Municipal Sustainable Development Index (IMDS), nighttime lights per capita, and 64 satellite embedding dimensions. Here we focus on robust standard errors and prediction intervals for the satellite-development model.</p>
<section id="load-the-ds4bolivia-data" class="level4">
<h4 class="anchored" data-anchor-id="load-the-ds4bolivia-data">Load the DS4Bolivia Data</h4>
<p>Let‚Äôs load the DS4Bolivia dataset and select the key variables for robust inference and prediction analysis.</p>
<div id="cell-63" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Load the DS4Bolivia dataset</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>url_bol <span class="op">=</span> <span class="st">"https://raw.githubusercontent.com/quarcs-lab/ds4bolivia/master/ds4bolivia_v20250523.csv"</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>bol <span class="op">=</span> pd.read_csv(url_bol)</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Display basic information</span></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"DS4BOLIVIA DATASET"</span>)</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Dataset shape: </span><span class="sc">{</span>bol<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> municipalities, </span><span class="sc">{</span>bol<span class="sc">.</span>shape[<span class="dv">1</span>]<span class="sc">}</span><span class="ss"> variables"</span>)</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Departments: </span><span class="sc">{</span>bol[<span class="st">'dep'</span>]<span class="sc">.</span>nunique()<span class="sc">}</span><span class="ss"> unique departments"</span>)</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Department names: </span><span class="sc">{</span><span class="bu">sorted</span>(bol[<span class="st">'dep'</span>].unique())<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Select key variables for this case study</span></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>key_vars <span class="op">=</span> [<span class="st">'mun'</span>, <span class="st">'dep'</span>, <span class="st">'imds'</span>, <span class="st">'ln_NTLpc2017'</span>,</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>            <span class="st">'A00'</span>, <span class="st">'A10'</span>, <span class="st">'A20'</span>, <span class="st">'A30'</span>, <span class="st">'A40'</span>]</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>bol_key <span class="op">=</span> bol[key_vars].copy()</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Key variables selected: </span><span class="sc">{</span><span class="bu">len</span>(key_vars)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"FIRST 10 MUNICIPALITIES"</span>)</span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(bol_key.head(<span class="dv">10</span>).to_string())</span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Variable descriptions</span></span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"KEY VARIABLE DESCRIPTIONS"</span>)</span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a>descriptions <span class="op">=</span> {</span>
<span id="cb30-29"><a href="#cb30-29" aria-hidden="true" tabindex="-1"></a>    <span class="st">'mun'</span>: <span class="st">'Municipality name'</span>,</span>
<span id="cb30-30"><a href="#cb30-30" aria-hidden="true" tabindex="-1"></a>    <span class="st">'dep'</span>: <span class="st">'Department (administrative region, 9 total)'</span>,</span>
<span id="cb30-31"><a href="#cb30-31" aria-hidden="true" tabindex="-1"></a>    <span class="st">'imds'</span>: <span class="st">'Municipal Sustainable Development Index (0-100, composite of all SDGs)'</span>,</span>
<span id="cb30-32"><a href="#cb30-32" aria-hidden="true" tabindex="-1"></a>    <span class="st">'ln_NTLpc2017'</span>: <span class="st">'Log of nighttime lights per capita (2017, satellite-based)'</span>,</span>
<span id="cb30-33"><a href="#cb30-33" aria-hidden="true" tabindex="-1"></a>    <span class="st">'A00-A40'</span>: <span class="st">'Satellite image embedding dimensions (5 of 64 principal features)'</span>,</span>
<span id="cb30-34"><a href="#cb30-34" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb30-35"><a href="#cb30-35" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> var, desc <span class="kw">in</span> descriptions.items():</span>
<span id="cb30-36"><a href="#cb30-36" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  </span><span class="sc">{</span>var<span class="sc">:20s}</span><span class="ss"> --- </span><span class="sc">{</span>desc<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="task-1-default-vs-robust-standard-errors-guided" class="level4">
<h4 class="anchored" data-anchor-id="task-1-default-vs-robust-standard-errors-guided">Task 1: Default vs Robust Standard Errors (Guided)</h4>
<p><strong>Objective</strong>: Estimate the satellite-development model with both default and HC1 robust standard errors and compare the results.</p>
<p><strong>Instructions</strong>:</p>
<ol type="1">
<li>Estimate <code>imds ~ ln_NTLpc2017 + A00 + A10 + A20 + A30 + A40</code> with default standard errors</li>
<li>Re-estimate with HC1 robust standard errors (<code>cov_type='HC1'</code>)</li>
<li>Compare standard errors side-by-side for each coefficient</li>
<li>Identify which coefficients have substantially different SEs under the two methods</li>
</ol>
<p><strong>Apply what you learned in section 12.2</strong>: Use <code>ols().fit()</code> for default SEs and <code>ols().fit(cov_type='HC1')</code> for robust SEs.</p>
<div id="cell-65" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Task 1: Default vs Robust Standard Errors</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="co"># ----------------------------------------------------------</span></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare regression data (drop missing values)</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>reg_vars <span class="op">=</span> [<span class="st">'imds'</span>, <span class="st">'ln_NTLpc2017'</span>, <span class="st">'A00'</span>, <span class="st">'A10'</span>, <span class="st">'A20'</span>, <span class="st">'A30'</span>, <span class="st">'A40'</span>]</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>reg_data <span class="op">=</span> bol_key[reg_vars <span class="op">+</span> [<span class="st">'dep'</span>]].dropna()</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Regression sample: </span><span class="sc">{</span><span class="bu">len</span>(reg_data)<span class="sc">}</span><span class="ss"> municipalities (after dropping missing values)"</span>)</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate with default standard errors</span></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>model_default <span class="op">=</span> ols(<span class="st">'imds ~ ln_NTLpc2017 + A00 + A10 + A20 + A30 + A40'</span>,</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>                    data<span class="op">=</span>reg_data).fit()</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate with HC1 robust standard errors</span></span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>model_hc1 <span class="op">=</span> ols(<span class="st">'imds ~ ln_NTLpc2017 + A00 + A10 + A20 + A30 + A40'</span>,</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>                data<span class="op">=</span>reg_data).fit(cov_type<span class="op">=</span><span class="st">'HC1'</span>)</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span> <span class="op">+</span> <span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"COMPARISON: DEFAULT vs HC1 ROBUST STANDARD ERRORS"</span>)</span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'Variable'</span><span class="sc">:&lt;18}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Coef'</span><span class="sc">:&gt;10}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Default SE'</span><span class="sc">:&gt;12}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'HC1 SE'</span><span class="sc">:&gt;12}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Ratio'</span><span class="sc">:&gt;8}</span><span class="ss">"</span>)</span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">62</span>)</span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> var <span class="kw">in</span> model_default.params.index:</span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a>    coef <span class="op">=</span> model_default.params[var]</span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>    se_def <span class="op">=</span> model_default.bse[var]</span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a>    se_hc1 <span class="op">=</span> model_hc1.bse[var]</span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>    ratio <span class="op">=</span> se_hc1 <span class="op">/</span> se_def</span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>var<span class="sc">:&lt;18}</span><span class="ss"> </span><span class="sc">{</span>coef<span class="sc">:&gt;10.4f}</span><span class="ss"> </span><span class="sc">{</span>se_def<span class="sc">:&gt;12.4f}</span><span class="ss"> </span><span class="sc">{</span>se_hc1<span class="sc">:&gt;12.4f}</span><span class="ss"> </span><span class="sc">{</span>ratio<span class="sc">:&gt;8.3f}</span><span class="ss">"</span>)</span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">R-squared: </span><span class="sc">{</span>model_default<span class="sc">.</span>rsquared<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Adj. R-squared: </span><span class="sc">{</span>model_default<span class="sc">.</span>rsquared_adj<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Note: Coefficients are identical --- only SEs change."</span>)</span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Ratios &gt; 1 suggest heteroskedasticity inflates default SEs' precision."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="task-2-cluster-robust-standard-errors-by-department-guided" class="level4">
<h4 class="anchored" data-anchor-id="task-2-cluster-robust-standard-errors-by-department-guided">Task 2: Cluster-Robust Standard Errors by Department (Guided)</h4>
<p><strong>Objective</strong>: Re-estimate the model with cluster-robust standard errors grouped by department.</p>
<p><strong>Instructions</strong>:</p>
<ol type="1">
<li>Re-estimate using <code>cov_type='cluster'</code> with <code>cov_kwds={'groups': reg_data['dep']}</code></li>
<li>Compare cluster-robust SEs with default and HC1 SEs</li>
<li>Discuss: Why might municipalities within a department share unobserved characteristics?</li>
</ol>
<p><strong>Apply what you learned in section 12.2</strong>: Cluster-robust SEs account for within-group correlation of errors.</p>
<div id="cell-67" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Task 2: Cluster-Robust Standard Errors by Department</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="co"># ----------------------------------------------------------</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate with cluster-robust SEs by department</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>model_cluster <span class="op">=</span> ols(<span class="st">'imds ~ ln_NTLpc2017 + A00 + A10 + A20 + A30 + A40'</span>,</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>                    data<span class="op">=</span>reg_data).fit(cov_type<span class="op">=</span><span class="st">'cluster'</span>,</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>                                      cov_kwds<span class="op">=</span>{<span class="st">'groups'</span>: reg_data[<span class="st">'dep'</span>]})</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"COMPARISON: DEFAULT vs HC1 vs CLUSTER-ROBUST STANDARD ERRORS"</span>)</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"="</span> <span class="op">*</span> <span class="dv">70</span>)</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span><span class="st">'Variable'</span><span class="sc">:&lt;18}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Coef'</span><span class="sc">:&gt;10}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Default SE'</span><span class="sc">:&gt;12}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'HC1 SE'</span><span class="sc">:&gt;12}</span><span class="ss"> </span><span class="sc">{</span><span class="st">'Cluster SE'</span><span class="sc">:&gt;12}</span><span class="ss">"</span>)</span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-"</span> <span class="op">*</span> <span class="dv">66</span>)</span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> var <span class="kw">in</span> model_default.params.index:</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>    coef <span class="op">=</span> model_default.params[var]</span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a>    se_def <span class="op">=</span> model_default.bse[var]</span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>    se_hc1 <span class="op">=</span> model_hc1.bse[var]</span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a>    se_clust <span class="op">=</span> model_cluster.bse[var]</span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>var<span class="sc">:&lt;18}</span><span class="ss"> </span><span class="sc">{</span>coef<span class="sc">:&gt;10.4f}</span><span class="ss"> </span><span class="sc">{</span>se_def<span class="sc">:&gt;12.4f}</span><span class="ss"> </span><span class="sc">{</span>se_hc1<span class="sc">:&gt;12.4f}</span><span class="ss"> </span><span class="sc">{</span>se_clust<span class="sc">:&gt;12.4f}</span><span class="ss">"</span>)</span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a>n_clusters <span class="op">=</span> reg_data[<span class="st">'dep'</span>].nunique()</span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Number of clusters (departments): </span><span class="sc">{</span>n_clusters<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Municipalities per department (avg): </span><span class="sc">{</span><span class="bu">len</span>(reg_data) <span class="op">/</span> n_clusters<span class="sc">:.0f}</span><span class="ss">"</span>)</span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Discussion: Municipalities within the same department share"</span>)</span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"geographic, institutional, and cultural characteristics that create"</span>)</span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"within-cluster correlation. Cluster-robust SEs account for this."</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<blockquote class="blockquote">
<p><strong>Key Concept 12.11: Clustered Observations in Spatial Data</strong></p>
<p>Municipalities within the same department share geographic, institutional, and cultural characteristics that create <strong>within-cluster correlation</strong>. Standard OLS assumes independent errors, but when municipalities in La Paz share unobserved factors that affect development, their errors are correlated. Cluster-robust standard errors account for this correlation, typically producing <em>larger</em> SEs than default or HC1, reflecting the reduced effective sample size.</p>
</blockquote>
</section>
<section id="task-3-predict-conditional-mean-semi-guided-1" class="level4">
<h4 class="anchored" data-anchor-id="task-3-predict-conditional-mean-semi-guided-1">Task 3: Predict Conditional Mean (Semi-guided)</h4>
<p><strong>Objective</strong>: Use <code>model.get_prediction()</code> to predict average IMDS for a municipality with median values of all predictors.</p>
<p><strong>Instructions</strong>:</p>
<ol type="1">
<li>Calculate the median value of each predictor variable</li>
<li>Use <code>model_default.get_prediction()</code> to predict IMDS at the median predictor values</li>
<li>Report the predicted value and its 95% confidence interval</li>
<li>Interpret: ‚ÄúFor a typical municipality, we predict IMDS between X and Y‚Äù</li>
</ol>
<p><strong>Apply what you learned in section 12.3</strong>: The confidence interval for the conditional mean reflects estimation uncertainty only.</p>
<div id="cell-70" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Task 3: Predict Conditional Mean</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="co"># ----------------------------------------------------------</span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Your code here: Predict IMDS for a municipality with median predictor values</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Steps:</span></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Calculate median values for each predictor</span></span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Create a DataFrame with those values</span></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Use model_default.get_prediction() to get prediction and CI</span></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Report and interpret</span></span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Example structure:</span></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a><span class="co"># pred_vars = ['ln_NTLpc2017', 'A00', 'A10', 'A20', 'A30', 'A40']</span></span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a><span class="co"># median_vals = reg_data[pred_vars].median()</span></span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a><span class="co"># pred_data = pd.DataFrame([median_vals])</span></span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a><span class="co"># pred = model_default.get_prediction(pred_data)</span></span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a><span class="co"># pred_frame = pred.summary_frame(alpha=0.05)</span></span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a><span class="co"># print(pred_frame)</span></span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"\nPredicted IMDS: {pred_frame['mean'].values[0]:.2f}")</span></span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"95% CI for E[IMDS|X]: [{pred_frame['mean_ci_lower'].values[0]:.2f}, "</span></span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a><span class="co">#       f"{pred_frame['mean_ci_upper'].values[0]:.2f}]")</span></span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"\nInterpretation: For a typical municipality with median predictor")</span></span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"values, we predict average IMDS between "</span></span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a><span class="co">#       f"{pred_frame['mean_ci_lower'].values[0]:.1f} and "</span></span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a><span class="co">#       f"{pred_frame['mean_ci_upper'].values[0]:.1f}.")</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="task-4-prediction-interval-for-an-individual-municipality-semi-guided" class="level4">
<h4 class="anchored" data-anchor-id="task-4-prediction-interval-for-an-individual-municipality-semi-guided">Task 4: Prediction Interval for an Individual Municipality (Semi-guided)</h4>
<p><strong>Objective</strong>: Compute the 95% prediction interval for an <em>individual</em> municipality (not just the mean) and compare it with the confidence interval.</p>
<p><strong>Instructions</strong>:</p>
<ol type="1">
<li>Use <code>model_default.get_prediction(...).summary_frame(alpha=0.05)</code> at the same median predictor values</li>
<li>Report the prediction interval using <code>obs_ci_lower</code> and <code>obs_ci_upper</code></li>
<li>Compare the width of the prediction interval with the confidence interval from Task 3</li>
<li>Explain why the prediction interval is wider</li>
</ol>
<p><strong>Apply what you learned in section 12.3</strong>: Individual predictions must account for the irreducible error <span class="math inline">\(u^*\)</span>, making them fundamentally less precise than conditional mean predictions.</p>
<div id="cell-72" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Task 4: Prediction Interval for an Individual Municipality</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="co"># ----------------------------------------------------------</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Your code here: Compute prediction interval and compare with CI</span></span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Steps:</span></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Use the same prediction from Task 3</span></span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Extract obs_ci_lower and obs_ci_upper for the prediction interval</span></span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Compare widths</span></span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Discuss why PI is wider</span></span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Example structure:</span></span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a><span class="co"># pred_vars = ['ln_NTLpc2017', 'A00', 'A10', 'A20', 'A30', 'A40']</span></span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a><span class="co"># median_vals = reg_data[pred_vars].median()</span></span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a><span class="co"># pred_data = pd.DataFrame([median_vals])</span></span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a><span class="co"># pred = model_default.get_prediction(pred_data)</span></span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a><span class="co"># pred_frame = pred.summary_frame(alpha=0.05)</span></span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a><span class="co"># ci_width = pred_frame['mean_ci_upper'].values[0] - pred_frame['mean_ci_lower'].values[0]</span></span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a><span class="co"># pi_width = pred_frame['obs_ci_upper'].values[0] - pred_frame['obs_ci_lower'].values[0]</span></span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb34-23"><a href="#cb34-23" aria-hidden="true" tabindex="-1"></a><span class="co"># print("=" * 70)</span></span>
<span id="cb34-24"><a href="#cb34-24" aria-hidden="true" tabindex="-1"></a><span class="co"># print("CONFIDENCE INTERVAL vs PREDICTION INTERVAL")</span></span>
<span id="cb34-25"><a href="#cb34-25" aria-hidden="true" tabindex="-1"></a><span class="co"># print("=" * 70)</span></span>
<span id="cb34-26"><a href="#cb34-26" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"Predicted IMDS: {pred_frame['mean'].values[0]:.2f}")</span></span>
<span id="cb34-27"><a href="#cb34-27" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"\n95% CI (conditional mean):  [{pred_frame['mean_ci_lower'].values[0]:.2f}, "</span></span>
<span id="cb34-28"><a href="#cb34-28" aria-hidden="true" tabindex="-1"></a><span class="co">#       f"{pred_frame['mean_ci_upper'].values[0]:.2f}]  width = {ci_width:.2f}")</span></span>
<span id="cb34-29"><a href="#cb34-29" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"95% PI (individual):        [{pred_frame['obs_ci_lower'].values[0]:.2f}, "</span></span>
<span id="cb34-30"><a href="#cb34-30" aria-hidden="true" tabindex="-1"></a><span class="co">#       f"{pred_frame['obs_ci_upper'].values[0]:.2f}]  width = {pi_width:.2f}")</span></span>
<span id="cb34-31"><a href="#cb34-31" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"\nPI/CI width ratio: {pi_width / ci_width:.1f}x wider")</span></span>
<span id="cb34-32"><a href="#cb34-32" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"\nThe prediction interval is wider because it includes the")</span></span>
<span id="cb34-33"><a href="#cb34-33" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"irreducible uncertainty from the individual error term u*.")</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<blockquote class="blockquote">
<p><strong>Key Concept 12.12: Prediction Uncertainty for SDG Monitoring</strong></p>
<p>Satellite-based prediction models can estimate <em>average</em> development patterns with reasonable precision (narrow confidence intervals for the conditional mean). However, predicting development for a <em>specific municipality</em> involves much greater uncertainty (wide prediction intervals) because individual municipalities deviate from the average relationship. For SDG monitoring, this means satellite predictions are more reliable for identifying broad patterns than for pinpointing the exact development level of any single municipality.</p>
</blockquote>
</section>
<section id="task-5-model-robustness-comparison-independent" class="level4">
<h4 class="anchored" data-anchor-id="task-5-model-robustness-comparison-independent">Task 5: Model Robustness Comparison (Independent)</h4>
<p><strong>Objective</strong>: Create a comprehensive comparison table showing coefficient estimates and standard errors under three specifications: default, HC1, and cluster-robust.</p>
<p><strong>Instructions</strong>:</p>
<ol type="1">
<li>Create a formatted comparison table with coefficients, SEs, and significance stars under all three SE specifications</li>
<li>Identify whether any coefficients change sign or statistical significance across specifications</li>
<li>Discuss what the comparison reveals about model reliability</li>
<li>What does stability (or instability) across SE methods tell us about the trustworthiness of our satellite-development model?</li>
</ol>
<p><strong>This extends Chapter 12 concepts</strong>: You‚Äôre systematically assessing how robust your conclusions are to different assumptions about the error structure.</p>
<div id="cell-75" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Task 5: Model Robustness Comparison</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="co"># ----------------------------------------------------------</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Your code here: Create comprehensive comparison table</span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Steps:</span></span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Extract coefficients and SEs from all three models</span></span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Compute t-statistics and significance levels for each</span></span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Create a formatted comparison table</span></span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Identify any changes in sign or significance</span></span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Example structure:</span></span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a><span class="co"># def sig_stars(pval):</span></span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a><span class="co">#     if pval &lt; 0.01: return '***'</span></span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a><span class="co">#     elif pval &lt; 0.05: return '**'</span></span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a><span class="co">#     elif pval &lt; 0.10: return '*'</span></span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a><span class="co">#     else: return ''</span></span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a><span class="co"># print("=" * 90)</span></span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a><span class="co"># print("MODEL ROBUSTNESS: COEFFICIENT ESTIMATES AND STANDARD ERRORS")</span></span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a><span class="co"># print("=" * 90)</span></span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"{'Variable':&lt;16} {'Coef':&gt;8} {'SE(Def)':&gt;10} {'SE(HC1)':&gt;10} {'SE(Clust)':&gt;10} "</span></span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a><span class="co">#       f"{'Sig(D)':&gt;7} {'Sig(H)':&gt;7} {'Sig(C)':&gt;7}")</span></span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a><span class="co"># print("-" * 90)</span></span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a><span class="co"># for var in model_default.params.index:</span></span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a><span class="co">#     coef = model_default.params[var]</span></span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a><span class="co">#     se_d = model_default.bse[var]</span></span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a><span class="co">#     se_h = model_hc1.bse[var]</span></span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a><span class="co">#     se_c = model_cluster.bse[var]</span></span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a><span class="co">#     sig_d = sig_stars(model_default.pvalues[var])</span></span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a><span class="co">#     sig_h = sig_stars(model_hc1.pvalues[var])</span></span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a><span class="co">#     sig_c = sig_stars(model_cluster.pvalues[var])</span></span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a><span class="co">#     print(f"{var:&lt;16} {coef:&gt;8.4f} {se_d:&gt;10.4f} {se_h:&gt;10.4f} {se_c:&gt;10.4f} "</span></span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a><span class="co">#           f"{sig_d:&gt;7} {sig_h:&gt;7} {sig_c:&gt;7}")</span></span>
<span id="cb35-35"><a href="#cb35-35" aria-hidden="true" tabindex="-1"></a><span class="co"># print("-" * 90)</span></span>
<span id="cb35-36"><a href="#cb35-36" aria-hidden="true" tabindex="-1"></a><span class="co"># print("Significance: *** p&lt;0.01, ** p&lt;0.05, * p&lt;0.10")</span></span>
<span id="cb35-37"><a href="#cb35-37" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb35-38"><a href="#cb35-38" aria-hidden="true" tabindex="-1"></a><span class="co"># print("\nDo any coefficients change sign or significance?")</span></span>
<span id="cb35-39"><a href="#cb35-39" aria-hidden="true" tabindex="-1"></a><span class="co"># print("What does this tell us about model reliability?")</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="task-6-prediction-brief-independent" class="level4">
<h4 class="anchored" data-anchor-id="task-6-prediction-brief-independent">Task 6: Prediction Brief (Independent)</h4>
<p><strong>Objective</strong>: Write a 200-300 word assessment of prediction uncertainty in satellite-based development models.</p>
<p><strong>Your brief should address:</strong></p>
<ol type="1">
<li>How much uncertainty exists in satellite-based development predictions?</li>
<li>Are prediction intervals narrow enough to be useful for policy targeting?</li>
<li>How does the confidence interval for the conditional mean compare with the prediction interval for individual municipalities?</li>
<li>What additional data or methods might reduce prediction uncertainty?</li>
<li>Should policymakers rely on satellite predictions for allocating development resources to specific municipalities?</li>
</ol>
<p><strong>Connection to Research</strong>: The DS4Bolivia project shows that satellite-based models achieve meaningful but imperfect predictive accuracy. Your analysis quantifies <em>how much uncertainty</em> remains and whether it is small enough for practical SDG monitoring applications.</p>
<div id="cell-77" class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Your code here: Additional analysis for the prediction brief</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="co"># You might want to:</span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Compare prediction intervals at different predictor values</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a><span class="co">#    (e.g., low-NTL vs high-NTL municipalities)</span></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Calculate how many municipalities fall outside prediction intervals</span></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Visualize actual vs predicted IMDS with confidence bands</span></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Example structure:</span></span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a><span class="co"># # Actual vs predicted comparison</span></span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a><span class="co"># reg_data['predicted'] = model_default.predict(reg_data)</span></span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a><span class="co"># reg_data['residual'] = reg_data['imds'] - reg_data['predicted']</span></span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a><span class="co"># print("=" * 70)</span></span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a><span class="co"># print("PREDICTION ACCURACY SUMMARY")</span></span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a><span class="co"># print("=" * 70)</span></span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"RMSE: {np.sqrt(model_default.mse_resid):.2f}")</span></span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"Mean IMDS: {reg_data['imds'].mean():.2f}")</span></span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"RMSE as % of mean: {100 * np.sqrt(model_default.mse_resid) / reg_data['imds'].mean():.1f}%")</span></span>
<span id="cb36-20"><a href="#cb36-20" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"\nLargest over-prediction: {reg_data['residual'].min():.2f}")</span></span>
<span id="cb36-21"><a href="#cb36-21" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"Largest under-prediction: {reg_data['residual'].max():.2f}")</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
</section>
<section id="what-youve-learned-from-this-case-study" class="level4">
<h4 class="anchored" data-anchor-id="what-youve-learned-from-this-case-study">What You‚Äôve Learned from This Case Study</h4>
<p>Through this analysis of robust inference and prediction for Bolivia‚Äôs satellite-development model, you‚Äôve practiced:</p>
<ul>
<li><strong>Robust SE comparison</strong>: Compared default, HC1, and cluster-robust standard errors for the same model</li>
<li><strong>Cluster-robust inference</strong>: Accounted for within-department correlation among municipalities</li>
<li><strong>Conditional mean prediction</strong>: Predicted average IMDS with a narrow 95% confidence interval</li>
<li><strong>Prediction intervals</strong>: Quantified the much larger uncertainty in predicting individual municipalities</li>
<li><strong>Model robustness assessment</strong>: Evaluated whether conclusions change across different SE specifications</li>
</ul>
<p>These tools are essential for translating satellite-based models into credible SDG monitoring instruments. Robust inference ensures your significance conclusions hold under realistic data conditions, while prediction intervals honestly communicate the limits of individual-level forecasting.</p>
<p><strong>Connection to future chapters</strong>: In Chapter 14, we add <em>indicator variables</em> for departments to explicitly model regional differences in the satellite-development relationship.</p>
<hr>
<p><strong>Well done!</strong> You‚Äôve now applied Chapter 12‚Äôs advanced inference and prediction tools to the satellite-development model, quantifying both the reliability of your estimates and the precision of your predictions.</p>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "Óßã";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
            // default icon
            link.classList.add("external");
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../notebooks_colab/ch11_Statistical_Inference_for_Multiple_Regression.html" class="pagination-link" aria-label="11. Statistical Inference for Multiple Regression">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">11. Statistical Inference for Multiple Regression</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../notebooks_colab/ch13_Case_Studies_for_Multiple_Regression.html" class="pagination-link" aria-label="13. Case Studies for Multiple Regression">
        <span class="nav-page-text"><span class="chapter-title">13. Case Studies for Multiple Regression</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




<script src="../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>