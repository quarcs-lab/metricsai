# Analysis of Economics Data Chapter 3 The Sample Mean 

(c) A. Colin Cameron<br>Univ. of Calif. Davis

November 2022

## CHAPTER 3: The Sample Mean

- Now consider statistical inference
- extrapolating from sample to population
- here from sample mean $\bar{x}$ to population mean $\mu$.
- Basic idea is that the sample values $x_{1}, \ldots, x_{n}$ (lower case)
- are realizations of random variables $X_{1}, \ldots, X_{n}$ (upper case)
- So the sample mean $\bar{x}=\left(x_{1}+\cdots+x_{n}\right) / n$
- is a realization of the random variable $\bar{X}=\left(X_{1}+\cdots+X_{n}\right) / n$
- This chapter: distribution of $\bar{X}$ from underlying distribution of $X$.
- Next chapter: The two main tools of statistical inference
- Confidence intervals for the population mean $\mu$
- Hypothesis tests on $\mu$.


## Outline

(1) Random Variables
(2) Sample Generated by an Experiment
( ) Random Samples
(4) Properties of the Sample Mean
(T) Sampling from a Finite Population
(6) Estimation of the Population Mean
(1) Nonrepresentative Samples
(- Computer Generation of a Random Sample

- Datasets: COINTOSSMEANS, CENSUSAGEMEANS


### 3.1 Random Variables

- A random variable is a variable whose value is determined by the outcome of an experiment.
- An experiment is an operation whose outcome cannot be predicted with certainty.
- Example: the experiment is tossing a coin and the random variable takes value 1 if heads and 0 if tails.
- Example: the experiment is randomly selecting a person from the population and the associated random variable takes value equal to their annual earnings.
- Standard notation
- $X$ (or $Y$ or $Z$ ) denotes a random variable
- $x$ (or $y$ or $z$ ) denotes the values taken by $X$ (or $Y$ or $Z$ ).


## Example: Coin toss

- Simplest case is a random variable that takes one of only two possible values.
- Consider toss of fair coin with $X=1$ if heads and $X=0$ if tails. Then

$$
X= \begin{cases}0 & \text { with probability } 0.5 \\ 1 & \text { with probability } 0.5 .\end{cases}
$$

## Mean of a Random Variable

- Mean of $X$, denoted $\mu$ or $\mu_{X}$
- is the probability-weighted average of all possible values of $X$ in the population.
- $\mu$ is also denoted $\mathrm{E}[X]$
- the expected value of the random variable $X$
- the long-run average value expected if we draw a value of $X$ at random, draw a second value of $X$ at random, and so on, and then obtain the average of these values.

$$
\begin{aligned}
\mu \equiv \mathrm{E}[X] & =x_{1} \times \operatorname{Pr}\left[X=x_{1}\right]+x_{2} \times \operatorname{Pr}\left[X=x_{2}\right]+\cdots \\
& =\sum_{x} x \cdot \operatorname{Pr}[X=x]
\end{aligned}
$$

- Note that
- $\sum_{x}$ means the sum over all possible values $x$ can take
- and the possible values of $x$ are denoted $x_{1}, x_{2}, x_{3}, \ldots$


## Example of Mean

- Fair coin toss: $X$ takes values 0 or 1 with equal probabilities

$$
\begin{aligned}
\mu & =\sum_{x} \times \times \operatorname{Pr}[X=x] \\
& =\operatorname{Pr}[X=0] \times 0+\operatorname{Pr}[X=1] \times 1 \\
& =0.5 \times 0+0.5 \times 1 \\
& =0.5
\end{aligned}
$$

- Unfair coin: $X=1$ with probability 0.6 and $X=0$ with probability 0.4
- $\mu=0 \times 0.4+1 \times 0.6=0.6$.


## Variance and Standard Deviation

- Variance $\sigma^{2}$
- measures the variability in $X$ around $\mu$
- equals the expected value of $(X-\mu)^{2}$, the squared deviation of $X$ from the mean $\mu$
- probability-weighted average of $x_{1}^{*}, x_{2}^{*}, \ldots$

$$
\begin{aligned}
\sigma^{2} & \equiv \mathrm{E}\left[(X-\mu)^{2}\right] \\
& =\left(x_{1}-\mu\right)^{2} \times \operatorname{Pr}\left[X=x_{1}\right]+\left(x_{2}-\mu\right)^{2} \times \operatorname{Pr}\left[X=x_{2}\right]+\cdots \\
& =\sum_{x}(x-\mu)^{2} \times \operatorname{Pr}[X=x] .
\end{aligned}
$$

- Population standard deviation $\sigma$ is square root of the variance
- measured in the same units as $X$.


## Example of Variance and Standard Deviation

- Fair coin toss: $X$ takes values 0 or 1 with equal probabilities so $\mu=0.5$.
- Variance

$$
\begin{aligned}
\sigma^{2} & =\sum_{x}(x-\mu)^{2} \times \operatorname{Pr}[X=x] \\
& =\operatorname{Pr}(0-0.5)^{2} \times[X=0]+(1-0.5)^{2} \times \operatorname{Pr}[X=1] \\
& =0.25 \times 0.5+0.25 \times 0.5 \\
& =0.25
\end{aligned}
$$

- Standard deviation

$$
\sigma=\sqrt{0.25} \simeq 0.5
$$

### 3.2 Random Samples

- A sample of size $n$ takes values denoted $x_{1}, \ldots, x_{n}$.
- These values are realizations or outcomes of the random variables $X_{1}, X_{2}, \ldots, X_{n}$.
- Example: four consecutive coin tosses with results tails, heads, heads and heads
- random variable $X_{1}$ has realized value $x_{1}=0$
- random variable $X_{2}$ takes value $x_{2}=1$
- random variable $X_{3}$ takes value $x_{3}=1$
- random variable $X_{4}$ takes value $x_{4}=1$.


## Sample Mean is a Random Variable

- Sample of size $n$ has observed values $x_{1}, x_{2}, \ldots, x_{n}$.
- These are realizations of the random variables $X_{1}, X_{2}, \ldots, X_{n}$.
- Sample mean is the average

$$
\bar{x}=\left(x_{1}+x_{2}+\cdots+x_{n}\right) / n=\frac{1}{n} \sum_{i=1}^{n} x_{i}
$$

- This is a realization of the random variable

$$
\bar{X}=\left(X_{1}+X_{2}+\cdots+X_{n}\right) / n=\frac{1}{n} \sum_{i=1}^{n} X_{i} .
$$

## Aside: Sample Variance and Standard Deviation

- Similarly any other sample statistic (such as the median) is a realization of a random variable
- In addition to the sample mean we focus on the sample variance and sample standard deviation.
- Sample variance is average of squared deviations of $x$ around $\bar{x}$
- not around $\mu$ since $\mu$ is unknown

$$
s^{2}=\frac{1}{n-1} \sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{2}
$$

- The sample variance is a realization of the random variable

$$
S^{2}=\frac{1}{n-1} \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}
$$

- Taking the square root gives the sample standard deviation $s$ which is a realization of the random variable $S$.


### 3.3 Sample Generated from an Experiment: Coin Tosses

- We consider a simple experiment that generates many samples
- hence many sample means $\bar{x}$
- then summarize the resulting distribution of the many $\bar{x}$.
- Population: Outcomes from experiment of tossing a coin
- $X=1$ if heads and $X=0$ if tails
- Population mean $\mu=\mathrm{E}[X]=0.5$ and standard deviation $\sigma=0.5$.
- Sample: $n=30$
- random sample of size 30 from 30 coin tosses
- there are 10 heads and 20 tails, so $\bar{x}=10 / 30=0.333$
- histogram of this single sample is given in left panel of next slide.


## Example: Coin Tosses (continued)

- Left panel: $x$ 's from 1 sample of size 30 with 20 heads and 10 tails
- Right panel: $\bar{x}^{\prime} s$ for 400 samples of size 30

One Sample of Size 30
![](https://cdn.mathpix.com/cropped/72a3f87a-41ec-4ad3-a2db-effc82ed52f5-14.jpg?height=355&width=488&top_left_y=395&top_left_x=164)

400 Sample Means
![](https://cdn.mathpix.com/cropped/72a3f87a-41ec-4ad3-a2db-effc82ed52f5-14.jpg?height=355&width=485&top_left_y=395&top_left_x=690)

## Example: Coin Tosses (continued)

- Randomly draw 400 different samples, each of size 30
- then $\bar{x}_{1}=.333, \bar{x}_{2}=.500, \bar{x}_{3}=533, \ldots$.
- Histogram (plus kernel density estimate) for the 400 means from the 400 samples of size 30 is given in right panel of previous slide.
- roughly centered on the population mean

★ the average of the 400 means is 0.499 , close to $\mu=0.5$.

- much less variability in these 400 means than in the original population

★ the standard deviation of the 400 means is 0.086
★ much less than the population standard deviation of $\sigma=0.5$

- the density estimate is roughly that of the normal.


### 3.4 Properties of the Sample Mean

- The properties of $\bar{X}$ depend on the properties of $X_{1}, X_{2}, \ldots, X_{n}$
- such as the means and variances of $X_{1}, X_{2}, \ldots, X_{n}$
- and whether their values depend in part on other values.
- In this chapter we consider the simplest and standard set of assumptions in introductory statistics
- $X_{1}, X_{2}, \ldots, X_{n}$ have common mean $\mu$ and common variance $\sigma^{2}$
- $X_{1}, X_{2}, \ldots, X_{n}$ are statistically independent

★ statistical independence means that the value taken by $X_{2}$, for example, is not influenced by the value taken by $X_{1}, X_{3}, \ldots, X_{n}$.

- In later chapters we relax these assumptions
- e.g. regression allows for different means for different observations.


## Population Assumptions

- Population
- = set of all observations (or experimental outcomes).
- Sample
- = subset selected from the population.
- Properties of $\bar{x}$ depend on the random variable $\bar{X}$
- hence on assumptions about process generating $X_{1}, X_{2}, \ldots, X_{n}$.
- We assume a simple random sample where
- A. $X_{i}$ has common mean $\mu: \mathrm{E}\left[X_{i}\right]=\mu$ for all $i$.
- B. $X_{i}$ has common variance $\sigma^{2}: \operatorname{Var}\left[X_{i}\right]=\sigma^{2}$ for all $i$.
- C. $X_{i}$ is statistically independent of $X_{j}, i \neq j$.
- Shorthand notation: $X_{i} \sim\left(\mu, \sigma^{2}\right)$
- means $X_{i}$ are distributed with mean $\mu$ and variance $\sigma^{2}$.


## Mean and Variance of the Sample Mean

- Consider $\bar{X}=\left(X_{1}+X_{2}+\cdots+X_{n}\right) / n$ for $X_{i} \sim\left(\mu, \sigma^{2}\right)$.
- The (population) mean of the sample mean is

$$
\mu_{\bar{X}} \equiv \mathrm{E}[\bar{X}]=\mu .
$$

- The (population) variance of the sample mean is

$$
\sigma_{\bar{X}}^{2} \equiv \mathrm{E}\left[\left(\bar{X}-\mu_{\bar{X}}\right)^{2}\right]=\frac{\sigma^{2}}{n},
$$

- The (population) standard deviation is $\sigma_{\bar{X}}=\sigma / \sqrt{n}$.
- Sample mean is less variable than the underlying data
- since $\sigma_{\bar{X}}^{2}<\sigma^{2}$.
- Sample mean is close to $\mu$ as $n \rightarrow \infty$
- since $\mathrm{E}[\bar{X}]=\mu$ and variance $\sigma_{\bar{X}}^{2}=\sigma^{2} / n \rightarrow 0$ as $n \rightarrow \infty$.


## Aside: Proof for Mean of the Sample Mean

- Recall

$$
\bar{X}=\left(X_{1}+X_{2}+\cdots+X_{n}\right) / n
$$

- Proof uses
- $\mathrm{E}[a X]=a \mathrm{E}[X]$
- $\mathrm{E}[X+Y]=\mathrm{E}[X]+\mathrm{E}[Y]$
and assumption A (common mean of $X_{i}$ ).
- Then

$$
\begin{aligned}
\mathrm{E}[\bar{X}] & =\mathrm{E}\left[\frac{1}{n}\left(X_{1}+X_{2}+\cdots+X_{n}\right)\right] \\
& =\frac{1}{n} \mathrm{E}\left[X_{1}+X_{2}+\cdots+X_{n}\right] \\
& =\frac{1}{n}\left\{\mathrm{E}\left[X_{1}\right]+\mathrm{E}\left[X_{2}\right]+\cdots+\mathrm{E}\left[X_{n}\right]\right\} \\
& =\frac{1}{n}\{\mu+\mu+\cdots+\mu\} \\
& =\mu .
\end{aligned}
$$

## Aside: Variance of the Population Mean

- Proof in Appendix B. 2 uses that
- $\operatorname{Var}[a X]=a^{2} \mathrm{E}[X]$ in general
- $\operatorname{Var}[X+Y]=\operatorname{Var}[X]+\operatorname{Var}[Y]$ for independent variables
- and assumptions A-C.
- Then

$$
\begin{aligned}
\operatorname{Var}[\bar{X}] & =\operatorname{Var}\left[\frac{1}{n}\left(X_{1}+X_{2}+\ldots+X_{n}\right)\right] \\
& =\left(\frac{1}{n}\right)^{2} \operatorname{Var}\left[X_{1}+X_{2}+\ldots+X_{n}\right] \\
& =\left(\frac{1}{n}\right)^{2}\left\{\operatorname{Var}\left[X_{1}\right]+\cdots+\operatorname{Var}\left[X_{n}\right]\right\} \\
& =\left(\frac{1}{n}\right)^{2} \sigma^{2}+\cdots+\left(\frac{1}{n}\right)^{2} \sigma^{2} \\
& =\left(\frac{1}{n}\right)^{2}\left\{\sigma^{2}+\cdots+\sigma^{2}\right\} \\
& =\left(\frac{1}{n}\right)^{2} \times n \sigma^{2} \\
& =\frac{1}{n} \sigma^{2}
\end{aligned}
$$

## Normal Distribution and the Central Limit Theorem

- We have shown to date that $\bar{X} \sim\left(\mu, \sigma^{2} / n\right)$
- In general, subtracting the mean and dividing by the standard deviation yields a random variable with mean 0 and variance 1 .
- So here the standardized variable

$$
Z=\frac{\bar{X}-\mu}{\sigma / \sqrt{n}} \sim(0,1) .
$$

- The central limit theorem (a remarkable result) proves normality as the sample size gets large

$$
Z \sim N(0,1) \text { as } n \rightarrow \infty .
$$

- The central limit theorem holds under assumptions A-C
- and also under some weaker conditions.


## Normal Distribution (continued)

- Now convert back to the original $\bar{X}$.
- We have

$$
Z=\frac{\bar{X}-\mu}{\sigma / \sqrt{n}} \sim N(0,1) \text { as } n \rightarrow \infty .
$$

- Then $\bar{X}$ is approximately normally distributed in large samples

$$
\bar{X} \sim N\left(\mu, \sigma^{2} / n\right) \text { approximately for large } n .
$$

- We will use this result to do statistical inference on $\mu$.
- However, the variance $\sigma^{2} / n$ is unknown as $\sigma^{2}$ is unknown
- we will have to get an estimate
- replace $\sigma^{2}$ by its estimate $s^{2}$
- where $s$ is the sample standard deviation of $X$.


## Standard Error of the Sample Mean

- Estimated variance of $\bar{X}$ is

$$
s_{\bar{X}}^{2}=\frac{s^{2}}{n}=\frac{\frac{1}{n-1} \sum_{i}\left(x_{i}-\bar{x}\right)^{2}}{n},
$$

- Estimated standard deviation of $\bar{X}$

$$
s_{\bar{X}}=\frac{s}{\sqrt{n}}=\frac{\sqrt{\frac{1}{n-1} \sum_{i}\left(x_{i}-\bar{x}\right)^{2}}}{\sqrt{n}} .
$$

- $s_{\bar{X}}$ is called the standard error of the sample mean $\bar{X}$.
- The term "standard error" means estimated standard deviation
- various estimators each have a distinct standard error
- a reported "standard error" in computer output need not be $s_{\bar{X}}$.
- Use the notation

$$
\operatorname{se}(\bar{X})=s / \sqrt{n}
$$

## Summary for the Sample Mean

(1) Sample values $x_{1}, \ldots, x_{n}$ are observed values of the random variables $X_{1}, \ldots, X_{n}$.
(2) Individual $X_{i}$ have common mean $\mu$ and variance $\sigma^{2}$ and are independent.
(3) Average $\bar{X}$ of $n$ draws of $X_{i}$ has mean $\mu$ and variance $\sigma^{2} / n$.
(4) Standardized statistic $Z=(\bar{X}-\mu) /(\sigma / \sqrt{n}) \sim(0,1)$ has mean 0 and variance 1.
(5) $Z$ is standard normal as size $n \rightarrow \infty$ by the central limit theorem.
(6) For large $n$ a good approximation is that $\bar{X} \sim N\left(\mu, \sigma^{2} / n\right)$
(1) The standard error of $\bar{X}$ equals $s / \sqrt{n}$, where "standard error" is general terminology for "estimated standard deviation".

### 3.5 Sampling from a Population: 1880 Census

- Now consider an example of sampling from a population.
- Population: $N=50,169,452$
- all people recorded as living in the U.S. in 1880
- the average age is 24.13 years, so $\boldsymbol{\mu}=\mathbf{2 4 . 1 3}$
- the standard deviation of age is 18.61 , so $\boldsymbol{\sigma}=\mathbf{1 8 . 6 1}$
- histogram is given in the next slide.


## Example: 1880 Census (continued)

- Population
- Probabilities decline with age (clearly not the normal)
- Peaks due to rounding at five and ten years

Entire 1880 Census
![](https://cdn.mathpix.com/cropped/72a3f87a-41ec-4ad3-a2db-effc82ed52f5-26.jpg?height=533&width=759&top_left_y=353&top_left_x=253)

## Example: 1880 Census (continued)

- Single sample: $n=25$
- random sample of size 25 from the entire U.S. population
- the average age is 27.84 , so $\overline{\mathbf{x}}=\mathbf{2 7 . 8 4}$
- the standard deviation of age is 20.71, so $\mathbf{s}=\mathbf{2 0 . 7 1}$
- these are similar to, but not exactly equal to, $\mu$ and $\sigma$
- histogram of $x^{\prime} s$ in a single sample is given in left panel of next slide.
- Many samples of size 25
- randomly draw 100 different samples, each of size 25
- then $\bar{x}_{1}=27.84, \bar{x}_{2}=19.40, \bar{x}_{3}=23.28$ years, $\ldots$.
- average of the 100 sample means is 23.78 , close to $\mu=24.13$.
- standard deviation of the 100 means is 3.76 , close to $\sigma / \sqrt{n}=18.61 / \sqrt{25}=3.72$.
- histogram of $\bar{x}^{\prime} s$ across 100 samples is given in right panel of next slide.


## Example: 1880 Census (continued)

- 100 different means from 100 different samples, each of size 25
- histogram (left) and kernel density estimate (right)
- looks like normal with mean $\mu$ and standard deviation much less than $\sigma$
![](https://cdn.mathpix.com/cropped/72a3f87a-41ec-4ad3-a2db-effc82ed52f5-28.jpg?height=433&width=538&top_left_y=387&top_left_x=82)
![](https://cdn.mathpix.com/cropped/72a3f87a-41ec-4ad3-a2db-effc82ed52f5-28.jpg?height=405&width=541&top_left_y=389&top_left_x=644)


### 3.6 Estimation of the Sample Mean

- Desire a good point estimate of population mean $\mu$
- why use $\bar{x}$ rather than some other estimate?
- A desirable estimator of $\mu$ has distribution
- centered on $\mu$
- with as little variability around $\mu$ as possible.


## Parameter, Estimator and Estimate

- A parameter is a constant that determines in part the distribution of $x$.
- An estimator is a method for estimating a parameter.
- An estimate is the particular value of the estimator obtained from the sample.
- For estimation of the mean of $X$ using the sample mean
- the parameter is $\mu$
- the estimator is the random variable $\bar{X}$
- the estimate is the sample value $\bar{x}$.


## Unbiased Estimators

- An unbiased estimator of a population parameter
- has expected value that equals the population parameter.
- The sample mean is unbiased for $\mu$
- since $\mathrm{E}[\bar{X}]=\mu$.


## Minimum Variance Estimators

- Other estimators may also be unbiased and consistent for $\mu$
- e.g. sample median in the case where $X$ is symmetrically distributed
- discriminate between such estimators using their variance.
- A best estimator or efficient estimator
- has minimum variance among the class of consistent estimators (or of unbiased estimators).
- Under assumptions A-C the sample mean has variance $\sigma^{2} / n$
- for $X$ that is normal, Bernoulli, binomial or Poisson no other unbiased estimator has lower variance
- for $X$ with other distributions the sample mean is often close to having the lowest variance
- generally the sample mean is used to estimate $\mu$.


## Consistent Estimators

- Consistency is a more advanced concept that considers behavior as the sample size goes to infinity.
- A consistent estimator of a population parameter
- is one that is almost certainly arbitrarily close to the population parameter as the sample size gets very large.
- A sufficient condition for consistency is
- any bias disappears as the sample size gets very large
- the variance goes to zero as the sample size gets very large
- The sample mean is consistent for $\mu$ under assumptions A-C
- it is unbiased
- the variance $\sigma_{\bar{X}}^{2}=\sigma^{2} / n \rightarrow 0$ as $n \rightarrow \infty$.


### 3.7 Samples other than Simple Random Samples

- Recall simple random sample means data are independent and from the same distribution.
- Representative Samples
- Still from same distribution but no longer statistically independent.
- Then can adapt methods using an alternative formula for $\operatorname{se}(\bar{x})$.
- Nonrepresentative samples
- Now different observations may have different $\mu$
- e.g. Survey readers of Golf Digest not representative of population.
- Big problem.
- Weighted mean can still be used if population weights are known
- $\pi_{i}=$ probability that $i^{t h}$ observation is included in the sample.
- sample weights $w_{i}=1 / \pi_{i}$
- weighted mean $\bar{x}_{w}=\left[\sum_{i=1}^{n} w_{i} x_{i}\right] /\left[\sum_{i=1}^{n} w_{i}\right]$.


### 3.8 Computer Generation of a Random Variable

- A (pseudo) uniform random number generator
- creates values between 0 and 1
- any value between 0 and 1 is equally likely
- successive values appear to be independent of each other.
- To simulate 30 coin tosses
- draw 30 uniform random numbers
- result is heads if the uniform random number exceeds 0.5
- For Census example
- if uniform random number is between 0 and $1 / N$, where $N=$ 50,169,452, we choose the first person, etcetera
- The sequence depends on the starting value called the seed
- always set the seed (e.g. equal to 10101).


## Example Stata Code to give 400 sample means

- The following advanced Stata code obtains the 400 sample means in the coin toss example of Chapter 3.2
- the program generates one sample of size 30 of $\times$ equal 1 or 0
- the simulate command does this 400 times
- this gives 400 observations on variable xbar.

```
program onesample, rclass
    drop _all
    set obs 30
    generate u = runiform()
    generate x = u > 0.5
    summarize x
    return scalar xbar = r(mean)
end
simulate xbar=r(xbar), seed(10101) reps(400): onesample
summarize
```


## Some in-class Exercises

(1) Suppose $X=100$ with probability 0.8 and $X=600$ with probability 0.2 . Find the mean, variance and standard deviation of $X$.
(2) Consider random samples of size 25 from the random variable $X$ that has mean 100 and variance 400 . Give the mean, variance and standard deviation of the mean $\bar{X}$.

